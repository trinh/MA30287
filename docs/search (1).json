[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "",
    "text": "Preface\nWelcome to to the 2022-23 delivery of MA30287 Maths of Planet Earth at the University of Bath.\nHere is a picture that represents the course."
  },
  {
    "objectID": "index.html#lectures-and-office-hours",
    "href": "index.html#lectures-and-office-hours",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "Lectures and office hours",
    "text": "Lectures and office hours\nLectures take place at the following times and locations:\n\nTuesdays 9:15 in 4E 3.10\nWednesdays 11:15 in 8W 3.22\nThursdays 15:15 in 8W 3.22\n\nOffice hours: You will be able to find me for an office hour in 4W 2.18 on Thursdays (following the lecture). Typically it is best to set this up, beforehand, by email appointment."
  },
  {
    "objectID": "index.html#coursework-and-examinations",
    "href": "index.html#coursework-and-examinations",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "Coursework and examinations",
    "text": "Coursework and examinations\nYour final mark will be 25% coursework and 75% final exam.\nDetails of the coursework will be released in Week 7 and it will be due in Week 101."
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "Resources",
    "text": "Resources\nIn general, you will have access to a few kinds of resources:\n\nThe Moodle portal will be the main organisation portal.\nLecture notes, coursework, and other resources will be found in an online format and will be linked on Moodle.\nCoding will be done via the website https://maths.jupyterhub.bath.ac.uk.\n\nNaturally, because this is an entirely new module at Bath, there will be a fair amount of activity as we settle the material over the semester. Whenever we complete a lecture note (i.e. a ‘chapter’), we will use a box like this to indicate when the material was covered and in which lecture:\n\n\n\n\n\n\n2022-23 note\n\n\n\nThe material in this note was covered in Lecture XX.\n\n\nHopefully by the time the module ends, every relevant chapter will have such a note. This allows you to judge what material has been ‘finalised’."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis course officially requires MA20221 (modeling and dynamical systems) or XX20231 (mathematical and statistical methods for the life sciences).\nIt is designed to be somewhat stand-alone in the sense that applied mathematical techniques learned in other courses will be introduced in some capacity. Such techniques will involve:\n\nSolutions of ordinary differential equations (MA10230 and MA20220).\nMultivariable calculus, partial differentiation, and multiple integrals (MA10230 and MA10236); some review/introduction of concepts from MA20223.\nDynamical systems, stability, phase planes (MA20221, MA30060).\nNumerical methods in Python (MA10276).\n\nWhenever possible, I have isolated such reviews/introductions and these can be found in the Mathematical methods section of these notes."
  },
  {
    "objectID": "index.html#resources-1",
    "href": "index.html#resources-1",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "Resources",
    "text": "Resources\nThis course is designed around the following sources:\n\nSustainable energy – without the hot air by (MacKay 2009)\nMathematics & Climate by (Kaper and Engler 2013)\nMathematical Geoscience by (Fowler 2011)\n\n\n\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36. Springer.\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM.\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "lectureplan.html",
    "href": "lectureplan.html",
    "title": "Lecture plan",
    "section": "",
    "text": "2022-23 note\n\n\n\nThis material has not yet been finalised and is still under construction.\nThis note will be completed as the course is taught for the first time.\n\n\n\n\n\n\n\n\n\n\nLecture\nTopic\nChapter\n\n\n\n\n\nEstimating your energy on the back of an envelope\n\n\n\n\nWeek 1\n\n\n\n1\nIntroduction to the course; conservation equations and deriving the heat equation\nChapter 1\n\n\n2\nUnits and nondimensionalisation\nChapter 2\n\n\n3\nMore nondimensionalisation; derivation of the basic energy model\nChapter 3\n\n\n\nWeek 2\n\n\n\n4\nProblem class; problem sheet 1\nChapter 4, Chapter 26\n\n\n5\nCO2 concentration and estimating consumption\nChapter 5\n\n\n6\nEstimating consumption; questions to think about\nChapter 6, Chapter 7, Chapter 26\n\n\n\nBoot camp on practical applied mathematics\n\n\n\n\nWeek 3\n\n\n\n7\nAsymptotic approximations for algebraic equations\nChapter 8\n\n\n8\nAsymptotic approximations for ODEs, Euler’s method\nChapter 9, Chapter 10\n\n\n9\nProblem class; problem set 2\nChapter 28\n\n\n\nWeek 4\n\n\n\n10\nBisection, Newton’s & Secant methods, Jacobians\nChapter 21\n\n\n11\nMatched asymptotics and BVPs\nChapter 12\n\n\n12\nProblem class; problem sheet 2\nChapter 13\n\n\n\nConceptual models of Planet Earth\n\n\n\n\nWeek 5\n\n\n\n13\nSteady states of the basic energy model I\nChapter 13\n\n\n14\nTechniques: Arclength continuation I\nChapter 23\n\n\n15\nTechniques: Arclength continuation II\nChapter 23\n\n\n\nWeek 6\n\n\n\n16\nSteady states of the basic energy model II\nChapter 14\n\n\n17\nBasic models of the ocean\nChapter 15\n\n\n18\nProblem class; problem sheet 3\n\n\n\n\nWeek 7\n\n\n\n19\nTechniques: Numerical solution of ODEs\n\n\n\n20\nTechniques: Method of multiple scales\n\n\n\n21\nStommel’s box model and its variants\nChapter 16\n\n\n\nWeek 8\n\n\n\n22\nZonal energy budget\n\n\n\n23\nTechniques: Legendre polynomials and spectral numerics\n\n\n\n24\nProblem class; problem sheet 4\n\n\n\nXX\nEl Nino-Southern Oscillation\n\n\n\n\nPhysical models of Planet Earth\n\n\n\n\nWeek 9\n\n\n\n26\nRadiative energy transfer\n\n\n\n27\nTwo-stream approximation\n\n\n\n28\nRunaway greenhouse effect\n\n\n\n\nWeek 10\n\n\n\n29\nIce-albedo feedback\n\n\n\n30\nCarbon cycle\n\n\n\n31\nOcean carbon\n\n\n\n32\nProblem class; problem sheet 5"
  },
  {
    "objectID": "part-01-intro/intro.html",
    "href": "part-01-intro/intro.html",
    "title": "Introduction",
    "section": "",
    "text": "2022-23 note\n\n\n\nCovered in lecture 1.\n\n\nMathematics of Planet Earth seems like an incredibly broad description for a course, but perhaps in order to give a rough idea of what such a course might include, we can consider the following diagram, which illustrates different categories and subject areas that are involved in the modelling of a full Earth system.\n\n\n\nFigure 1: The many components of a full Earth System Model (image from Nature; citation needed\n\n\nIt would be possible to spend a lifetime studying any one aspects of the above categories, and they span many different areas of study, including: (i) engineering (civil, fluids, mechanical, etc.); (ii) physics (geosciences, mechanics); (iii) Earth sciences; (iv) policy and health; and so forth and so on. As mathematicians, we also have a unique perspective, and applied mathematics plays important roles in many of the above categories.\nIn essence, this course will divide into three themes, each theme centred upon a different style of study. All of these themes are united by aspects of mathematical modelling and mathematical analysis and this is what distinguishes our style of study from adjacent areas of science and social science.\n\nIn the first part of the course, we will use back-of-the-envelope mathematics, and conservation-style arguments to study various aspects of energy consumption and energy renewal. This involves, for example, estimating your own energy usage, and developing a basic understanding of the mechanics of some renewable technologies. The source for this part of the course will be (MacKay 2009).\nIn the second part of the course, we will study so-called conceptual or box models of the climate. This involves some of the blue elements of Figure 1, and thus we use coarse-grained models of describing the climate. This will involve applying some of the dynamical systems (phase-plane analysis of ODEs) you have learned previously, along with new methods of computation and analysis. The source for this part of the course will be (Kaper and Engler 2013).\nFinally, the last part of the course will involve more in-depth analysis of the physical models that govern the blue elements of Figure 1. This moves us from the toy box models studied above to digging into the underlying physics—this also falls into the category of Mathematical Geoscience. For example, we will use partial differential equations to study the atmosphere and develop a deeper understanding of greenhouse gases. The source for this part of the course will be (Fowler 2011).\n\n\n\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36. Springer.\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM.\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-01-intro/intro-PDEs.html",
    "href": "part-01-intro/intro-PDEs.html",
    "title": "1  Conservation laws and consitutive laws",
    "section": "",
    "text": "2022-23 note\n\n\n\nCovered in lecture 1.\n\n\nIn the first chapter of (Fowler 2011), there is a concise introduction to the different categories of techniques and approaches that you might use when doing mathematical modelling in the real world. Some of these ideas will be introduced to you in this course.\nHere, we provide a brief intro to the highlights, involving the use of conservation laws (and PDEs) and also the concept of non-dimensionalisation (which you would have encountered previously), studied in Chapter 2.\n\n\n\n\n\n\nVectors and PDEs\n\n\n\nVectors and PDEs is not a prerequisite for this course, but naturally in studying anything related to the physical real world, we must discuss partial differential equations. The hope is that the necessary theory for PDEs will be presented to you as this course evolves, so that it can appreciated by both newcomers and experienced readers.\n\n\nConservation laws can be expressed as mathematical equations that represent the idea that some quantity is conserved. In processes governing the planet, these might correspond to conservation of heat, of water, of air, of momentum, etc.\nIn Chapter 3, we will develop the simplest possible model governing the temperature on the surface of the Earth. It is a conservation equation for energy and is zero-dimensional (does not involve time and does not involve spatial variation).\nIn order to demonstrate some of the basic principles of this course, let us demonstrate the derivation of the heat equation. We are interested in modelling the heat in a volume, \\(V\\), which, for the sake of concreteness is given by a long cylinder with its axis along \\(x \\in [0, L]\\). We assume that the side walls of the cylinder are insulated and the temperature only varies along the \\(x\\) direction.\nAt any point along this rod, the internal heat is given by \\(\\rho c T(x, t)\\), where \\(\\rho\\) is the density of the material (kg/m3), \\(c\\) is the specific heat capacity (J/(kg K)), and \\(T\\) is the temperature (K). Therefore, the heat energy along any segment in the rod is calculated from\n\n\n\n\n\n\nInternal heat energy\n\n\n\n\\[\n\\text{heat energy in $[a, b]$} = \\int_a^b \\rho c T \\, \\mathrm{d}x.\n\\]\n\n\nIf the heat changes, then the rate of change of heat energy is given the time derivative of the above quantity. By conservation of energy, any change of the internal energy must be equal to the inflow or outflow of heat at the ends, \\(x = a\\) or \\(x = b\\). We therefore write \\(q\\) for the flux (or flow) of heat.\nWe need a constitutive law that dictates how energy is exchanged at the boundaries. Based on intuition, it is sensible to assume that the flow of heat proceeds from hot to cold. For example, hot air rises towards cool air; or heat from a hot mug of tea flows and diffuses outwards into a cold room. Therefore, we write this as\n\n\n\n\n\n\nFourier’s law\n\n\n\nFourier’s law in 1D specifies that the heat flux is given by \\[\nq(x, t) = -k \\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}x}.\n\\]\n\n\nThis is known as Fourier’s law. The quantity \\(k\\) is the thermal conductivity, and its units are W/(m K). Because a Watt is a Joule/s, you can also see that the units of \\(k\\) are J/(m K s). The quantity \\(q\\) is the flux, and you can verify that it is given in units of J/(m2 s).\nTherefore by energy conservation, we have \\[\n\\frac{\\mathrm{d}}{\\mathrm{d}t}  \\int_a^b \\rho c T \\, \\mathrm{d}x = q(x = b, t) - q(x = a, t),\n\\] i.e. the change in internal heat is equal to the flow through the ends. Substitution Fourier’s law, we can then write \\[\n\\int_a^b \\rho c \\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}t} \\, \\mathrm{d}x = \\int_a^b k \\frac{\\mathrm{\\partial}^2 T}{\\mathrm{\\partial}x^2} \\, \\mathrm{d}x.\n\\] We then argue that because the above needs to be true for all segments [a, b] within the rod, then it must be true everywhere. Therefore we are left with the classic heat equation.\n\n\n\n\n\n\nHeat equation\n\n\n\n\\[\n\\rho c\\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}t} = k \\frac{\\mathrm{\\partial}^2 T}{\\mathrm{\\partial}x^2}.\n\\tag{1.1}\\]\n\n\nIn order to produce a sensible physical solution, the above equation is typically supplemented by initial conditions and boundary conditions. An example might be\n\n\n\n\n\n\nInitial and boundary conditions\n\n\n\n\\[\n\\begin{gather}\nT(x, 0) = T_0 \\\\\nT(0, 0) = T_a \\\\\nT(L, 0) = T_b\n\\end{gather}\n\\]\n\n\nwhich expresses, respectively, that the temperature starts from a constant temperature, \\(T_0\\), and where the ends of the rod are kept at temperature \\(T_a\\) and \\(T_b\\). In courses like MA20223, you may have learned how to solve the above equation.\n\n\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36. Springer."
  },
  {
    "objectID": "part-01-intro/intro-nondim.html#dimensional-quantities",
    "href": "part-01-intro/intro-nondim.html#dimensional-quantities",
    "title": "2  Dimensional scaling analysis",
    "section": "2.1 Dimensional quantities",
    "text": "2.1 Dimensional quantities\nEvery physical quantity, say Q, can be expressed as a product of a dimensional unit, denoted [Q], and a magnitude, say Q’. Thus we write \\[\nQ = Q'[Q]\n\\] For example, if \\(x\\) corresponds to the physical length in a problem, we might select \\([x] = \\mathrm{km}\\) or \\([x] = \\mathrm{yards}\\) or \\([x] = \\mathrm{m}\\). It is important to choose the dimensionalisation to suit the problem under consideration.\n\n2.1.1 SI units\nThe International System (SI) of Base Units sets out a distinct selection of choices for dimensions in certain physical quantities. The seven fundamental dimensional units are\n\n[Length] = metre\n[Time] = seconds\n[Mass] = kilogram\n[Temperature] = Kelvin\n[Electric current] = ampere\n[Light intensity] = candela\n[Material quantity] = mole\n\nDimensional units that can be expressed in terms of other fundamental units are known as derived units. For example:\n\n[Speed] = metre/second\n[Acceleration] = metre/second2\n[Force] = kilogram . metre/second2"
  },
  {
    "objectID": "part-01-intro/intro-nondim.html#dimensional-homogeneity-and-non-dimensionalisation",
    "href": "part-01-intro/intro-nondim.html#dimensional-homogeneity-and-non-dimensionalisation",
    "title": "2  Dimensional scaling analysis",
    "section": "2.2 Dimensional homogeneity and non-dimensionalisation",
    "text": "2.2 Dimensional homogeneity and non-dimensionalisation\nAll terms in any equation must have the same dimensions. This is the principle of dimensional homogenuity. For example, Newton’s second law expresses the fact that \\[\nF = m \\frac{\\mathrm{d}^2x}{\\mathrm{d}t^2}\n\\] We can check, then, that the units do indeed match up on either side. Here, the RHS has units of [m] [x]/[t]2 or in SI units, kg . metres / seconds2. This indeed matches our previous given SI unit decomposition for force.\nNotice in addition that the input to functions like \\(\\cos\\theta\\) and \\(e^z\\) must be non-dimensional (or dimensionless).\nThe process of nondimensionalisation is then as follows. Given an equation, we know that each term must have the same dimension. Therefore, we can scale all the dependent and independent variables by dimensional constants in order to yield a non-dimensional equation.\nWhy this is an important tool is demonstrated by the below."
  },
  {
    "objectID": "part-01-intro/intro-nondim.html#returning-to-the-heat-equation",
    "href": "part-01-intro/intro-nondim.html#returning-to-the-heat-equation",
    "title": "2  Dimensional scaling analysis",
    "section": "2.3 Returning to the heat equation",
    "text": "2.3 Returning to the heat equation\nExact units are not relevant for dynamics, and it is instead the ratio of units that we care about. To apply this principle, let us non-dimensionalise the equation Equation 1.1. We introduce typical scales for each of the variables. For example, we non-dimensionalise the temperature and distance by setting \\[\nT = T_0 T' \\quad \\text{and} \\quad x = L x',\n\\] where primes now denote non-dimensional quantities. Since it is not clear how to scale time, we set \\(t = [t] t;'\\) and choose the scale later. Substitution into the equation now yields \\[\\begin{gather}\n\\frac{\\rho c T_0}{[t]}\\frac{\\mathrm{\\partial}T'}{\\mathrm{\\partial}t'} = \\frac{kT_0}{L^2} \\frac{\\mathrm{\\partial}^2 T'}{\\mathrm{\\partial}x'^2}, \\\\\nT(x, 0) = 1 \\\\\nT(0, 0) = \\frac{T_a}{T_0}, \\\\\nT(L, 0) = \\frac{T_b}{T_0}.\n\\end{gather}\\]\nIt is useful to think of time in terms of velocity and distance. Let us then write \\[\n[t] = L/U,\n\\] where \\(U\\) is a typical velocity scale (which again, we shall specify later). Then note that the heat equation can be written as \\[\n\\frac{\\rho c}{(L/U)} \\frac{\\mathrm{\\partial}T'}{\\mathrm{\\partial}t'} = \\frac{k}{L^2}\\frac{\\mathrm{\\partial}^2 T'}{\\mathrm{\\partial}x'^2}.\n\\] We can move all the units to one side and then write \\[\n\\frac{\\mathrm{\\partial}T'}{\\mathrm{\\partial}t'} =\\text{Pe} \\frac{\\mathrm{\\partial}^2 T'}{\\mathrm{\\partial}x'^2}.\n\\tag{2.1}\\]\nWe can verify that the quantity \\[\n\\mathrm{Pe} =  \\frac{k/(\\rho c L^2)}{U/L} = \\frac{\\text{diffusive timescale}}{\\text{advective timescale}}.\n\\] known as the Peclet number is entirely non-dimensional. This number essentially charactises the balance between diffusive effects (which causes heat to spread out) versus advective effects (the transport of the heat). In the case of our problem, there is no obvious source of advection. Another way to see this is that the temporal or velocity scale is entirely free for us to select.\nWe can now choose the temporal scale so as to simplify the equation. Let us choose \\[\n[t] = \\frac{L}{U} = \\frac{\\rho c L^2}{k}.\n\\tag{2.2}\\]\nNow the system simplifies. We can now write \\[\n\\begin{gather}\n\\frac{\\mathrm{\\partial}T'}{\\mathrm{\\partial}t'} = \\frac{\\mathrm{\\partial}^2 T'}{\\mathrm{\\partial}x'^2} \\\\\nT'(x', 0) = 1 \\\\\nT'(0, 0) = A, \\\\\nT'(1, 0) = B.\n\\end{gather}\n\\tag{2.3}\\]\nWe have gone from a system where we needed to consider six parameters to one where we only need to specify two (essentially, the ratio of the initial heat to the boundary values). Imagine you are an engineer at a thermal company, and asked to study the different possible configurations of heat in the above setup. If you were to blindly perform numerical computations, you would have had to set specific values for each of the six parameters.\nInstead, some mathematical analysis has demonstrated that the six-dimensional space of parameters can be simplified to a two-dimensional one—this is an enormous simplification.\nYour analysis has further identified the key non-dimensional parameter that appears in Equation 2.1. This demonstrates that it is not the individual values of \\(k\\), \\(\\rho\\), \\(c\\), … that matter, but rather their specific combination in the form of the Peclet number."
  },
  {
    "objectID": "part-01-intro/intro-nondim.html#gi-taylor-and-the-atomic-bomb",
    "href": "part-01-intro/intro-nondim.html#gi-taylor-and-the-atomic-bomb",
    "title": "2  Dimensional scaling analysis",
    "section": "2.4 GI Taylor and the atomic bomb",
    "text": "2.4 GI Taylor and the atomic bomb\n\n\n\n\n\n\n2022-23 note\n\n\n\nDuring Lecture 3 we will cover some aspects of how non-dimensionalisation was famously used by British fluid dynamicist GI Taylor to estimate the energy of the atom bomb. Students can refer to the visualiser notes.\n\n\n\n\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36. Springer."
  },
  {
    "objectID": "part-01-intro/basic-energy-model.html#the-basic-energy-model",
    "href": "part-01-intro/basic-energy-model.html#the-basic-energy-model",
    "title": "3  Basic energy models",
    "section": "3.1 The basic energy model",
    "text": "3.1 The basic energy model\nThe basic model is derived as follows.\n\nBy considering the incoming radiation from the sun, obtain an estimate for the incoming energy, \\(E_{\\text{in}}\\).\nUse a constitutive law that indicates how much outgoing energy is produced by an object heated to some temperature.\nEquate the change in internal energy to be equal to the difference between the above two items.\n\nNote that the primary components of the global energy balance are radiative fluxes: we receive short-wave radiation (UV and visible light) from the Sun, and emit longwave radiation (infra-red) to space.\n\n\n\nFigure 3.1: Radiation in the atmosphere\n\n\nFirst we consider incoming energy.\n\n\n\n\n\n\nEnergy from the Sun\n\n\n\nFirst, note that the shortwave radiation (UV and radiation) recieved from the sun is \\(Q \\approx 1370 \\text{ W$\\cdot$m$^{-2}$}\\) (which we consider measured at a point near the planet).\nIf we consider only that radiation that is absorbed into the Earth, we have \\[\nE_{\\mathrm{in}} = \\pi R^2 Q (1 - a),\n\\tag{3.2}\\] where \\(R\\) is the Earth’s radius.\nIn the above formula, we have multiplied the flux, \\(Q\\), with the visible surface area, \\(\\pi R^2\\). There is an additional multiplication by \\((1 - a)\\) where \\(a\\) is the planetary albedo, which characterises amount of energy reflected due to the surface properties. Light surfaces like snow will have high albedo, \\(a \\approx 0.9\\), while darker surfaces like the ocean have smaller albedo, \\(a \\approx 0.3\\). The global average albedo is \\(a \\approx 0.3\\).\n\n\nNext we consider outgoing energy.\n\n\n\n\n\n\nEnergy from the Earth\n\n\n\nWe now wish to characterise the energy, \\(E_{out}\\), and in the case of Earth, this will correspond to longwave radiation (infra-red) emitted into space. All bodies characterised by a temperature, say \\(T_e\\), will emit radiation, \\(Q_e\\). As a model, we can consider \\(Q_e\\) to be given by the Stefan-Boltzmann law, which states that \\[\nQ_e = \\sigma T_e^4,\n\\tag{3.3}\\] where \\(\\sigma \\approx 5.67 \\times 10^{-8} W m^{-2} K^{-4}\\) is the Stefan-Boltzmann constant.\nNow although the Earth’s surface may emit radiation according to (Equation 3.3), some of this radiation will be absorbed by the atmosphere and reflected back. This is the greenhouse effect. As a consequence of the greenhouse gas, the surface temperature of the Earth, \\(T\\), will be larger than the effective emitting temperature, \\(T_e\\). For the moment, we model this as \\[\nT_e = \\gamma^{1/4} T_e,\n\\tag{3.4}\\] where \\(\\gamma < 1\\) is a greenhouse gas factor, which depends on the properties of the atmosphere.\n\n\nNow combining the above equations, we have \\[\nE_{\\mathrm{in}} - E_{\\mathrm{out}} = \\pi R^2 Q (1 - a) - 4\\pi R^2 \\sigma \\gamma T^4,\n\\tag{3.5}\\] which gives the incoming energy per unit time.\n\n\n\n\n\n\nInternal heat energy\n\n\n\nDue to this incoming energy, the Earth will cool or heat in response. We need to know how the internal temperature of an object responds to an input in energy. The general formula is \\[\n\\text{Internal heat energy} = \\text{volume} \\times (\\rho c_p) \\times T.\n\\] The key quantity is the experimentally determined, \\(c_p\\), which corresponds to the specific heat capacity. It is given in the SI units of \\(\\mathrm{J} \\cdot \\mathrm{kg}^{-1} \\cdot \\mathrm{K}^{-1}\\), i.e. energy per unit mass per unit temperature. Note that this applied to a shell around the planet of thickness \\(d\\) in the atmosphere, and so the mass is given by \\[\n\\text{mass} = (4 \\pi R^2) d \\rho\n\\tag{3.6}\\] where \\(\\rho\\) is the average density of the atmosphere. Let us imagine the increase in temperature, \\(\\Delta T\\),during an interval of time, \\(\\Delta t\\). You can now verify that \\[\n\\Bigl[ (4 \\pi R^2) d \\rho \\Bigr] c_p (\\Delta T)\n\\] returns the units of Joules—i.e. this is the internal energy produced during the time \\(\\Delta t\\). We then have \\[\n\\Bigl[ (4 \\pi R^2) d \\rho \\Bigr] c_p \\Delta T =  \\Delta t (E_{in} - E_{out}).\n\\] Putting in (Equation 3.5) and taking the limit of \\(\\Delta t \\to 0\\), we finally have a heat equation for the Earth’s temperature given by the following ordinary differential equation (ODE) for \\(T = T(t)\\),\n\\[\nc \\frac{\\mathrm{d}T}{\\mathrm{d}t} = \\frac{1}{4} Q(1 - a) - \\sigma \\gamma T^4,\n\\tag{3.7}\\] where we have defined \\(c = \\rho c_p d\\) as the heat capacity of the atmosphere.\n\n\nThe above equation Equation 3.7 is time-dependent, but we may consider that the surface temperature, either over long-time or in an averaged sense, is dictated by the steady-state (time-independent) solution. Setting \\(\\mathrm{d}T/\\mathrm{d}t\\) to zero, we see that there is a unique steady-state given by \\[\nT = \\left(\\frac{Q(1-a)}{4\\sigma\\gamma}\\right)^{1/4}.\n\\]\nIf we take \\(Q \\approx 1370 \\,\\mathrm{W m}^{-2}\\), \\(a \\approx 0.3\\), \\(\\sigma \\approx 5.67 \\times 10^{-8} \\mathrm{W} \\,\\mathrm{m}^{-2} \\mathrm{K}^{-4}\\), we then get \\[\nT \\approx 255 \\mathrm{K} = -18^\\circ \\mathrm{C}.\n\\] under the assumption that \\(\\gamma = 1\\). That’s pretty cold! The actual average temperature is around \\(288 \\mathrm{K} \\approx 15 ^\\circ \\mathrm{C}\\).\nThe above back-of-the-envelope calculation seems to suggest that the parameter \\(\\gamma < 1\\) plays an important role in keeping the Earth warm enough for us to live on, and indeed the value of \\(\\gamma\\) inferred by the above is roughly \\(\\gamma \\approx 0.61\\). Later on in the course, we will develop a more rigorous model to predict such a \\(\\gamma\\) by studying the properties of the atmosphere."
  },
  {
    "objectID": "part-01-intro/basic-energy-model.html#the-history-of-global-warming",
    "href": "part-01-intro/basic-energy-model.html#the-history-of-global-warming",
    "title": "3  Basic energy models",
    "section": "3.2 The history of global warming",
    "text": "3.2 The history of global warming\nThe history of global warming (and hence the estimation of \\(\\gamma\\)) is convoluted, but the origins can be considered as far back as the work of (Fourier 1827) and (Pouillet 1838), and is discussed in the work by (Van der Veen 2000).\n\n\n\nFigure 3.2: An illustration of Fourier’s glass box\n\n\n\n\n\n\nFourier, Joseph. 1827. “Mémoire Sur Les Températures Du Globe Terrestre Et Des Espaces Planétaires.” Mémoires de l’Académie Royale Des Sciences de l’Institut de France 7: 570–604.\n\n\nPouillet, Claude Servais Mathias. 1838. “Memoire Sur Le Chaleur Solaire.” Paris.\n\n\nVan der Veen, CJ. 2000. “Fourier and the ‘Greenhouse Effect’.” Polar Geography 24 (2): 132–52."
  },
  {
    "objectID": "part-01-intro/problemclass01.html#projectile-motion",
    "href": "part-01-intro/problemclass01.html#projectile-motion",
    "title": "4  Problem class 1",
    "section": "4.1 Projectile motion",
    "text": "4.1 Projectile motion\nA projectile of mass \\(M\\) (in kg) is launched vertically with initial velocity \\(V_0\\) (in m/s) from a position \\(Y_0\\) (in m) above the surface. Thus the mass’s position, \\(Y(t)\\) is governed by Newton’s second law (applied to the mass and the mass of the Earth) and the set of equations \\[\\begin{gather}\nM Y_{tt} = - \\frac{g R_E^2 M}{(R_E + Y)^2}, \\\\\nY(0) = Y_0,\n\\end{gather}\\] where \\(g = 9.81 m/s^2\\) and \\(R_E = 6.4 \\times 10^6 m\\) is the radius of the Earth.\n\nNon-dimensionalise the equation using arbitary length and time scales.\nIdentify the non-dimensional constants, \\(\\Pi_i\\).\nChoose a length scale of \\(L = Y_0\\) and time scale of \\(T = (L/g)^{1/2}\\). Discuss the resultant equation and the interpretation of choosing these scales.\nDoes your above choice allow you to easily study the limit of \\(R_E \\to \\infty\\)? If the limit can be taken, reduce the governing system to a simpler equation.\nDoes your choice in 3. allow you to easily study the limit of \\(Y_0 \\to 0\\)? If not, choose an alternative choice of length and time scales and in that case, reduce the set of equations."
  },
  {
    "objectID": "part-01-intro/problemclass01.html#terminal-velocity",
    "href": "part-01-intro/problemclass01.html#terminal-velocity",
    "title": "4  Problem class 1",
    "section": "4.2 Terminal velocity",
    "text": "4.2 Terminal velocity\nA ball of radius \\(R\\) (in m) and uniform density \\(\\rho\\) (in kg/m3) falls in a viscous fluid. The fluid has density \\(\\rho_f\\) (in kg/m3) and viscosity (a measure of friction or resistance) \\(\\mu\\) (in kg/(m s)). The equation that governs the velocity is \\[\\begin{gather}\n\\frac{4}{3} \\pi R^3 \\rho \\frac{\\mathrm{d}V}{\\mathrm{d}t} = \\frac{4}{3} \\pi R^3 (\\rho - \\rho_f) g - 6\\pi \\mu R V, \\\\\nV(0) = V_0.\n\\end{gather}\\]\n\nChoose appropriate velocity and time scales to non-dimensionalise the equation so as to leave only a single non-dimensional number on the drag term (the last term on the right hand-side).\nDefine the non-dimensional parameter expressing a ratio between drag force and gravity force by the Stokes number (St) and confirm that it is \\[\nSt = \\frac{9\\mu V_0}{2(\\rho - \\rho_f) g R^3}.\n\\]\nComment on the two limits of \\(St \\to 0\\) and \\(St \\to \\infty\\). Can the problem be reduced in these two limits? If so, reduce and solve."
  },
  {
    "objectID": "part-02-energy/part-energy.html",
    "href": "part-02-energy/part-energy.html",
    "title": "Energy usage and energy sources",
    "section": "",
    "text": "The first part of this course is centred upon a seminal book by Cambridge physicist David MacKay (MacKay 2009) that was written a number of years ago.\n\n\n\nFigure 1: Cover of MacKay’s book\n\n\nUnlike many other books and discussions on the topic of energy, this one is written with the emphasis placed on developing simple back-of-the-envelope estimates of usage. This is a great philosophy, and one that does well to cut straight to the heart of more long-winded discussions.\nMacKay’s book was published with an open license, and can be freely downloaded at https://www.withouthotair.com/.\n\n\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-02-energy/mackay-energy.html#the-industrial-revolution-and-its-effects",
    "href": "part-02-energy/mackay-energy.html#the-industrial-revolution-and-its-effects",
    "title": "5  The CO2 concentration",
    "section": "5.1 The Industrial Revolution and its effects",
    "text": "5.1 The Industrial Revolution and its effects\nIn his book, MacKay offers the following graph of carbon dioxide (CO2) concentration.\n\n\n\nFigure 5.1: Upper graph showing carbon dioxide concentrations (in parts per million). The middle graph shows the history of UK coal production, Saudi oil production, world oil production, and total of all greenhouse gas emissions (shown circled). The bottom graph shows the similar trends as associated with the industrial revolution. Note scales of last two graphs are logarithmic.\n\n\nIt is remarked that the sudden rise of CO2 concentration is attributed to the industrial revolution, with a key event being the invention of the steam engine in 1769. Correlations between the rise and other key industries can also be established, including correlations with population increase, the growth of British ships and pig-iron production, and oil and coal production.\nSo in a nutshell, Mackay quite strongly argues that the significant rises in measured CO2 are the result of human influence and notably the downstream effects of the Industrial Revolution.\n\n\n\n\n\n\nNote\n\n\n\nMackay notes that in the various visualisations and explanations, greenhouse gases include carbon dioxide, methane, nitrous oxide, but Mackay expresses emissions in “equivalent amounts of CO2” where equivalent means having the same warming effect over a hundred years."
  },
  {
    "objectID": "part-02-energy/mackay-energy.html#doubling-of-co2",
    "href": "part-02-energy/mackay-energy.html#doubling-of-co2",
    "title": "5  The CO2 concentration",
    "section": "5.2 Doubling of CO2",
    "text": "5.2 Doubling of CO2\nWhat happens if CO2 concentration is doubled? This is one of the key questions that McKay discusses. Models seem to indicate that a doubling of CO2 would have the same effect as increasing the intensity of the sun by 2% and global temperatures rising by 3\\(^\\circ\\)C. Mackay notes (p. 10) that\nThis is what historians call a Bad Thing. I won’t recite the whole litany of probable drastic effects, as I am sure you’ve heard it before. The litany begins “the Greenland icecap would gradually melt, and, over a period of a few 100 years, sea-level would rise by about 7 metres.” The brunt of the litany falls on future generations. Such temperatures have not been seen on earth for at least 100 000 years, and it’s conceivable that the ecosystem would be so significantly altered that the earth would stop supplying some of the goods and services that we currently take for granted.\nThere is an excellent scientific paper by (Charney et al. 1979) that is cited by Mackay in footnote 10 on p.20, and which you should be able to find in the extended references of your Moodle page. This is a very readable scientific paper that summarises the current state-of-the art in simulations from 1979—which is still largely valid today. The authors of the review essentially conclude two facts.\n\nDoubling atmospheric CO2 would change net heating of the troposphere, oceans, and land by an average power per unit area of roughly 4W/m^2. Since the average power absorbed by the atmosphere, land, and oceans is approximately 238 W/m^2, then this would be equivalent to increasing the sun’s intensity by about 1.7%.\nThe effect of global temperatures is more difficult, since this involves some complex simulations. However, the current simulations seem to predict an increase of between 2\\(^\\circ\\)C and 3.5\\(^\\circ\\)C.\n\n\n\n\n\n\n\nNote\n\n\n\nIt is possible to develop a back-of-the-envelope calculation to estimate the rise in temperature via doubling of CO2 and this was done as early as 1896 by Arrhenius(!) (Arrhenius 1896)"
  },
  {
    "objectID": "part-02-energy/mackay-energy.html#who-should-fix-it",
    "href": "part-02-energy/mackay-energy.html#who-should-fix-it",
    "title": "5  The CO2 concentration",
    "section": "5.3 Who should fix it?",
    "text": "5.3 Who should fix it?\nSo to whom does the responsibility lie to fix the issue? There are different visualisations possible in order to make this argument. For example, one can examine estimates of the rate of GG poulation per population (tons of CO2 emissions per year per person). This would tell you who are the current biggest offenders.\nHowever, an alternative viewpoint is that the responsible party should be the party who was the largest polluter in time (i.e. find each country’s total historical footprint and divide by the populace). This produces the following graph.\n\n\n\nFigure 5.2: A graph of the average pollution rate vs. the population\n\n\nNote that the units of the vertical axis are given as tons of CO2 per year per person.\nSo how much do we need to reduce in order to “guarantee” global temperatues do not rise more than 2\\(^\\circ\\)C? At the end of the chapter, Mackay summarises the situations as follows. The plans require global emissions to fall by 70% or 85% by 2050. In the UK, for instance, 11 tons of CO2/y.p would need to be changed to 1.1 tons of CO2/y.p.\n\n\n\n\n\n\nImportant\n\n\n\n“This [the necessary reduction of carbon footprint per person] is such a deep cut, I suggesst the best way to think about it is no more fossil fuels”.\n\n\n\n\n\n\nArrhenius, Svante. 1896. “XXXI. On the Influence of Carbonic Acid in the Air Upon the Temperature of the Ground.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 41 (251): 237–76.\n\n\nCharney, Jule G, Akio Arakawa, D James Baker, Bert Bolin, Robert E Dickinson, Richard M Goody, Cecil E Leith, Henry M Stommel, and Carl I Wunsch. 1979. Carbon Dioxide and Climate: A Scientific Assessment. National Academy of Sciences, Washington, DC.\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-02-energy/mackay-units.html#units",
    "href": "part-02-energy/mackay-units.html#units",
    "title": "6  Units and physics",
    "section": "6.1 Units",
    "text": "6.1 Units\n\nDefinition 6.1 (Unit of energy) The SI unit of energy is a Joule (J). In discussing usage, however, we will often use the kilowatt-hour (kWh).\n\n\nDefinition 6.2 (Unit of power) The SI unit of power is a Watt (W), equivalent to 1 J/s. Thus 1 kW of power is 1000 J/s. Power can also be measured in kWh per day.\n\nSo based on the above, let us unpack one unit of energy (kWh) in terms of Joules.\n\\[\n[E] = 1\\mathrm{kWh} = (10^3 \\mathrm{J/s}) \\times \\left(3.6 \\cdot 10^3 \\frac{\\mathrm{s}}{\\mathrm{hr}}\\right) \\cdot 1 \\mathrm{hr} = 3.6 \\cdot 10^6 \\mathrm{J}.\n\\]\n\n\n\n\n\n\nNote\n\n\n\nOne 40W lightbulb left on for a day uses about 1 kWh via the following argument.\n\\[\n40 \\mathrm{W} \\cdot 1 \\mathrm{day} = 40 \\cdot 10^{-3} \\mathrm{kW} \\cdot 24 \\mathrm{hours} = 0.96 \\mathrm{kWh}.\n\\]\n\n\nSo to repeat, for measurement of electricity, the unit we will often use is the kWh, and 1 kWh is approximately the energy required to light a (40W) lightbulb for an entire day. Given the importance of understanding your energy bills, thinking in terms of those quantities will help you remember. See below note.\n\n\n\n\n\n\nNote\n\n\n\nExamining the current Shell Energy tarifs as of mid October 2022, the unit rate of electricity is 21.6p/kWh and the unit rate of gas is 4.2p/kWh. This is about double the figures quoted in (MacKay 2009)!\n\n\n\nDefinition 6.3 (Kilo, mega, giga, tera) Kilo means a multiplier of \\(10^3\\). Similarly, Mega is a multiplier of \\(10^6\\), Giga a multiplier of \\(10^9\\), and Tera a multipier of \\(10^{12}\\)."
  },
  {
    "objectID": "part-02-energy/mackay-units.html#energy-equivalences",
    "href": "part-02-energy/mackay-units.html#energy-equivalences",
    "title": "6  Units and physics",
    "section": "6.2 Energy equivalences",
    "text": "6.2 Energy equivalences\nAs the fundamental law of thermodynamics goes, energy cannot be created nor destroyed. However, not all energies are equivalent because there are penalties and efficiencies when one converts from one energy type to another (in terms of usable energy). For example:\n\nA fossil fuel plant will convert from chemical energy to electrical energy at an efficiency of about 40%.\nAn aluminium plant will convert from elecrical energy to manufacture aluminium (and hence chemical energy) at an efficiency of about 30%.\n\nBecause of the above, in common usage, some tables of energy usage will include the conversion factors while others will not. For example, consider a power station that converts 2.5 kWh of oil into 1 kWh of electrical energy (an efficiency of 40%). We might then write \\[\nE_\\mathrm{electrical} = E_\\mathrm{oil} \\cdot 0.4\n\\] but the above is a confusing statement if you assume that there is a single intrinsic notion of energy, \\(E\\). Do we set \\(E = E_\\mathrm{oil}\\) or \\(E = E_\\mathrm{electrical}\\)?. If this further confuses you, ask the following question: what does \\(E_\\mathrm{oil}\\) mean if one does not consider a conversion process?\nIn order to avoid this confusion, MacKay uses (p. 27) the convention of treating energy values as equivalent, i.e. 1 kWh of chemical energy is the same as 1 kWh of electrical energy.\n\n\n\n\n\n\nNote\n\n\n\nAs MacKay notes (p. 27) the above assumption is not the same as assuming that all energy can be converted to one and the other without loss.\n\n\n\n\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#tips-for-estimates",
    "href": "part-02-energy/mackay-consumption.html#tips-for-estimates",
    "title": "7  Estimating consumption",
    "section": "7.1 Tips for estimates",
    "text": "7.1 Tips for estimates\n\nUse appropriate conversion of units.\n\nFor example, even though you may not know what specific heat means (see below question about the bath hot water usage), examining the units of Joules/(Litre x Celcius) should tell you that this quantity corresponds to energy per unit volume per unit degree Celcius. Specific heat is a quantity associated with certain materials that describe the energy requred to increase its volume by one degree.\n\nManipulate different forms of energy\n\nAn object of mass \\(m\\) moving at speed \\(v\\) possesses kinetic energy given by \\[\nE_\\mathrm{kinetic} = \\frac{1}{2} mv^2.\n\\] An object can also possess different kinds of potential energy. For example, an object of mass \\(m\\) that will fall when released possesses gravitational potential energy given by \\[\nE_\\rm{grav. potential} = mgh\n\\] where \\(h\\) is its distance relative to some given point and \\(g = 9.8 \\, \\mathrm{m/s^2}\\) is the standard gravitational constant on the surface.\nA hot object also possesses heat energy. The heat energy is given by \\[\nE_\\mathrm{heat} = c \\rho V T\n\\] where \\(c\\) is the specific heat capacity, \\(\\rho\\) is the density, \\(V\\) is the volume, and \\(T\\) is the temperature. An object can also possess chemical potential energy (for example, we possess such energy when we eat food). And so forth and so on.\n\n\n\n\n\n\nChecking energies\n\n\n\nIt is a good idea to check that all the above units make sense and the right hand-sides return the expected unit of energy."
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#heating-and-cooling",
    "href": "part-02-energy/mackay-consumption.html#heating-and-cooling",
    "title": "7  Estimating consumption",
    "section": "7.2 Heating and cooling",
    "text": "7.2 Heating and cooling\nWe would like to develop estimates of energy usage in heating and cooling.\n\n\n\n\n\n\nEnergy in a hot bath\n\n\n\nTo compute the heat energy in taking a hot bath, we take the specific heat capacity of water, \\(c = 4200 \\, \\mathrm{J}/(\\mathrm{L} \\, ^{\\circ}\\mathrm{C})\\). This multiplies the volume of a bath (50 cm x 15 cm x 150 cm), and the temperature of water minus the temperature of ambient water, estimated at \\(40^\\circ\\mathrm{C}\\). This gives \\[\nE_\\mathrm{hot bath} \\approx (4200 \\times 110 \\times 40) \\mathrm{J} \\approx 18 \\, \\mathrm{MJ} \\approx 5 \\, \\mathrm{kWh}.\n\\]\n\n\n\n\n\n\n\n\nEnergy in appliances\n\n\n\nFor example, consider a kettle with a voltage of \\(V = 230V\\) and a max amperage of \\(I = 13A\\). Voltage measures the potential difference of electricity, and amperage measures the current. If you multiply the two together, \\(VI = P\\), you get power, \\(P\\). So this kettle has power \\(P = 3\\mathrm{kW}\\).\nTo estimate usage, we must estimate how often the kettle is used and for how long. Considering 20 minutes per household of two people, this then requires \\[\nE_\\mathrm{kettle} \\approx (3 \\mathrm{kW}) \\times \\left(20 \\, \\mathrm{min} \\times \\frac{\\mathrm{hrs}}{60\\mathrm{min}}\\right) = 1 \\mathrm{kWh}.\n\\]\nYou may also be interested in MacKay’s estimates for microwave ovens (0.5 kWh/day), regular ovens (1.5 kWh/day), and clothes washers (1 kWh/day).\n\n\nFollowing (MacKay 2009), you can also follow similar estimates of using space heaters, refrigerators, and air conditioners.\n\n\n\n\n\n\nHot air and cooling\n\n\n\nMackay develops the following estimates of energy usage (per day per person). Considering space heaters run during the colder months, he develops\n\\[\nE_\\text{hot air} \\approx 24\\,\\text{kWh}.\n\\] while considering the refrigerator and air condition usage, he approximates \\[\nE_\\text{heat + cooling} \\approx 1.5 \\, \\mathrm{kWh}.\n\\]\n\n\nNote that the above estimates are for average domestic consumption, and hence this does not include the significant energy usages of the service and workplace industries. The total estimate from this chapter is as follows.\n\n\n\n\n\n\nTotal heating and cooling estimate\n\n\n\nMacKay estimates (p. 53) that the total energy one (domestic) person spends on heating and cooling, including home, workplace, and cooking, is 37 kWh per day per person (12 for hot water, 24 for hot air, and 1 for cooling). He notes that this seems to be close to the typical figures quoted (45 kWh/d per person) if you make use of some national tables (and some liberties—like using the University of Cambridge’s energy estimates)."
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#energy-usage-of-stuff",
    "href": "part-02-energy/mackay-consumption.html#energy-usage-of-stuff",
    "title": "7  Estimating consumption",
    "section": "7.3 Energy usage of stuff",
    "text": "7.3 Energy usage of stuff\nA significant amount of energy is expended on:\n\nproduction of raw materials\nproduction on stuff and transportation of such\nuse of stuff\ndisposal and recycling of stuff\n\n\n\n\n\n\n\nEnergy usage in a soda addict\n\n\n\nConsider someone who has a coca-cola addiction and drinks five cans of coke a day. What is their energy usage in this regard? On the assumption that the raw aluminium material phase dominates (production of metals is intensive), MacKay notes that one can needs about 0.6kWh of energy. Thus \\[\nE_\\text{coke} \\approx 5 \\times 0.6 \\, \\mathrm{kWh} = 3 \\, \\mathrm{kWh}\n\\] as the per day per person figure."
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#energy-usage-of-transportation",
    "href": "part-02-energy/mackay-consumption.html#energy-usage-of-transportation",
    "title": "7  Estimating consumption",
    "section": "7.4 Energy usage of transportation",
    "text": "7.4 Energy usage of transportation\n\n7.4.1 Cars\nMacKay uses some interesting back-of-the-envelope estimates here. First \\[\n\\text{energy per day} = \\frac{\\text{distance travelled per day}}{\\text{distance over unit of fuel}} \\times \\text{energy per unit of fuel}.\n\\]\nWe take about 50km travelled per day, and a typical family car is quoted as 12 km/L.\nIn order to estimate the energy per unit (L) of fuel, MacKay notes that automobile fuel is a hydrocarbon and so we can sensibly use butter as an estimate. A packet of butter informs that it contains a calorific value of about 3000 kJ per 100g. We have that 1 kJ is 1/3600 kWh, so this gives (5/6)*10 ~ 8 kWh per kg. To get energy density in terms of volume, we need to know the density of butter. Water has a density of about 1kg/L (nearly by definition). Since butter floats on water, we might take its density to be 0.9kg/L (this is very close). Together this gives an estimate of about 8*0.9 or 7 kWh/L.\nLooking it up in a random reference, though, gives that petrol has about 10kWh/L.\nThus altogether, this gives an estimate of \\[\n\\text{energy per day} = \\frac{50 \\mathrm{km}}{12 \\mathrm{km/L}} \\times 10 \\mathrm{kWh/L} \\approx 40 \\mathrm{kWh/day}\n\\] so the equivalent of leaving 40 lightbulbs on for an entire day."
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#in-depth",
    "href": "part-02-energy/mackay-consumption.html#in-depth",
    "title": "7  Estimating consumption",
    "section": "7.5 In-depth",
    "text": "7.5 In-depth\nMacKay provides a more in-depth calculation for car transport in the Appendix A.\nThe energy in a fossil-fuel car goes into four main categories.\n\nSpeeding-up and slowing down using the brakes;\nair resistance;\nrolling resistance;\nheat – about 75% of the energy is thrown away as heat\n\n\n7.5.1 Brakes\n\nAssume a car of mass \\(m_c\\) accelerates rapidly to a constant speed, \\(v\\), and maintains this speed for a distance \\(d\\), at which point the driver brakes rapidly to a stop.\nAssume that the kinetic energy is transferred into the brakes. We can estimate \\[\n\\text{Power in brakes} = \\frac{ \\text{kinetic energy}}{ \\text{time between braking events}} = \\frac{\\frac{1}{2}m_c v^2}{(d/v)} = \\frac{1}{2} \\frac{m_c v^3}{d}.\n\\]\n\n\n\n7.5.2 Air resistance\nDrag is the most important aerodynamic force in cars at highway speeds. In order to calculate the exact drag, we would essentially need to integrate forces around the car in a fluid dynamics model. However, drag is usually approximated by the force1, \\[\nF_d = \\frac{1}{2} \\rho C_D A_f v^2,\n\\] where \\(\\rho\\) is the density of air, \\(A_f\\) is the frontal cross-sectional area of the car, and \\(C_D\\) is the drag coefficient, a non-dimensional number that encodes all of the complicated fluid dynamics. Then we know that \\[\n\\text{Power in drag} = \\frac{ \\text{Force . distance}}{ \\text{time between braking}} =  \\frac{1}{2} \\rho C_D A_f v^3.\n\\]\n\n\n7.5.3 Ratio of brake power to drag power\nRecalling our discussion of non-dimensionalisation, we can form a non-dimensional number representing the ratio of the two above powers:\n\\[\n\\Pi = \\frac{\\text{Power in brakes}}{\\text{Power in drag}} = \\frac{m_c}{d(\\rho C_D A_f)}.\n\\] Verify that the units are sensible. Note that when \\(\\Pi > 1\\), then braking effects are more dominant, and if \\(\\Pi < 1\\), then drag effects are more dominant. In order to examine the threshold, set \\(\\Pi = 1\\) and solve for \\(d\\), \\[\nd_{\\text{crit}} = \\frac{m_c}{\\rho C_D A_f}.\n\\]\nWe use the following approximations: \\(m_c = 1000 kg\\), \\(\\rho = 1.3 kg/m^3\\), \\(C_D = 1/3\\), \\(A_f = 3 m^2\\). This gives a critical distance of \\[\nd_{ \\text{crit}} = 750m.\n\\] Therefore, when travelling more than about a 1km, much of your energy expenditure between these two items is largely going into drag, while for less than 1km, more energy is going into your brakes. In order to save energy, you can (i) drive more slowly; (ii) reduce the mass of your car; (iii) get better brakes (regenerative brakes); (iv) reduce your car’s drag coefficient or reduce its cross sectional area.\n\n\n7.5.4 Rolling resistance\nRolling resistance involves the energy consumed in the tyres and bearings of the car, the energy going into the noise of the wheels against the ground, the energy of grinding rubber off the tyres, the energy in the wheel vibrating the ground, etc. The standard model assumes that the rolling resistance force is \\[\nF = C_{rr} m_c g,\n\\] where car rubber tyres are given in MacKay’s book as having a coefficient \\(C_{rr} = 0.01\\). Again, we can compare the threshold where rolling resistance is equal to drag via \\[\nC_{rr} m_c g = \\frac{1}{2} \\rho C_D A_f v^2,\n\\] which gives a critical speed of \\[\nv = \\sqrt{2 \\frac{C_{rr} m_c g}{\\rho C_D A_f}} = 7m/s = 16 mi/hr.\n\\]\n\n\n7.5.5 Power\nNotice that we can then write the total power as \\[\nP = \\sigma \\left( \\mathcal{A} v + \\mathcal{C} v^3\\right),\n\\] where \\(\\sigma\\) is an efficiency parameter that indicates how efficiently chemical energy (petrol) is converted into mechanical energy via the engine and transmission. Much of this is initial energy is ‘lost’ to heat, and MacKay indicates that petrol engines are about 25% efficient. Thus we should set \\(\\sigma = 4\\). Above, note that \\(\\mathcal{A}\\) is then associated with the rolling resistance and \\(\\mathcal{C}\\) to the drag and braking.\nPreviously in Section 7.4.1, we estimated energy consumption of 80 kWh to drive 100km (note this did not take into account any dynamics, i.e. time); this was a straight approximation based on the energy of petrol.\nFrom the table below (most figures taken from MacKay but see the footnotes)\n\n\n\nQuantity\nApproximation\n\n\n\n\n\\(m_c\\)\n1000kg\n\n\n\\(v\\)\n110km/h = 31 m/s\n\n\n\\(d\\)\n10km\n\n\n\\(\\rho\\)\n1.3 kg/m^3\n\n\n\\(C_D A_f\\)2\n0.7 m^2\n\n\n\\(C_{rr}\\)\n0.01\n\n\n\nWe seem to get the following. \\[\\begin{align}\n\\text{Power}_{\\text{brakes}} &\\approx 1500 W \\approx 1.5 kW \\\\\n\\text{Power}_{\\text{air}} &\\approx   13,600 W = 13.6 kW  \\\\\n\\text{Power}_{\\text{rolling}} &\\approx 3000 W = 3 kW.\n\\end{align}\\]\nWe see that by far, the biggest contributor at such speeds is the drag. The above numbers should be multiplied by \\(\\sigma = 4\\). If we ignore all other effects and only consider drag, this gives about 54 kW of power. Hence driving for one hour this is 54 kWh, to be compared with our prior estimate of 80 kWh3.\n\n\n7.5.6 Conclusions and caveats\nSo there are a few interesting conclusions. One conclusion is nicely summarised by this graph, which you can often see in other references.\n\n\n\nFigure 7.1: Car fuel consumption (energy per distance) from p.259 of MacKay\n\n\nThe key, really, is that energy consumption is largely dominated by the cubic term in the power. MacKay, on p.258, compares the relative energetic consumption due to drag of a cyclist versus a car. If we assume their drag-area values are about the same (cyclists are less aerodynamic but occupy less area), a cyclist travelling at 20 km/h versus a car travelling at 100 km/h would have an energy ratio of \\[\n\\frac{\\text{Energy per distance of bike}}{\\text{Energy per distance of car}} \\approx \\left(\\frac{20 }{100}\\right)^2 = 0.04,\n\\] i.e. 4% of the energy consumption of a car.\nThere is one interesting caveat that would have been nice to see more discussion, but there is a commentary on p.260 of MacKay. It is conventional knowledge that cars have a ‘sweet spot’ for fuel consumption, which is often quoted as around the range of 40-60mph4.\n\n\n\nFigure 7.2: Car fuel efficiency versus the approximations developed above\n\n\nIt seems unclear how the above alternative shape is modeled via the back-of-the-envelope estimates. For instance, can be be modeled by considering an efficiency, \\(\\sigma = \\sigma(v)\\), the depends on speed?"
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#references",
    "href": "part-02-energy/mackay-consumption.html#references",
    "title": "7  Estimating consumption",
    "section": "7.6 References",
    "text": "7.6 References\nA good reference on the so-called road load equation\n\n\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-05-techniques/techniques.html",
    "href": "part-05-techniques/techniques.html",
    "title": "Practical applied mathematics",
    "section": "",
    "text": "As we go deeper into formulating the equations that model or govern aspects of Planet Earth, we will quickly come to the realisation that many such equations, even for the simplest minimal models, are not exactly solvable.\nFor example, in Chapter 15 we develop the following “simple” model for the temperature in the ocean: \\[\\begin{align}\n\\frac{\\mathrm{d}x}{\\mathrm{d}t} &= \\delta(1 - x) - |f(x, y)|x, \\\\\n\\frac{\\mathrm{d}y}{\\mathrm{d}t} &= 1 - y - |f(x, y)|y,\n\\end{align}\\] where we have introduced the function, \\[\nf(x, y; R, \\lambda) = \\frac{1}{\\lambda}(Rx - y),\n\\]\nThis is quite a difficult problem! This is essentially a set of two nonlinear differential equations for two unknowns and three parameters. What kind of practical applied mathematics can we apply to study such problems?\nThe intention of this part is to introduce (and in some cases, review) three key concepts:\n\nAsymptotic approximations.\nNumerical solutions of differential equations.\nNumerical solutions of nonlinear equations (Newton’s method)."
  },
  {
    "objectID": "part-05-techniques/asymptotics01.html#a-simple-quadratic",
    "href": "part-05-techniques/asymptotics01.html#a-simple-quadratic",
    "title": "8  Asymptotic approximations",
    "section": "8.1 A simple quadratic",
    "text": "8.1 A simple quadratic\n\n\n\n\n\n\nA singular quadratic\n\n\n\nConsider the solution of \\[\n\\epsilon x^2 + x - 1 = 0,\n\\tag{8.1}\\] where \\(\\epsilon\\) is a fixed and very small positive number, say \\(0.000001\\). Forget that we know how to solve a quadratic equation: is it possible to develop a systematic approximation method?\n\n\nIf \\(\\epsilon = 0\\), then \\(x = 1\\). Moreover, if we substitute \\(x = 1\\) into the equation, then we see that the error is small and proportional to \\(\\epsilon\\). It is natural to seek an approximation in powers of \\(\\epsilon\\). We call this an . We write \\[\nx = x_0 + \\epsilon x_1 + \\epsilon^2 x_2 + \\ldots\n\\] Substitution into the equation yields \\[\n\\epsilon \\Bigl(x_0 + \\epsilon x_1 + \\epsilon^2 x_2 + \\ldots\\Bigr)^2 + \\Bigl( x_0 + \\epsilon x_1 + \\epsilon^2 x_2 + \\ldots \\Bigr) - 1 = 0.\n\\] Expand and collect terms in powers of \\(\\epsilon\\): \\[\n\\Bigl( x_0 - 1 \\Bigr) + \\epsilon\\Bigl(x_1 + x_0^2\\Bigr) + \\epsilon^2\\Bigl(x_2 + 2 x_0 x_1\\Bigr) + \\ldots = 0.\n\\] Now we equate coefficients at each order in \\(\\epsilon\\). This gives \\[\\begin{align}\nx_0 - 1 &= 0 \\Longrightarrow x_0 = 1 \\\\\nx_1 + x_0^2 &= 0 \\Longrightarrow x_1 = -1 \\\\\nx_2 + 2 x_0 x_1 &= 0 \\Longrightarrow x_2 = 2\n\\end{align}\\] We therefore have obtained the three-term approximation, \\[\nx = 1 - \\epsilon + 2\\epsilon^2 + \\ldots\n\\] Clearly we could continue this process ad infinitum obtaining increasingly accurate approximations to one of the roots.\n\n8.1.1 The singular root\nBut where has the other quadratic root gone?\nThe problem is that in considering \\(\\epsilon\\) to be small, we began by ignoring the leading term, \\(\\epsilon x^2\\). We effectively assumed that the equation was primarily balanced by setting the \\(x\\) term with the \\(-1\\) term, and the sum of the two terms approximately equalling zero.\nBut if \\(|x|\\) is large, then clearly our assumption that \\(\\epsilon x^2\\) being small may not be necessarily true for it depends on how large \\(|x|\\) is compared to \\(\\epsilon\\). Note that if \\(|x|\\) is large, then necessarily the last term, \\(-1\\), is negligible in comparison. Therefore, in order for \\(\\epsilon x^2\\) to balance \\(x\\), we see that \\(|x|\\) must be of size \\(1/\\epsilon\\).\nTherefore this suggests that we should re-scale our solution as follows \\[\nx = \\frac{X}{\\epsilon}.\n\\]\nSubstitution into the original quadratic now yields \\[\nX^2 + X - \\epsilon = 0.\n\\] Now notice that \\(\\epsilon = 0\\) expresses the correct balance in order to detect that missing root. Again we write \\[\nX = X_0 + \\epsilon X_1 + \\epsilon^2 X_2 + \\ldots\n\\] and attempt to solve order by order. Substitution into the equation yields \\[\n\\Bigl(X_0 + \\epsilon X_1 + \\epsilon^2 X_2 + \\ldots\\Bigr)^2 + \\Bigl(X_0 + \\epsilon X_1 + \\epsilon^2 X_2 + \\ldots\\Bigr) - \\epsilon = 0.\n\\] Expand and collect orders of \\(\\epsilon\\): \\[\\begin{align}\nX_0^2 + X_0 &= 0 \\Longrightarrow X_0 = -1 \\\\\n2X_0 X_1 + X_1 -1 &= 0 \\Longrightarrow X_0 = -1,\n\\end{align}\\] and thus to two orders, we have \\[\nX = -1 - \\epsilon + \\ldots \\Longrightarrow x = - \\frac{1}{\\epsilon} - 1 + \\ldots\n\\]\nOf course, we have used a very simple example (a solvable quadratic) to illustrate the idea of asymptotic approximations, but you should hopefully see that this method is extensible to much more complicated equations.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nep = np.linspace(1,0.1, 20)\nroot1 = (-1 + np.sqrt(1-4*ep*(-1)))/(2*ep)\nroot2 = (-1 - np.sqrt(1-4*ep*(-1)))/(2*ep)\nasym1 = 1 - ep\nasym2 = -1/ep - 1\nplt.plot(ep, root1, 'o')\nplt.plot(ep, root2, 'o')\nplt.plot(ep, asym1, '-')\nplt.plot(ep, asym2, '-')\nplt.legend(['$x_1$', '$x_2$', '2-term asymp.', '2-term asym'])\nplt.xlabel('$\\epsilon$')\nplt.ylabel('x');"
  },
  {
    "objectID": "part-05-techniques/asymptotics01.html#order-notation-and-the-tilde-sign-for-asymptotic",
    "href": "part-05-techniques/asymptotics01.html#order-notation-and-the-tilde-sign-for-asymptotic",
    "title": "8  Asymptotic approximations",
    "section": "8.2 Order notation and the tilde sign for asymptotic",
    "text": "8.2 Order notation and the tilde sign for asymptotic\nWe define precisely what we mean when we say that two functions, say \\(f\\) and \\(g\\), exhibit the same behaviour in some limit, say \\(\\epsilon \\to 0\\) or \\(x \\to x_0\\) or \\(x \\to \\infty\\) and so forth. For instance, we claim that the graphs of \\(\\sin(x)\\) and \\(x\\) look very similar as \\(x \\to 0\\). Thus we might write \\[\n    \\sin(x) \\sim x \\quad \\text{as $x \\to 0$}.\n\\tag{8.2}\\] This notion of allows us to specify functional behaviours at a deeper level than just limits. As you can see, it is not as useful to specify that \\[\n\\lim_{x \\to 0} \\sin{x} = \\lim_{x\\to 0} x.\n\\] In contrast, (Equation 8.2) is much more prescriptive about the way that the functions are approaching the limit.\n\n\n\n\n\n\nDefinition of \\(\\sim\\), \\(\\gg\\), and \\(\\ll\\)\n\n\n\nFirst, the notation \\[\nf(x) \\ll g(x), \\qquad x \\to x_0,\n\\] is read as “\\(f(x)\\) is much smaller than \\(g(x)\\) as \\(x \\to x_0\\)” and means \\[\n\\lim_{x\\to x_0} \\frac{f(x)}{g(x)} = 0.  \n\\] We may analogously use \\(g(x) \\gg f(x)\\) for “much greater than”.\nSecond, the notation \\[\nf(x) \\sim g(x), \\qquad x \\to x_0,\n\\] is read as “\\(f(x)\\) is asymptotic to \\(g(x)\\) as \\(x \\to x_0\\)”, and means that the error between \\(f\\) and \\(g\\) tends to zero as \\(x \\to x_0\\), or \\[\n\\lim_{x\\to x_0} \\frac{f(x)}{g(x)} = 1.  \n\\] We will often say “\\(f\\) is like \\(g\\)” or “\\(f\\) behaves like \\(g\\)”,\n\n\nHere are some examples.\n\n\n\n\n\n\nExamples\n\n\n\n\n\\(\\sin x \\sim x \\sim \\tan x\\) as \\(x \\to 0\\)\n\\(x^2 + x + 1 \\sim \\dfrac{x^3 + \\sin x}{1 + x}\\) as \\(x \\to \\infty\\)\n\\(\\sin x \\ll \\cos x\\) as \\(x \\to 0\\)\n\n\n\nIn the examination of limiting processes, often the main issue of consideration is the relative sizes of quantities defined according to their powers. For example, if \\(x\\) is a very small number, with \\(x = 10^{-5}\\), then \\(x^5\\) is much smaller than \\(x\\) (in terms of our notation, \\(x^5 \\ll x\\) as \\(x \\to 0\\)). On the other hand, we might not care so much about the difference between \\[\nx^5 \\quad \\text{vs.} \\quad 5 x^5\n\\] The point is that the of \\(x^5\\) and \\(5 x^5\\) is the same as \\(x \\to 0\\). The “Big-Oh” notation formalises this distinction.\n\n\n\n\n\n\nDefinition of Big-Oh\n\n\n\nWe write \\(f = O(g)\\) as \\(x \\to x_0\\) to mean that there exists constants \\(K > 0\\) and \\(x^* > 0\\) such that \\[\n|f| < K |g| \\quad \\text{for all $|x - x_0| < x^*$}.\n\\]\n\n\nIn practice, the use of the order symbol is very natural and you will not need to work with the technical definition. For example, when you derive the terms of the Maclaurin/Taylor series, you are naturally clustering all the terms of the same order (power) together. For us, the \\(O\\) symbol provides a very convenient way of separating terms of different sizes.\n\n\n\n\n\n\nExamples\n\n\n\n\n\\(2\\sin x = O(\\tan x)\\) as \\(x \\to 0\\)\n\\(x^2 + x + 1 = O\\left(\\dfrac{5x^3 + \\sin x}{1 + x}\\right)\\) as \\(x \\to \\infty\\)\n\n\n\nLet us return to the case of the quadratic example (Equation 8.1). Using the O notation, we can write \\[\nx =\n\\begin{cases}\n1 - \\epsilon + 2 \\epsilon^2 + O(\\epsilon^3) \\\\\n-\\frac{1}{\\epsilon} - 1 + O(\\epsilon^2)\n\\end{cases}\n\\] for the two roots. Alternatively, we can truncate the expansions and simply using the \\(\\sim\\) symbol: \\[\nx \\sim\n\\begin{cases}\n1 - \\epsilon  \\\\\n-\\frac{1}{\\epsilon} - 1\n\\end{cases}\n\\]"
  },
  {
    "objectID": "part-05-techniques/asymptotics02.html#returning-to-the-projectile-problem",
    "href": "part-05-techniques/asymptotics02.html#returning-to-the-projectile-problem",
    "title": "9  Asymptotic approximations of ODEs",
    "section": "9.1 Returning to the projectile problem",
    "text": "9.1 Returning to the projectile problem\nIn Chapter 4 and Chapter 26 you studied the non-dimensionalisation of the projectile problem. Once re-scaled, it takes the following form: \\[\n\\begin{align}  \n\\frac{\\mathrm{d}^2 y}{\\mathrm{d}t^2} &= -\\frac{1}{(1 + \\epsilon y)^2}, \\qquad t > 0 \\\\\ny(0) &= 0, \\\\\ny'(0) &= 1.\n\\end{align}\n\\tag{9.1}\\] This is a difficult problem without, in fact, any explicit solutions. However, we can estimate the solution in the limit \\(\\epsilon \\to 0\\). We expand the solution as \\[\ny(t) = y_0(t) + \\epsilon y_1(t) + \\epsilon^2 y_2(t) + \\ldots\n\\] In order to expand the denominator, you can use Taylor’s theorem to expand the function \\[\nf(x) = (1 + x)^\\alpha = f(0) + f'(0)x + \\ldots = 1 + \\alpha x + \\ldots\n\\] around \\(x = 0\\).\nThe differential equation now yields \\[\ny_0'' + \\epsilon y_1'' + \\epsilon^2 y_2'' + \\ldots = -\\left[1 - 2\\epsilon \\left(y_0 + \\epsilon y_1 + \\ldots\\right) + \\ldots \\right]\n\\] so grouping terms together order-by-order yields \\[\n\\Bigl[ y_0'' + 1 \\Bigr] + \\epsilon \\Bigl[ y_1'' - 2y_0\\Bigr] + \\ldots = 0.\n\\]\nWe can similarly substitute the expansion into the initial conditions. Altogether, at leading order, we obtain the following system to solve: \\[\\begin{align}\ny_0'' + 1 &= 0, \\\\\ny_0(0) &= 0, \\\\\ny_0'(0) &= 1.\n\\end{align}\\] Integrating twice and applying the boundary conditions gives us \\[\ny_0(t) = -\\frac{1}{2}t^2 + t.\n\\] In fact, this is simply the parabolic motion you would expect from school Physics. The \\(\\epsilon = 0\\) solution corresponds to assuming that the mass at the centre of the planet is dominant and then acceleration is constant.\nHowever, we can now proceed to higher order and examine the nonlinear effects. Proceeding to \\(O(\\epsilon)\\), we have the following system to solve: \\[\\begin{align}\ny_1'' &= 2y_0, \\\\\ny_1(0) &= 0, \\\\\ny_1'(0) &= 0.\n\\end{align}\\] Again this is simple to integrate. Integrating the solution for \\(y_0\\) twice and substitution of the initial conditions yields \\[\ny_1(t) = -\\frac{1}{12}t^4 + \\frac{1}{3}t^3.\n\\] We have thus solved for the asymptotic approximation to two orders. We have \\[\ny(t) \\sim \\Bigl[ -\\frac{1}{2}t^2 + t\\Bigr] + \\epsilon \\Bigl[ -\\frac{1}{12}t^4 + \\frac{1}{3}t^3\\Bigr].\n\\] This was quite an accomplishment! We have taken a problem that was not easily solvable in explicit form and through fairly simple integrations, obtained an approximation to two orders in \\(\\epsilon\\). How good is it? Let us solve the problem numerically and compare with the asymptotic approximation."
  },
  {
    "objectID": "part-05-techniques/asymptotics02.html#numerical-solutions-of-ivps",
    "href": "part-05-techniques/asymptotics02.html#numerical-solutions-of-ivps",
    "title": "9  Asymptotic approximations of ODEs",
    "section": "9.2 Numerical solutions of IVPs",
    "text": "9.2 Numerical solutions of IVPs\nWe first demonstrate how to solve ODEs (initial-value-problems, IVPs) using black-box functions in Python. For starters, most numerical formulations for ODEs will require that the problem be posed in terms of a first-order system of equations. To convert (Equation 9.1) into such a form, create a set of unknowns for the derivatives. Set \\[\n\\mathbf{Y}(t) =\n\\begin{pmatrix}\ny_1(t) \\\\\ny_2(t)\n\\end{pmatrix}\n= \\begin{pmatrix}\ny(t) \\\\\ny'(t)\n\\end{pmatrix}\n\\]\nThen we have the following first-order system: \\[\n\\begin{align}\n\\mathbf{Y}'(t) &= \\mathbf{F}(t, \\mathbf{Y}(t)) = \\begin{pmatrix}\ny_1' \\\\\n- \\frac{1}{(1 + \\epsilon y_1)^2}\n\\end{pmatrix} \\\\\n\\mathbf{Y}(0) &= \\begin{pmatrix}\n0 \\\\\n1\n\\end{pmatrix}\n\\end{align}\n\\tag{9.2}\\]\nYou can find a little guide on using solve_ivp in Python here. Here is the Python code to solve the differential equation.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import solve_ivp\n\nep = 0.2 # epsilon value\ntmax = 2 # max time\nt = np.linspace(0, tmax, 100) # mesh used for plotting\n\n# Define function for the ODE\ndef f(t, Y):\n    ep = 0.2\n    y, yp = Y\n    ypp = -1/(1 + ep*y)**2\n    return [yp, ypp]\n\n# define the initial condition\nY0 = [0, 1]\n\nsol = solve_ivp(f, [0, tmax], Y0, dense_output=True)\n\n# Prior to plotting, re-interpolate solution on a fine grid\nyy = sol.sol(t)\n# Asymptotic solutions\ny0 = -1/2*t**2 + t\ny1 = -1/12*t**4 + 1/3*t**3\n\n# Plot it all\nplt.plot(t, yy[0,])\nplt.plot(t, y0, '--')\nplt.plot(t, y0 + ep*y1, '--')\nplt.xlabel('t')\nplt.ylabel('y(t)')\n\nText(0, 0.5, 'y(t)')\n\n\n\n\n\nThe two-term approximation does beautifully well, even at this moderate value of \\(\\epsilon = 0.2\\)."
  },
  {
    "objectID": "part-05-techniques/euler.html",
    "href": "part-05-techniques/euler.html",
    "title": "10  Euler’s method",
    "section": "",
    "text": "2022-23 note\n\n\n\nCovered in lectures 8-9.\n\n\nIn the previous section, we used built-in ODE solvers to develop numerical solutions. It is important to gain an understanding how a simple ODE solver works. The simplest scheme is called Euler’s method, and this we now explain.\nBegin from the system (Equation 9.2). We assume that the solution is represented by a discrete set of points, \\(\\mathbf{Y}_n = \\mathbf{Y}(t_n)\\) at the times \\(t_0 = 0\\), \\(t_1 = \\Delta t\\), \\(t_2 = 2\\Delta t\\), and so on. The time derivative is written as a discrete derivative while we approximate the right hand side by its value at the nth time step: \\[\n\\frac{\\mathbf{Y}_{n+1} - \\mathbf{Y}_{n}}{\\Delta t} = \\mathbf{F}(t_n, \\mathbf{Y}_n)\n\\]\nRearranging yields a very simple algorithm for solving the ODE: \\[\n\\mathbf{Y}_{n} = \\mathbf{Y}_{n-1} + \\mathbf{F}(t_{n-1}, \\mathbf{Y}_{n-1}) \\Delta t\n\\] for \\(n = 1, 2, 3, \\ldots\\)\nThis would be implemented via the following pseudocode:\n\n\n\n\n\n\nEuler’s method\n\n\n\n1. Input: function f(t, Y)  \n            time step, dt\n            initial condition, Y0\n\n2. Set initial condition Y = Y0\n\n2. Take one Euler step and overwrite previous value\n\n                 Y = Y + f(t, Y)\n\n3. Increment t by dt and goto 2\n\n\nEuler’s method is conceptually simple but quite inaccurate. But in this case, we see that it works fairly well in comparison to the built-in solvers.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import solve_ivp\n\nep = 0.2            # epsilon value\ntmax = 2            # max time\nN = 20              # number of steps\nt = np.linspace(0, tmax, N) # mesh used for plotting\ndt = t[1] - t[0]\n\n# Define function for the ODE\ndef f(t, Y, ep):\n    y, yp = Y\n    ypp = -1/(1 + ep*y)**2\n    return np.array([yp, ypp])\n\n# define the initial condition\nY = [0.0, 1.0]\nti = 0\n\n# define the solution vector\nfor i in range(1, N):\n    ti = ti + dt  # Increment time\n    Y = Y + f(ti, Y, ep)*dt # Euler step\n    plt.plot(ti, Y[0], 'k.')\n\n# Asymptotic solutions\ny0 = -1/2*t**2 + t\ny1 = -1/12*t**4 + 1/3*t**3\nplt.plot(t, y0, '--')\nplt.plot(t, y0 + ep*y1, '--')\nplt.xlabel('t');\nplt.ylabel('y');"
  },
  {
    "objectID": "part-03-box/part-box.html#physical-vs.-conceptual-vs.-statistical-models",
    "href": "part-03-box/part-box.html#physical-vs.-conceptual-vs.-statistical-models",
    "title": "Box models and dynamical systems",
    "section": "Physical vs. conceptual vs. statistical models",
    "text": "Physical vs. conceptual vs. statistical models\n\n\n\n\n\n\nNewton’s law of cooling and similar linear laws\n\n\n\nIn the following, we will follow some historical developments of physical box models, which often depend on certain assumed linear relationships. It can be very confusing if you want a derivation, via first-principles, of these relationships since often none will exist. This is an important-enough point to explain by analogy.\nConsider an object of temperature \\(T\\) placed in a room with ambient temperature \\(T_a\\). A well-known empirical law for the time-evolution of temperature is given by Newton’s Law of Cooling, i.e.  \\[\n\\frac{\\mathrm{d}T}{\\mathrm{d}t} = -c(T - T_a).\n\\tag{1}\\] The constant \\(c > 0\\) here has units of \\(s^{-1}\\).\nHowever, it is important to understand that the above law is often strictly used without derivation and without justification. It can be interpreted as a one-term Taylor expansion of the heat flux when \\(T - T_a\\) is small but very rarely do people use the expansion under this assumption. There is more discussion of the law and its issues in the work by (Besson 2012) and also in this online discussion.\nI personally think a better way to think of such laws is that they are assumptions that the rate-of-changes are driven by linear gradients."
  },
  {
    "objectID": "part-03-box/part-box.html#pre-requisites",
    "href": "part-03-box/part-box.html#pre-requisites",
    "title": "Box models and dynamical systems",
    "section": "Pre-requisites",
    "text": "Pre-requisites\nBefore covering the next few chapters, we plan to go through a few methods-based prerequisites.\n\nPreliminary asymptotics approximations in Chapter 8;\nSeries expansions and error propagation in …;\nFinite difference approximations in …;\nBisection, Newton’s and Secant methods, Jacobians in …;\n\n\n\n\n\nBesson, Ugo. 2012. “The History of the Cooling Law: When the Search for Simplicity Can Be an Obstacle.” Science & Education 21 (8): 1085–1110."
  },
  {
    "objectID": "part-03-box/box-energy-model.html#steady-state-analysis",
    "href": "part-03-box/box-energy-model.html#steady-state-analysis",
    "title": "13  Steady-states of the basic energy model I",
    "section": "13.1 Steady-state analysis",
    "text": "13.1 Steady-state analysis\nPreviously, we have assumed that the planetary albedo, \\(a\\), is constant and independent of temperature. In actuality, water can turn to snow and ice and vice versa, and since snow and ice have much higher albedo than open water, then we should consider \\(a = a(T)\\).\nWe know that there are two relevant ranges to consider: \\[\na(T) \\approx\n\\begin{cases}\n0.7 & \\mathrm{if }\\, T < 150\\mathrm{K}, \\\\\n0.3 & \\mathrm{if }T > 280\\mathrm{K}.\n\\end{cases}\n\\] Basically, the above guarantees that more energy is reflected if temperatures are low. To model this, we can use a ramp function, \\[\na(T) = A - B \\mathrm{tanh}\\left(k(T - 265)\\right).\n\\tag{13.2}\\] where \\(A = 0.5\\), \\(B = 0.3\\), \\(k = 0.1\\), and \\(T_0 = 265\\).\nUsing parameters from (Kaper and Engler 2013) p.16 and p.17, we can study the steady-state solution, which is given by seeking the zeros of \\[\n\\frac{1}{4}Q[1 - a(T)] = \\sigma \\gamma T^4.\n\\] Note that (Kaper and Engler 2013) use \\(Q = 342\\) but they do not have the initial pre-factor of \\(1/4\\). So we shall use \\(Q = 1370\\) (noting \\(1370/4 = 342.5\\)).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.optimize as sciopt\n\nQ = 1370\nsigma = 5.67e-8 \ngamma = 0.62\n\nTT = np.linspace(220,310,50)\n\ndef fun(T):\n    a = 0.5 - 0.2*np.tanh((T - 265)/10)\n    x = (1-a)*Q/4\n    return x\nLHS = fun(TT)\n\nplt.plot(TT, LHS)\nplt.plot(TT, gamma*sigma*TT**4, 'k--')\n\ndef eq(T):\n    x = fun(T) - gamma*sigma*T**4\n    return x\nT1 = sciopt.fsolve(eq, 230)\nT2 = sciopt.fsolve(eq, 265)\nT3 = sciopt.fsolve(eq, 290)\nprint(\"T1 = {:.2f}\".format(T1[0]))\nprint(\"T2 = {:.2f}\".format(T2[0]))\nprint(\"T3 = {:.2f}\".format(T3[0]))\n\nT1 = 232.63\nT2 = 265.50\nT3 = 286.86\n\n\n\n\n\nTherefore multiple equilibria are observed. You can argue (how?) that the centre equilbria is unstable while the other two are stable. The higher temperature corresponds to the one that the Earth is currently in, but according to this model, there seems to be the possibility of a colder climate (50 degrees colder) where the Earth is entirely covered with snow and ice."
  },
  {
    "objectID": "part-03-box/box-energy-model.html#newton-solver-for-the-steady-states",
    "href": "part-03-box/box-energy-model.html#newton-solver-for-the-steady-states",
    "title": "13  Steady-states of the basic energy model I",
    "section": "13.2 Newton solver for the steady states",
    "text": "13.2 Newton solver for the steady states\nIn the above code, we used the built-in Python codes (fsolve) to solve for the steady-states. It is a good idea to learn (or review, if you have learned it previously) how to design your own solver. An implementation of Newton’s solver is given by the following pseudo-code:\n\n\n\n\n\n\nPseudocode for Newton’s method\n\n\n\n1. input x0, tolerance, maxiterations, f, df\n\n2. repeat while |f(x0)| > tol and iterations < maxiterations\n\n    a. set y0 = f(x0)\n       set yp = df(x0)\n    \n    b. set x1 = x0 - y0/yp\n\n    c. print iter #, x1, and f(x1)\n\n    d. set x0 = x1\n\n\nWe discuss Newton’s method in Chapter 11.\nUsing the simplest Newton code there, we can solve for one of the roots.\n\nimport numpy as np\n\ndef Newton(f, df, x, maxiter=100, tol=1e-12, display=0):\n    i = 0\n    while (abs(f(x) - 0) > tol) and (i < maxiter):\n        err = f(x)\n        x = x - err / df(x)\n        if display == 1:\n            print(\"f(x) = \", np.abs(err), \", x = \", x)\n        i = i + 1\n    return x, err\n\n\nQ = 1370\nsigma = 5.67e-8\ngamma = 0.62\n\na = lambda T: 0.5 - 0.2*np.tanh((T - 265)/10)\nda = lambda T: -0.2*1/np.cosh((T-265)/10)**2/10\n\nf = lambda T: Q/4*(1-a(T)) - sigma*gamma*T**4\ndf = lambda T: -Q/4*da(T) - 4*sigma*gamma*T**3\n\nx = 290\nx, err = Newton(f, df, x, 10, 1e-8, 1)\nprint(\"Final approximation = \", x)\n\nf(x) =  9.804483316627028 , x =  286.98075256805225\nf(x) =  0.36161336669368893 , x =  286.85997144120904\nf(x) =  0.000725960590870045 , x =  286.8597279859311\nFinal approximation =  286.8597279859311\n\n\n\n\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM."
  },
  {
    "objectID": "part-03-box/box-energy-model2.html#poor-persons-numerical-continuation",
    "href": "part-03-box/box-energy-model2.html#poor-persons-numerical-continuation",
    "title": "14  Steady-states of the basic energy model II",
    "section": "14.1 Poor person’s numerical continuation",
    "text": "14.1 Poor person’s numerical continuation\nSuppose that we are interested in studying how the steady-states (up to three) change as \\(Q\\) changes. Then we are interested in producing a diagram of \\(Q\\) vs. \\(T\\). The basic idea is to start with an initial solution at some value of \\(Q\\), increment \\(Q\\), then solve for the next value using the previous value as a guess. This involves the following pseudocode:\n\n\n\n\n\n\nPoor person’s numerical continuation\n\n\n\n1. Input guess T0, f, df, parameter Q1\n\n    a. Call Newton's method via Newton(f, df, T0, Q1) \n    b. Obtain a preliminary solution (T1, Q1)\n\n2. Increment Q1 = Q1 + dQ \n\n    a. Call Newton's method via Newton(f, df, T1, Q1)\n    b. Obtain a new solution (T1, Q1)\n\n3. Repeat 2 until we reach a desired Q value\n\n\nUnfortunately this does not work as well as we would like.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef Newton(f, df, x, maxiter=100, tol=1e-12, display=0):\n    i = 0\n    while (abs(f(x) - 0) > tol) and (i < maxiter):\n        err = f(x)\n        x = x - err / df(x)\n        if display == 1:\n            print(\"f(x) = \", np.abs(err), \", x = \", x)\n        i = i + 1\n    return x, err\n\n\nsigma = 5.67e-8\ngamma = 0.62\na = lambda T: 0.5 - 0.2*np.tanh((T - 265)/10)\nda = lambda T: -0.2*1/np.cosh((T-265)/10)**2/10\n\nQ0 = 1370\nQmat = np.linspace(1000, 1800, 30)\nTmat = 0*Qmat\nx = 220\n\nfor i, Q in enumerate(Qmat):\n    f = lambda T: Q/4*(1-a(T)) - sigma*gamma*T**4\n    df = lambda T: -Q/4*da(T) - 4*sigma*gamma*T**3\n\n    x, err = Newton(f, df, x, 10, 1e-8, 0)\n    if err > 1e-4:\n        print(\"Careful no convergence at Q/Q0 = \", Q/Q0)\n    Tmat[i] = x\n\nplt.plot(Qmat/1370, Tmat);\nplt.xlabel('Q/Q0');\nplt.ylabel('T');\n\nCareful no convergence at Q/Q0 =  1.2131890259249938\nCareful no convergence at Q/Q0 =  1.2735967782532092\nCareful no convergence at Q/Q0 =  1.2937326956959476\nCareful no convergence at Q/Q0 =  1.313868613138686\n\n\n\n\n\nAbove, we have scaled \\(Q\\) with the reference value of \\(Q_0 = 1370\\). The problem is that somewhere within \\(1.2 < Q/Q_0 < 1.3\\), two of the steady-state solutions merge."
  },
  {
    "objectID": "part-03-box/box-energy-model2.html#arclength-continuation",
    "href": "part-03-box/box-energy-model2.html#arclength-continuation",
    "title": "14  Steady-states of the basic energy model II",
    "section": "14.2 Arclength continuation",
    "text": "14.2 Arclength continuation"
  },
  {
    "objectID": "part-03-box/box-energy-model2.html#budyokos-model",
    "href": "part-03-box/box-energy-model2.html#budyokos-model",
    "title": "14  Steady-states of the basic energy model II",
    "section": "14.3 Budyoko’s model",
    "text": "14.3 Budyoko’s model\n(Sec. 2.8 of Kapler & Engler)\nPrevously we used the assumption that the outgoing radiation follows the Stefan-Boltzmann law (Equation 3.3). Based on observational data, there seems to be a simpler linear law, first suggested by Budyko (Budyko 1969). The law can be written as \\[\nE_\\text{out} = A + BT,\n\\tag{14.1}\\] where \\(A\\) and \\(B\\) will vary with location and climate. For instance, for the Northern Hemisphere, (Kaper and Engler 2013) gives the values of \\(A = 203.3\\text{Wm}^{-2}\\) and \\(B = 2.09 \\text{Wm}^{-2}\\text{deg}^{-1}\\) and where temperature is measured in degrees Celcius. One can interpret this as a linear expansion of the Stefan Boltzmann law about \\(T = 0\\) (after which similar values of \\(A\\) and \\(B\\) are derived)."
  },
  {
    "objectID": "part-03-box/box-energy-model2.html#bifurcation-analysis-and-plotting-tools",
    "href": "part-03-box/box-energy-model2.html#bifurcation-analysis-and-plotting-tools",
    "title": "14  Steady-states of the basic energy model II",
    "section": "14.4 Bifurcation analysis and plotting tools",
    "text": "14.4 Bifurcation analysis and plotting tools\n(Sec. 2.8 of (Kaper and Engler 2013))\nThere is an interesting bifurcation analysis that can be done in studying the steady-state solutions when \\(Q/Q_0\\) is varied. Students can be asked to construct the bifurcation diagram of \\(Q/Q_0\\) vs. temperature.\n\n\n\n\nBudyko, Mikhail I. 1969. “The Effect of Solar Radiation Variations on the Climate of the Earth.” Tellus 21 (5): 611–19.\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM."
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#terminology-and-context",
    "href": "part-03-box/basic-ocean-model.html#terminology-and-context",
    "title": "15  Basic models of the ocean",
    "section": "15.1 Terminology and context",
    "text": "15.1 Terminology and context\nThe ocean plays a significant role in regulating the Earth’s climate, as it acts as a massive heat sink and helps to distribute heat and moisture around the planet. In addition, carbon dioxide is water soluble, and through precipitation and wave motion, is transferred into the oceans. Thus the ocean acts as a sink, absorbing large amounts of this greenhouse gas from the atmosphere.\nThe thermohaline circulation (THC), also known as the global ocean conveyor belt, is a complex ocean circulation pattern that is driven by differences in water temperature and salinity. It is an important component of the Earth’s climate system, as it helps to distribute heat and other properties throughout the planet’s oceans.\nThe thermohaline circulation is driven by the sinking of cold, dense water in the polar regions, which then spreads out and flows towards the equator. As the water warms and becomes less dense, it rises to the surface and returns to the poles, creating a continuous loop of ocean currents. The role of salinity in driving the thermohaline circulation is due to the fact that the dissolved salts in seawater increase its density.\nThis circulation pattern has a significant impact on global climate, as it helps to regulate the exchange of heat and other properties between the oceans and the atmosphere. Changes in the thermohaline circulation, such as those caused by global warming, can have far-reaching effects on the planet’s climate and weather patterns.\n\n\n\nFigure 15.1: The thermohaline circulation. In the Atlantic, the circulation carries warm water (red) north near the surface and cold deep water (blue) south. Image from NASA/JPL."
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#temperature",
    "href": "part-03-box/basic-ocean-model.html#temperature",
    "title": "15  Basic models of the ocean",
    "section": "15.2 Temperature",
    "text": "15.2 Temperature\nIn regards to the temperature, the ocean can be divided into three layers.\n\nThe top layer is thin (on the order of metres) and is heated from the Sun. Mixing is a dominant effect due to wind and waves, and so the temperature in this region is mostly constant.\nThe thermocline region is the intermediate layer. Here, the temperature decreaes approximately linearly.\nThe deep abyssal zone comprises 98% of the total volume of the oceans. The temperature in this region is mostly constant, and a few degrees above freezing.\n\nWithin the intermediate region, the temperature can be modelled by an advection diffusion equation, \\[\n\\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}t} + w \\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}z} = \\kappa \\frac{\\mathrm{\\partial}^2 T}{\\mathrm{\\partial}z^2},\n\\tag{15.1}\\] where \\(w\\) is the upswelling velocity and \\(\\kappa\\) is the diffusion coefficient of the fluid.\nLet us assume that the temperature in this region is near steady state and that the upwards velocity is constant. Then we integrate the ODE to find \\[\nT(z) = T_0 + T_1 \\mathrm{e}^{-z/z^*},\n\\] where \\(T_0\\) and \\(T_1\\) are constants. From (Kaper and Engler 2013), the typical orders for the parameters are \\(\\kappa \\sim 10^{-2} \\,\\mathrm{m}^{2} \\,\\mathrm{s}^{-1}\\) and \\(z^* \\sim 10^2 \\, \\mathrm{m}\\), so \\(w \\sim 10^{-4} \\,\\mathrm{m} \\,\\mathrm{s}^{-1}\\), which is quite slow.\n\n\n\nFigure 15.2: Cross section of the Atlantic Ocean, showing the temperature and salinity profiles on the right. Image from (Kaper and Engler 2013)."
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#salinity",
    "href": "part-03-box/basic-ocean-model.html#salinity",
    "title": "15  Basic models of the ocean",
    "section": "15.3 Salinity",
    "text": "15.3 Salinity\nSalinity is a key component in the oceans since the salts have a large effect on the water density (which consequently drives motion). Salinity is measured in psu or practical salinity units, which is a non-dimensional ratio of conductivities. In the mixed layer, the sainity ranges from 31-39 psu, and is about 35 in the abyssal zone. You can inspect the profile in Figure 15.2.\n\n\n\nFigure 15.3: Image from (Kaper and Engler 2013)"
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#two-box-model-of-the-ocean",
    "href": "part-03-box/basic-ocean-model.html#two-box-model-of-the-ocean",
    "title": "15  Basic models of the ocean",
    "section": "15.4 Two-box model of the ocean",
    "text": "15.4 Two-box model of the ocean\nModelling the THC is a challenging task! In principal, this might involve the solution of multiple coupled PDEs for the flows and temperatures, which would then need to be solved on a very complicated domain. In addition, such models require a number of empirical equations of state (connecting density to temperature and salinity).\nToy models can be developed much more easily at the ‘systems level’ via box models."
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#a-one-dimensional-model-constant-temperature",
    "href": "part-03-box/basic-ocean-model.html#a-one-dimensional-model-constant-temperature",
    "title": "15  Basic models of the ocean",
    "section": "15.5 A one-dimensional model (constant temperature)",
    "text": "15.5 A one-dimensional model (constant temperature)\nConstruction and assumptions of the box model.\n\nWe consider two boxes, labeled ‘1’ and ‘2’, respectively via subscripts. Box 1 corresponds to high latitudes (near poles) and Box 2 to low latitudes (near equator). Each box has a corresponding temperature, \\(T_i\\), and salinity, \\(S_i\\).\nWe assume (see above) that the strength of the exchange flow between the boxes is linearly proportional to their differences of temperature and salinity.\nExternal wind forces and Coriolis effects are ignored.\nWe assume that in each box, there is an exchange of heat and salinity to the surrounding environment. For instance, salinity will exchange due to evaporation, precipitation, and runoff.\nWe assume that there is a positive salt flux \\(H\\) into Box 2 and a compensating salt flux \\(-H\\) out of Box 1.\n\nAn image of the box model is shown below.\n\n\n\nFigure 15.4: Two-box model of the North Atlantic with evaporation and precipitation. Image from (Kaper and Engler 2013)\n\n\nThe equations are given as follows.\n\\[\n\\begin{align}\n\\frac{\\mathrm{d}T_1}{\\mathrm{d}t} &= c(T_1^* - T_1) + |q|(T_2 - T_1) \\\\\n\\frac{\\mathrm{d}T_2}{\\mathrm{d}t} &= c(T_2^* - T_2) + |q|(T_1 - T_2) \\\\\n\\frac{\\mathrm{d}S_1}{\\mathrm{d}t} &= -H + d(S_1^* - S_1) + |q|(S_2 - S_1) \\\\\n\\frac{\\mathrm{d}S_2}{\\mathrm{d}t} &= H + d(S_2^* - S_2) + |q|(S_1 - S_2)\n\\end{align}\n\\tag{15.2}\\]\nThe symmetry in the above equations suggests we should re-write the temperature and salinity with respect to averaged values. In particular, notice that if we add the two first equations, we see that the steady-state temperatures satisfy \\[\nT_1 + T_2 = T_1^* + T_2^*,\n\\] and therefore the average temperature in the two ocean regions will tend to the average of the basin regions. A similar conclusion is made for the salinities. It is then sensible to write all temperature and salinity in terms of this baseline scenario. So let us write \\[\\begin{align}\nT_1 &= \\frac{1}{2}m + U_1 \\\\\nT_2 &= \\frac{1}{2}m + U_2\n\\end{align}\\] where \\(m = T_1^* + T_2^*\\). Then the first equation becomes \\[\\begin{align}\n\\frac{\\mathrm{d}U_1}{\\mathrm{d}t} &= c\\left(T_1^* - U_1 - \\frac{1}{2}m\\right) + |q| (U_2 - U_1)\\\\\n&= c\\left(- T^*  - U_1\\right) + |q| (U_2 - U_1).\n\\end{align}\\] where \\(T^* = \\frac{1}{2}(T_2^* - T_1^*)\\).\nThe analgous manipulations are done to the quantities for the salinity. In the end, if we (confusingly) re-write \\(T\\) for \\(U\\), then we obtain \\[\n\\begin{align}\n\\frac{\\mathrm{d}T_1}{\\mathrm{d}t} &= c(-T^* - T_1) + |q|(T_2 - T_1) \\\\\n\\frac{\\mathrm{d}T_2}{\\mathrm{d}t} &= c(T^* - T_2) + |q|(T_1 - T_2) \\\\\n\\frac{\\mathrm{d}S_1}{\\mathrm{d}t} &= -H + d(-S^* - S_1) + |q|(S_2 - S_1) \\\\\n\\frac{\\mathrm{d}S_2}{\\mathrm{d}t} &= H + d(S^* - S_2) + |q|(S_1 - S_2)\n\\end{align}\n\\tag{15.3}\\]\nComparing the above to Equation 15.2, the main difference is that, in expressing the temperature and salinities with respect to the average values in the basin, we have eliminated two of the constants from the set \\((T_1^*, T_1^*, S_1^*, S_2^*)\\) now only into two constants \\((T^*, S^*)\\).\nIn the situation of zero salt flux. \\(H = 0\\), the above model reduces to Stommel’s box model studied in Chapter 16."
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#analysis-of-a-1d-model-for-the-salinity",
    "href": "part-03-box/basic-ocean-model.html#analysis-of-a-1d-model-for-the-salinity",
    "title": "15  Basic models of the ocean",
    "section": "15.6 Analysis of a 1D model for the salinity",
    "text": "15.6 Analysis of a 1D model for the salinity\nWe make the following assumptions\n\nWe assume that on the timescale of interest in the THC, the temperature of each box equilibrates quickly with the surrounding basin.\nThe difference in temperatures between the two boxes is small; together with the top assumption, this implies that \\(T_1(t) = -T^*\\) and \\(T_2(t) = T^*\\).\nSalinity exchanges by negligible amounts with its surrounding basin, i.e. \\(d = 0\\)\n\nThis leaves us with \\[\\begin{align}\n\\frac{\\mathrm{d}S_1}{\\mathrm{d}t} &= -H + |q|(S_2 - S_1) \\\\\n\\frac{\\mathrm{d}S_2}{\\mathrm{d}t} &= H + |q| (S_1 - S_2),\n\\end{align}\\] where \\(q = k(2\\alpha T^* - \\beta(S_2 - S_1))\\).\nNow, the formulation for the salinities can be placed into a single equation for \\(\\Delta S = S_2 - S_1\\), which satisfies \\[\n\\frac{\\mathrm{d}\\Delta S}{\\mathrm{d}t} = 2H - 2k|\\alpha \\Delta T - \\beta \\Delta S| \\Delta S.\n\\]\nFrom here…\n\nNon-dimensionalise\nStudy the equilibrium states and their stability\nDiscuss the tipping phenomena"
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#references",
    "href": "part-03-box/basic-ocean-model.html#references",
    "title": "15  Basic models of the ocean",
    "section": "15.7 References",
    "text": "15.7 References\nThis chapter was largely following Chap. 3 of (Kaper and Engler 2013).\n\n\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM."
  },
  {
    "objectID": "part-03-box/stommel.html#non-dimensionalisation",
    "href": "part-03-box/stommel.html#non-dimensionalisation",
    "title": "16  Stommel’s box model",
    "section": "Non-dimensionalisation",
    "text": "Non-dimensionalisation\nWe can then nondimensionalise the system by setting \\[\nx = \\frac{\\Delta S}{\\Delta S^*}, \\quad y = \\frac{\\Delta T}{\\Delta T^*}, \\quad t' = ct,\n\\] where \\(t'\\) is nondimensional time. Dropping the primes henceforth, we have the following set of non-dimensional equations to study for the unknowns, \\(x = x(t)\\), and \\(y = y(t)\\): \\[\n\\begin{align}\n\\frac{\\mathrm{d}x}{\\mathrm{d}t} &= \\delta(1 - x) - |f(x, y)|x, \\\\\n\\frac{\\mathrm{d}y}{\\mathrm{d}t} &= 1 - y - |f(x, y)|y,\n\\end{align}\n\\tag{16.2}\\] where we have introduced the function, \\[\nf(x, y; R, \\lambda) = \\frac{1}{\\lambda}(Rx - y),\n\\tag{16.3}\\] where there are now three non-dimensional parameters given by \\[\n\\begin{align}\n\\delta &= d/c, \\\\\n\\lambda &= c/(2\\alpha k \\Delta T^*), \\\\\nR &= \\beta \\Delta S^*/(\\alpha \\Delta T^*).\n\\end{align}\n\\] Together Equation 16.2 and Equation 16.3 form a system of equations for \\((x(t), y(t))\\), with parameters \\(\\delta\\), \\(\\lambda\\), and \\(R\\)."
  },
  {
    "objectID": "part-03-box/stommel.html#equilibrium-states",
    "href": "part-03-box/stommel.html#equilibrium-states",
    "title": "16  Stommel’s box model",
    "section": "Equilibrium states",
    "text": "Equilibrium states\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.optimize as sciopt\n\ndef phi(f, delt, R):\n    phi = delt*R/(delt + np.abs(f)) - 1/(1 + np.abs(f))\n    return phi\n\nfmat = np.linspace(-2.5, 2.5, 101)\nplt.plot(fmat, phi(fmat, 1, 2), 'k--', label='$\\lambda = 1$, $R = 2$')\nplt.plot(fmat, phi(fmat, 1/6, 2), 'k', label='$\\lambda = 1/6$, $R = 2$')\nplt.plot(fmat, fmat, 'b--', label='$\\lambda = 1$')\nplt.plot(fmat, 1/6*fmat, 'b', label='$\\lambda = 1/6$' )\nplt.ylim((-1.5,2))\nplt.xlabel(\"$f$\")\nplt.ylabel(\"$\\phi$\")\nplt.legend()\n\n<matplotlib.legend.Legend at 0x125430bb0>\n\n\n\n\n\nAbove, we can see that dependent on the parameter values, there may be one or three possible equilibrum states."
  },
  {
    "objectID": "part-03-box/stommel.html#stability",
    "href": "part-03-box/stommel.html#stability",
    "title": "16  Stommel’s box model",
    "section": "Stability",
    "text": "Stability\nWe let \\(x = x^* + \\xi\\) and \\(y = y^* + \\eta\\) and linearise the system about the fixed points. This gives \\[\n\\begin{pmatrix}\n\\dot{\\xi} \\\\\n\\dot{\\eta}\n\\end{pmatrix} = A\n\\begin{pmatrix}\n\\xi \\\\ \\eta\n\\end{pmatrix},\n\\] where the matrix \\(A\\) is given by \\[\nA =\n\\begin{pmatrix}\n-(\\delta + |f^*|) \\mp \\frac{Rx^*}{\\lambda} & \\pm \\frac{x^*}{\\lambda} \\\\\n\\mp \\frac{Ry^*}{\\lambda} & -(1 + |f^*|) \\pm \\frac{y^*}{\\lambda}\n\\end{pmatrix}\n\\] if \\(f^* \\gtrless 0\\).\nWe can then calculate the trace and determinant, giving \\[\n\\begin{align}\nT &= -(1 + \\delta + 3 |f^*|), \\\\\nD &= (\\delta + 2|f^*|)(1 + |f^*|) \\pm (1 - \\delta) \\frac{y^*}{\\lambda}.\n\\end{align}\n\\] Using the above, we can analytically calculate the key discriminant expression of \\(T^2 - 4D\\) (or numerically) in order to verify stability.\nIn lectures and in your assignments, you will be asked to verify the stability and phase-plane analyses. As an example test point, try \\(R = 2\\), \\(\\delta = 1/6\\), and \\(\\lambda = 1/5\\).\n\nimport matplotlib.pyplot as plt\nimport numpy as np\ndelt = 1/6\nR = 2\nlam = 1/5\nxx, yy = np.meshgrid(np.arange(0, 1, 0.05), np.arange(0, 1, 0.05))\nf = (R*xx-yy)/lam\nxdot = delt*(1 - xx)- np.abs(f)*xx\nydot = 1 - yy - np.abs(f)*yy\nplt.streamplot(xx,yy,xdot,ydot, density=2);"
  },
  {
    "objectID": "part-03-box/stommel.html#bifurcation-diagrams",
    "href": "part-03-box/stommel.html#bifurcation-diagrams",
    "title": "16  Stommel’s box model",
    "section": "16.1 Bifurcation diagrams",
    "text": "16.1 Bifurcation diagrams\nYou will study the generation of the bifurcation diagrams, e.g. \\(\\lambda\\) vs. \\(f^*\\). This will be done using techniques in numerical continuation.\n\n\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM.\n\n\nStommel, Henry. 1961. “Thermohaline Convection with Two Stable Regimes of Flow.” Tellus 13 (2): 224–30."
  },
  {
    "objectID": "part-03-box/el-nino.html",
    "href": "part-03-box/el-nino.html",
    "title": "17  El Nino-Southern Oscillation",
    "section": "",
    "text": "2022-23 note\n\n\n\nThis material has not yet been finalised and is still under construction. Once it is covered in lectures, this banner will be replaced.\n\n\n\n\n\n\n\n\nReference\n\n\n\nThis largely follow from Chap. 16 of (Kaper and Engler 2013).\n\n\n\n\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM."
  },
  {
    "objectID": "part-04-pde/greenhouse.html",
    "href": "part-04-pde/greenhouse.html",
    "title": "18  The greenhouse gas effect",
    "section": "",
    "text": "19 Vertical structure of the atmosphere"
  },
  {
    "objectID": "part-04-pde/greenhouse.html#sec-radiative",
    "href": "part-04-pde/greenhouse.html#sec-radiative",
    "title": "18  The greenhouse gas effect",
    "section": "18.1 Radiative energy transfer",
    "text": "18.1 Radiative energy transfer\nRather than thinking of the greenhouse factor, \\(\\gamma\\), as an empirical parameter, we want to investigate how a mathematical model for its prediction can be studied. To do this, we must develop a deeper understanding of how energy is transferred through the atmosphere.\nRadiation is the transfer of energy by electromagnetic waves. Given a point in space, \\(\\mathbf{x}\\), we define the intensity \\(I_\\nu(\\mathbf{x}, \\mathbf{\\hat{s}})\\) as the energy flux per unit surface area of waves with frequency \\(\\nu\\) travelling in the direction \\(\\mathbf{\\hat{s}}\\) at the point \\(\\mathbf{x}\\). Remember as well that frequency is related to wavelength and speed by \\[\n\\lambda = \\frac{c}{\\nu}.\n\\]\nIn order to calculate the total radiative energy flux at a given point, we imagine surrounding the point with a unit sphere. The unit vector on the sphere is given in spherical coordinates via \\[\n\\mathbf{\\hat{s}} = (\\sin\\theta \\cos\\phi, \\sin\\theta \\sin\\phi, \\cos\\theta).\n\\]\nConsider a patch element of the sphere, with area element \\(\\mathrm{d}{\\omega}\\) given by \\[\n\\mathrm{d}{\\omega} = \\sin \\theta \\mathrm{d}{\\theta} \\mathrm{d}{\\phi}.\n\\] Then the radiative energy flux through this area element is given by \\[\nI_\\nu(\\mathbf{x}, \\mathbf{\\hat{s}}) \\mathbf{\\hat{s}} \\mathrm{d}{\\omega}.\n\\]\nTo calculate the total radiative energy flux, we then sum over all possible surface elements and over all possible frequencies: \\[\n\\mathbf{q}(\\mathbf{x}) = \\int_S \\int_0^\\infty I_\\nu(\\mathbf{x}, \\mathbf{\\hat{s}}) \\mathbf{\\hat{s}} \\, \\mathrm{d}{\\nu} \\, \\mathrm{d}{\\omega},\n\\] where note that the integral \\(\\int_S \\mathrm{d}{\\omega}\\) is a double integral over all angles \\(\\theta\\) and \\(\\phi\\).\nNext, we need a governing equation for the intensity, \\(I_\\nu\\).\n\n\n\n\n\n\nRadiative transfer equation\n\n\n\nThe radiative intensity, \\(I_\\nu\\), is given by solving the radiative transfer equation, \\[\n\\frac{\\mathrm{\\partial}I_\\nu}{\\mathrm{\\partial}s} = -\\rho \\kappa_\\nu I_\\nu + \\rho \\kappa_\\nu B_\\nu,\n\\tag{18.2}\\] where \\(\\partial/\\partial s = \\mathbf{\\hat{s}} \\cdot \\nabla_{\\mathbf{x}}\\) is the directional derivative in the direction \\(\\mathbf{\\hat{s}}\\). This is essentially an advection equation with source terms given by the first term, representing absorption by the atmosphere, and the second term representing re-emission. In addition, \\(\\rho\\) is the density and \\(\\kappa_\\nu\\) are the absorption coefficients.\nRe-emission is assumed to be independent of direction and is described by the Planck function, \\[\nB_\\nu = \\frac{2h\\nu^3}{c^2(\\mathrm{e}^{h\\nu/(kT)} - 1)},\n\\] describing the emission of radiation for a given local temperature \\(T\\). The constants correspond to Planck’s constant, \\(h \\approx 6.6 \\times 10^{-34} \\,\\mathrm{J} \\,\\mathrm{s}\\), the speed of light, \\(c\\approx 3.0 \\times 10^8 \\,\\mathrm{m s}^{-1}\\), and Boltzmann’s constant, \\(k \\approx 1.38 \\times 10^{-23} \\,\\mathrm{J K}^{-1}\\).\n\n\nWe wish to consider \\(I_\\nu\\), determined above, within the atmosphere. However, dependent on the composition of the atmosphere, \\(\\kappa_\\nu\\) is strongly dependent on the frequency (and space). For simplicity, however, we consider a ‘grey’ atmosphere, with \\(\\kappa_\\nu = \\kappa\\), independent of frequency.\nIntegrating Equation 18.2 over all frequencies, we have \\[\n\\frac{\\mathrm{\\partial}I}{\\mathrm{\\partial}s} = -\\rho \\kappa (I - B),\n\\tag{18.3}\\] where we have the total radiation intensity and emission intensity defined by \\[\nI(\\mathbf{x}, \\mathbf{s}) = \\int_0^\\infty I_\\nu \\, \\mathrm{d}{\\nu}, \\qquad\nB(\\mathbf{x}) = \\int_0^\\infty B_\\nu \\, \\mathrm{d}{\\nu}.\n\\]\nWe can integrate \\(B_\\nu\\) for \\(B\\) (exercise) to obtain \\[\nB = \\frac{\\sigma T^4}{\\pi},\n\\] where \\(\\sigma = 2\\pi^5 k^4/(15 h^3 c^2)\\) is the Stefan-Boltzmann constant, and now \\(B\\) is related to the local temperature at each point.\nAlthough the above relates \\(B\\) to temperature, \\(T\\), it is not so useful for our purposes because \\(T\\) is undetermined. Consider an infinitessimal parcel of the medium. Let us assume that there is no other energy transfer mechanism except for radiation absorption and emission. Then by energy conservation, \\(B\\) must be equal to the average radiation over all directions at each point, \\[\nB(\\mathbf{x}) = \\frac{1}{\\text{Surf. area}} \\iint_O I(\\mathbf{x}, \\mathbf{\\hat{s}}) \\, \\mathrm{d}S =  \\frac{1}{4\\pi} \\int_0^{2\\pi} \\int_0^\\pi I(\\mathbf{x}, \\mathbf{\\hat{s}}) \\sin\\theta \\, \\mathrm{d}{\\theta} \\, \\mathrm{d}{\\phi},\n\\tag{18.4}\\] where \\(O\\) is the unit sphere in \\(s\\)-space.\nThe above is the assumption of local radiative equilibrium, i.e. the total absorbed radiation at a point is equal to that determined by black body emission."
  },
  {
    "objectID": "part-04-pde/greenhouse.html#sec-two-stream",
    "href": "part-04-pde/greenhouse.html#sec-two-stream",
    "title": "18  The greenhouse gas effect",
    "section": "18.2 Two-stream approximation",
    "text": "18.2 Two-stream approximation\nThe above formulation for the intensity function, \\(I\\), is difficult to solve in general. Let us consider the case of a one-dimensional atmosphere, \\(I = I(z, \\theta)\\), where \\(\\theta\\) is the angle of \\(\\mathbf{\\hat{s}}\\) to the vertical. Then \\(\\partial_s = \\cos\\theta\\partial_z\\) and Equation 18.3 gives \\[\n\\cos\\theta \\frac{\\mathrm{\\partial}I}{\\mathrm{\\partial}z} = -\\rho \\kappa (I - B).\n\\] Since the density typically depends on \\(z\\), \\(\\rho = \\rho(z)\\), we define a new vertical coordinate that scales out the density. Let \\(\\tau\\) be the optical depth, and given by \\[\n\\tau = \\int_z^\\infty \\rho \\kappa \\, \\mathrm{d}{z}.\n\\tag{18.5}\\] Then since \\(\\partial_z = \\tau'(z) \\partial_\\tau\\), we have, for a new function, \\(I = I(\\tau, \\mu)\\), \\[\n\\mu \\frac{\\mathrm{\\partial}I}{\\mathrm{\\partial}\\tau} = I - B,\n\\tag{18.6}\\] where we have also defined \\(\\mu = \\cos\\theta\\). It should be remarked that \\(B\\) is given from Equation 18.4 and must only depend as a function of of the optical depth, \\(\\tau\\). To see this, note from Equation 18.4 that via the radiative equilibrium assumption, \\[\nB = \\frac{1}{4\\pi} \\int_0^{2\\pi} \\int_0^\\pi I \\, \\sin\\theta \\, \\mathrm{d}\\theta \\, \\mathrm{d}\\phi = \\frac{1}{2} \\int_{-1}^1 I(\\tau, \\mu) \\, \\mathrm{d}\\mu  = \\frac{1}{2}(I_+ + I_-).\n\\] This makes sense since the assumption that \\(B\\) averages all the different directions of radiation (which are measured by the coordinate \\(\\mu\\)).\nSo in fact Equation 18.6 is an integro-differential equation, \\[\n\\mu \\frac{\\mathrm{\\partial}I}{\\mathrm{\\partial}\\tau} = I - \\frac{1}{2} \\int_{-1}^1 I(\\tau, \\mu) \\, \\mathrm{d}\\mu.\n\\]\n\n18.2.1 Shuster-Schwarzschild approximation\nWe next make the Shuster-Schwarzschild approximation to reduce the radiation from all different directions to either an average over the upwards direction or an average over the downwards direction. First, note that if we integrate over the top hemisphere, \\[\n\\iint_S I \\, \\mathrm{d}{S} = \\int_{\\phi = 0}^{2\\pi} \\int_{\\theta = 0}^{\\pi/2} I \\cdot \\sin\\theta \\, \\mathrm{d}{\\theta} \\, \\mathrm{d}{\\phi}.\n\\] Since \\(I\\) is independent of the angular coordinate, \\(\\phi\\), we can integrate directly to see that \\[\n\\int_0^{2\\pi} \\mathrm{d}\\phi \\int_{\\theta = 0}^{\\pi/2} I (-\\mathrm{d}\\mu) = 2\\pi \\int_{\\mu = 0}^1 I \\, \\mathrm{d}\\mu \\equiv 2\\pi I_+,\n\\] once the integral in \\(\\theta\\) is converted to an integral in \\(\\mu\\). Doing the same for the radiation on the lower hemisphere yields the two new quantities \\[\n\\begin{align}\nI_+(\\tau) &\\equiv \\int_0^1 I(\\tau, \\mu) \\, \\mathrm{d}\\mu, \\\\\nI_-(\\tau) &\\equiv \\int_{-1}^0 I(\\tau, \\mu) \\, \\mathrm{d}\\mu.\n\\end{align}\n\\]\nWe can now write \\(B\\) in terms of these quantities: \\[\nB = \\frac{1}{2} \\int_{-1}^1 I(\\tau, \\mu) \\, \\mathrm{d}\\mu  = \\frac{1}{2}(I_+ + I_-).\n\\tag{18.7}\\]\nReturning now to Equation 18.6, we integrate with respect to \\(\\mu\\) on the interval \\(\\mu \\in [-1, 0]\\) and also on the interval \\(\\mu\\in[0, 1]\\) to obtain the two equations \\[\n\\begin{align}\n\\frac{1}{2} \\frac{\\mathrm{d}I_+}{\\mathrm{d}\\tau} &= I_+(\\tau) - B(\\tau) \\\\\n\\frac{1}{2} \\frac{\\mathrm{d}I_-}{\\mathrm{d}\\tau} &= I_-(\\tau) - B(\\tau)\n\\end{align}\n\\] and now using Equation 18.7, we have \\[\n\\begin{align}\n\\frac{\\mathrm{d}I_+}{\\mathrm{d}\\tau} &= I_+(\\tau) - I_-(\\tau)\\\\\n\\frac{\\mathrm{d}I_-}{\\mathrm{d}\\tau} &= I_+(\\tau) - I_-(\\tau).\n\\end{align}\n\\]\nWe require some bondary conditions to solve the above. First, there is no incoming radiation at the top of the atmosphere (\\(z \\to \\infty\\) or \\(\\tau \\to 0\\)), so \\[\nI_- = 0 \\quad \\text{at $\\tau = 0$}.\n\\] Next, at the surface, we have \\[\n\\pi I_+ = \\sigma T_s^4,\n\\] which expresses the flux from the surface via the Stefan-Boltzmann law, where \\(T_s\\) is surface temperature.\n\n\n\n\n\n\nNote\n\n\n\nDouble check the physicality of the above BCs.\n\n\nNote that the net upwards flux is given by \\(F = F_+ - F_- = \\pi(I_+ - I_-)\\) so we subtract the two above equations for \\(I_+\\) and \\(I_-\\) to get \\[\n\\begin{align}\nF_- &= \\pi I_- = F \\tau \\\\\nF_+ &= \\pi I_+ = F(1 + \\tau).\n\\end{align}\n\\] The surface boundary condition is thus \\[\nF = \\frac{\\sigma T_s^4}{1 + \\tau_s},\n\\] where recall the definition of optical depth from Equation 18.5 and we have written \\[\n\\tau_s = \\int_0^\\infty \\rho \\kappa \\, \\mathrm{d}z,\n\\] for the optical depth of the atmosphere.\nNote that the net upwards flux, \\(F\\), defines the effective emitting temperature, \\(T_e\\), according to \\[\nF = \\sigma T_e^4,\n\\] and thus we conclude that \\[\nT_s = (1 + \\tau_s)^{1/4} T_e.\n\\]\nThe above final result indicates why surface temperature is warmer than the effective emitting temperature, and we can also conclude that the greenhouse gas factor introduced earlier is \\[\n\\gamma = \\frac{1}{1 + \\tau_s}.\n\\]\nFinally, we can obtain an expression for the temperature, \\(T\\) throughout the atmosphere, using \\(B = F(1/2 + \\tau)/pi\\). Then \\[\nT = \\left(\\frac{1/2 + \\tau}{1 + \\tau_s}\\right)^{1/4} T_s,\n\\] so indeed temperature decreases with height."
  },
  {
    "objectID": "part-04-pde/greenhouse.html#problems",
    "href": "part-04-pde/greenhouse.html#problems",
    "title": "18  The greenhouse gas effect",
    "section": "21.1 Problems",
    "text": "21.1 Problems\n\nIn Section 18.1, the units of the various quantities such as radiation intensity, energy flux, etc. can be confusing to follow. Follow the argument from eqns (…) to eqn (…) and carefully indicate the units of each associated quantity.\n\n\n\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36. Springer."
  },
  {
    "objectID": "part-05-techniques/part-techniques.html",
    "href": "part-05-techniques/part-techniques.html",
    "title": "Mathematical methods",
    "section": "",
    "text": "(Appendix-like) review of mathematical methods"
  },
  {
    "objectID": "part-05-techniques/dynamical-systems.html",
    "href": "part-05-techniques/dynamical-systems.html",
    "title": "18  Dynamical systems",
    "section": "",
    "text": "Insert some revew of dynamical systems."
  },
  {
    "objectID": "part-05-techniques/vector-calculus.html#coordinate-systems",
    "href": "part-05-techniques/vector-calculus.html#coordinate-systems",
    "title": "19  Vector calculus",
    "section": "19.1 Coordinate systems",
    "text": "19.1 Coordinate systems\n\nWe need some vector calculus in the section on Section 17.1 when discussing the radiation integrals.\n\n\n19.1.1 Spherical coordinates\nIn spherical coordinates, …"
  },
  {
    "objectID": "part-05-techniques/vector-calculus.html#directional-derivatives",
    "href": "part-05-techniques/vector-calculus.html#directional-derivatives",
    "title": "19  Vector calculus",
    "section": "19.2 Directional derivatives",
    "text": "19.2 Directional derivatives\nUsed in the Section 17.1, i.e. \\(\\partial\\partial s = \\mathbf{\\hat{s}} \\cdot \\nabla_{\\mathbf{x}}\\)."
  },
  {
    "objectID": "part-05-techniques/vector-calculus.html#integration-in-different-coordinate-systems",
    "href": "part-05-techniques/vector-calculus.html#integration-in-different-coordinate-systems",
    "title": "19  Vector calculus",
    "section": "19.3 Integration in different coordinate systems",
    "text": "19.3 Integration in different coordinate systems\n\n\n\n\n\n\nImportant\n\n\n\nProbably need some homework questions on spherical integration?\n\n\nIn Section 17.2, we make sure of the surface integral in spherical coordinates. This converts an integral as follows: \\[\n\\iint_S I \\, \\mathrm{d}{S} = \\iint_{\\theta, \\phi} I \\, \\sin\\theta \\, \\mathrm{d}\\theta \\, \\mathrm{d}\\phi.\n\\]"
  },
  {
    "objectID": "part-05-techniques/modelling.html#units",
    "href": "part-05-techniques/modelling.html#units",
    "title": "21  Modelling",
    "section": "21.1 Units",
    "text": "21.1 Units\nIt is good to clarify notation and analysis of scientific units. In this course, we will sometimes use square brackets to indicate the units of a quantity. For example, in the next chapter, we will discuss radiation from the sun, measured by \\(Q = 1380\\) W m^{-2}. A Watt (W) is energy per unit time, or joules per second (J/s). So alternatively, we could write \\(Q = 1380 J/(m^2 s)\\), or \\[\n[Q] = J m^{-2} s^{-1}.\n\\] This is an example of a flux—the flow (W, J/s) per unit area (m^2) of some quantity (in this case, energy). If you are ever confused about what a unit means, it is a good idea to break it into its constituent parts."
  },
  {
    "objectID": "part-05-techniques/modelling.html#nondimensionalisation",
    "href": "part-05-techniques/modelling.html#nondimensionalisation",
    "title": "21  Modelling",
    "section": "21.2 Nondimensionalisation",
    "text": "21.2 Nondimensionalisation\n\n\n\n\n\n\nImportant\n\n\n\nInsert a few words about nondimensionalisation here."
  },
  {
    "objectID": "part-05-techniques/finitedifference.html#forwards-backwards-and-centred-differences",
    "href": "part-05-techniques/finitedifference.html#forwards-backwards-and-centred-differences",
    "title": "21  Finite difference approximations",
    "section": "21.1 Forwards, backwards, and centred differences",
    "text": "21.1 Forwards, backwards, and centred differences\nWe want to learn how to use finite differences in order to approximate derivatives numerically. We know that \\[\nf'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h},\n\\] provided the limit exists. Therefore, a simple idea to approximating the value of \\(f'(x)\\) is to use a small numerical value for \\(h\\), and calculate (the gradient of the secant line), \\[\nf'(x) \\approx \\frac{f(x + h) - f(x)}{h},\n\\] where \\(h\\) is a specified small number. The above is known as the two-point forward-difference formula. In fact, we can determine exactly the error of such an approximation via Taylor’s theorem. If \\(f\\) is twice continuously differentiable, then \\[\nf(x + h) = f(x) + h f'(x) + \\frac{h^2}{2} f''(c),\n\\] for some point \\(c\\in [x, x+h]\\). Therefore by re-arrangement, we see the following.\n\n\n\n\n\n\nTwo-point forward-difference formula\n\n\n\n\\[\nf'(x) = \\frac{f(x + h) - f(x)}{h} - \\frac{h}{2} f''(c),\n\\] where \\(c \\in (x, x+h)\\).\n\n\nNotice that the error in using the two-point forward difference approximation is then \\(\\mathcal{O}(h)\\), and this error tends to zero as \\(h \\to 0\\) (as long as \\(f''\\) is continuous). We thus call the above formula a first-order finite-difference approximation. If the error is \\(\\mathcal{O}(h^n)\\), we call the corresponding formula an \\(n\\)th-order approximation.\n\n\n\n\n\n\nExample\n\n\n\nUse the two-point forward difference formula with different values of \\(h\\) in order to approximate the derivative of \\(f(x) = 1/x\\) at \\(x = 2\\).\n\n\n\n\\(f(x)\\)\n\\(f(x + h)\\)\n\\(h\\)\n\\(f'(x)\\)\nError\n\n\n\n\n…\n…\n…\n…\n…\n\n\n…\n…\n…\n…\n…\n\n\n…\n…\n…\n…\n…\n\n\n\n\n\nSimilar formulae can be developed for the backwards difference (send \\(h \\to -h\\)).\nA more accurate formula can be developed via subtracting the Taylor series for \\(f(x - h)\\) from that for \\(f(x + h)\\). This results in:\n\n\n\n\n\n\nThree-point centered-difference formula\n\n\n\n\\[\nf'(x) = \\frac{f(x + h) - f(x - h)}{2h} - \\frac{h^2}{6} f'''(c),\n\\] where \\(c \\in (x-h, x+h)\\).\n\n\nThus we see that the centered difference formula is accurate to \\(O(h^2)\\)."
  },
  {
    "objectID": "part-05-techniques/finitedifference.html#jacobian-matrices",
    "href": "part-05-techniques/finitedifference.html#jacobian-matrices",
    "title": "21  Finite difference approximations",
    "section": "21.2 Jacobian matrices",
    "text": "21.2 Jacobian matrices\n\n\n\n\n\n\nReference\n\n\n\nYou will have encountered the Jacobian, firstly in your first-year Methods courses when performing change-of-coordinates in integration formulae, and secondly in your second-year Modelling and Dynamics courses when studying differential equations. It also comes up in the second-year Vectors and PDEs course.\n\n\nThe Jacobian matrix, \\(\\mathbf{J}\\), of a vector function, \\(\\mathbf{F}: \\mathbb{R}^n \\to \\mathbb{R}^m\\), \\[\n\\mathbf{F}(\\mathbf{x}) = \\begin{pmatrix}\nf_1(\\mathbf{x}) \\\\\nf_2(\\mathbf{x}) \\\\\n\\vdots \\\\\nf_m(\\mathbf{x})\n\\end{pmatrix},\n\\] is the matrix of all its first-order partial derivatives, \\[\n\\mathbf{J}(\\mathbf{x}) = \\begin{pmatrix}\n\\frac{\\mathrm{\\partial}f_1}{\\mathrm{\\partial}x_2} & \\cdots &\n\\frac{\\mathrm{\\partial}f_1}{\\mathrm{\\partial}x_n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\frac{\\mathrm{\\partial}f_m}{\\mathrm{\\partial}x_1} & \\cdots &\n\\frac{\\mathrm{\\partial}f_m}{\\mathrm{\\partial}x_n}\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\nabla f_1(\\mathbf{x})^T \\\\\n\\vdots \\\\\n\\nabla f_n(\\mathbf{x})^T\n\\end{pmatrix}.\n\\] We can essentially think of the Jacobian as the multi-dimensional extension of the basic derivative. It encodes all of the (first-order) information about the rate-of-change of the function.\nIt is interesting and important to consider the numerical evaluation of the Jacobian, in the event that the function \\(\\mathbf{F}\\) cannot be easily differentiated exactly. The simplest algorithm is based on approximating each entry of the matrix by a finite difference.\nFor example, let us consider approximating \\[\n\\frac{\\mathrm{\\partial}f_i}{\\mathrm{\\partial}x_j}(\\mathbf{x}_0).\n\\] We define the \\(j\\)th unit vector by \\(\\mathbf{e}_j = [0 \\, 0 \\, \\cdots \\, 1 \\, \\cdots \\, 0]\\), which the \\(j\\)th entry being one and all entries being zero. Then we can approximate the derivative by a central difference, \\[\n\\frac{\\mathrm{\\partial}f_i}{\\mathrm{\\partial}x_j}(\\mathbf{x}_0) \\approx \\frac{f_i(\\mathbf{x}_0 + \\mathbf{e}_j h) - f_i(\\mathbf{x}_0 - \\mathbf{e}_j h)}{2h},\n\\] where \\(h\\) is a small step size.\nLet us test this by calculating the Jacobian for \\[\n\\mathbf{F}(\\mathbf{x}) = \\begin{pmatrix}\nx_1^2 \\\\\nx_2^2 \\\\\nx_1 x_2\n\\end{pmatrix}.\n\\] The pseudocode for this looks like this\n\n\n\n\n\n\nPseudocode for numerical Jacobian\n\n\n\nInput: function F (size m), point x (size n), step size h\n1. Create an (m x n) matrix, J\n2. a. Loop through all the rows indexed by i\n      b. Loop through all the columns indexed by j\n             Create the ej unit vector\n         Calculate the difference of F_i(x + h e_j) - F_i(x - h e_j)\n         Divide by 2h\n         Assign this value to the (i,j)th value of the Jacobian\n\nOutput: the (mxn) Jacobian matrix J\n\n\nHere is a code that puts it into practice.\n\nimport numpy as np\n\ndef jacobian(func,initial,delta=1e-3):\n  f = func\n  nrow = len(f(initial))\n  ncol = len(initial)\n  output = np.zeros(nrow*ncol)\n  output = output.reshape(nrow,ncol)\n  for i in range(nrow):\n    for j in range(ncol):\n      ej = np.zeros(ncol)\n      ej[j] = 1\n      dij = (f(initial+ delta * ej)[i] - f(initial- delta * ej)[i])/(2*delta)\n      output[i,j] = dij\n  return output\n  \ndef myf(x):\n  x1 = x[0]\n  x2 = x[1]\n  output = np.zeros(3)\n  output[0] = x[0]**2\n  output[1] = x[1]**2\n  output[2] = x[0]*x[1]\n  return output\n  \njacobian(myf,[1,2])\n\narray([[2., 0.],\n       [0., 4.],\n       [2., 1.]])"
  },
  {
    "objectID": "part-05-techniques/newtons.html#demo-of-newtons-method-for-scalar-equations",
    "href": "part-05-techniques/newtons.html#demo-of-newtons-method-for-scalar-equations",
    "title": "11  Newton’s method",
    "section": "11.1 Demo of Newton’s method for scalar equations",
    "text": "11.1 Demo of Newton’s method for scalar equations\nHere is a simple demonstration of Newton’s method.\n\nimport numpy as np\n\ndef Newton(f, df, x, maxiter=100, tol=1e-12, display=0):\n    i = 0\n    while (abs(f(x) - 0) > tol) and (i < maxiter):\n        err = f(x)\n        x = x - err / df(x)\n        if display == 1:\n            print(\"f(x) = \", np.abs(err), \", x = \", x)\n        i = i + 1\n    return x, err\n\nf = lambda x: x**3 + 4*x**2 - 10\ndf = lambda x: 3*x**2 + 8*x\n\nx = 2\nx, err = Newton(f, df, x, 10, 1e-8, 1)\nprint(\"Final approximation = \", x)\n\nf(x) =  14 , x =  1.5\nf(x) =  2.375 , x =  1.3733333333333333\nf(x) =  0.13434548148148195 , x =  1.3652620148746266\nf(x) =  0.0005284611795151051 , x =  1.3652300139161466\nFinal approximation =  1.3652300139161466"
  },
  {
    "objectID": "part-05-techniques/newtons.html#newtons-method-for-systems-of-nonlinear-equations",
    "href": "part-05-techniques/newtons.html#newtons-method-for-systems-of-nonlinear-equations",
    "title": "11  Newton’s method",
    "section": "11.2 Newton’s method for systems of nonlinear equations",
    "text": "11.2 Newton’s method for systems of nonlinear equations\nNewton’s method generalises naturally to the case of a system of equations. Suppose we wish to solve for the \\(n\\) unknowns \\(\\mathbf{x} = (x_1, \\ldots, x_n)\\) via \\[\n\\mathbf{F(\\mathbf{x}}) =\n\\begin{pmatrix}\nF_1(\\mathbf{x}) \\\\\nF_2(\\mathbf{x}) \\\\\n\\ldots \\\\\nF_n(\\mathbf{x})\n\\end{pmatrix} = 0.\n\\]\nWe have, via Taylor’s formula, \\[\n\\mathbf{F}(\\mathbf{x}_{i+1}) \\sim  \\mathbf{F(\\mathbf{x}_i}) + J(\\mathbf{x}_i)(\\mathbf{x}_{i+1} - \\mathbf{x}_i) + \\mathcal{O}(||\\mathbf{x}_{i+1} - \\mathbf{x}_i||^2),\n\\] where \\(J\\) is the Jacobian matrix \\[\nJ(\\mathbf{x}) = \\nabla \\mathbf{F}(\\mathbf{x}) =\n\\begin{pmatrix}\n\\frac{\\mathrm{\\partial}F_1}{\\mathrm{\\partial}x_1} &\n\\cdots &\n\\frac{\\mathrm{\\partial}F_1}{\\mathrm{\\partial}x_n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\frac{\\mathrm{\\partial}F_n}{\\mathrm{\\partial}x_1} &\n\\cdots &\n\\frac{\\mathrm{\\partial}F_n}{\\mathrm{\\partial}x_n}\n\\end{pmatrix}.\n\\] Therefore, Newton’s method forms the iterates of \\[\n\\mathbf{x}_{i+1} = \\mathbf{x}_i + J^{-1}(\\mathbf{x}_i) \\mathbf{F}(\\mathbf{x}_i),\n\\] which takes a very similar form to the scalar case.\nHowever, solution of the inverse of \\(J\\) is typically inefficient, and it is better to instead solve for \\(\\delta_{i+1} = \\mathbf{x}_{i+1} - \\mathbf{x}_i\\) via \\[\nJ(\\mathbf{x}_i) \\delta_{i+1} = - \\mathbf{F}(\\mathbf{x}_i),\n\\] and then calculate \\(\\mathbf{x}_{i+1} = \\mathbf{x}_i + \\delta_{i+1}\\). There are many ways of solving the above matrix problem efficiently using built-in routines that perform, e.g. Gaussian elimination.\nhttp://hplgit.github.io/prog4comp/doc/pub/._p4c-solarized-Python031.html"
  },
  {
    "objectID": "part-05-techniques/arclength.html#parameter-continuation",
    "href": "part-05-techniques/arclength.html#parameter-continuation",
    "title": "23  Arclength continuation",
    "section": "23.1 Parameter continuation",
    "text": "23.1 Parameter continuation\nOur task is to investigate numerical procedures where we can solve problems like Equation 23.1 and generate the set of solutions, as illustrated in a bifurcation diagram.\n\nThe basic idea is to start with an initial guess, say \\((\\mathbf{x}^*, \\lambda^*)\\). We can apply Newton’s method and solve Equation 23.1 in order to determine a point on the solution curve, say \\((\\mathbf{x}_0, \\lambda_0\\).\nNext, we increment \\(\\lambda\\), say to \\(\\lambda_1 = \\lambda_0 + \\Delta \\lambda\\). Starting from the previous solution, \\(\\mathbf{x}_0\\), we then attempt to converge to the correct solution \\((\\mathbf{x}_1, \\lambda_1)\\).\n\nThis involves the following pseudocode:\n\n\n\n\n\n\nPoor person’s numerical continuation\n\n\n\n1. Input guess (x, lambda), f, df\n\n    a. Call Newton's method via Newton(f, df, x, lambda) \n    b. Obtain a preliminary solution (x0, lambda0)\n\n2. Increment lambda1 = lambda0 + delta \n\n    a. Call Newton's method via Newton(f, df, x0, lambda1)\n    b. Obtain a new solution (x1, lambda1)\n\n3. Repeat 2 until we have established enough values of lambda\n\n\nUnfortunately this does not work as well as we would like. We can try it on the above circle example. In this case, notice that \\[\n\\begin{align}\nF(x, \\lambda) &= x^2 + \\lambda^2 - 1, \\\\\nF_x(x, \\lambda) &= 2x.\n\\end{align}\n\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef Newton(f, df, x, maxiter=100, tol=1e-12, display=0):\n    i = 0\n    while (abs(f(x) - 0) > tol) and (i < maxiter):\n        err = f(x)\n        x = x - err / df(x)\n        if display == 1:\n            print(\"f(x) = \", np.abs(err), \", x = \", x)\n        i = i + 1\n    return x, err\n\nlammat = np.linspace(-1, 1.1, 20)\nxmat = 0*lammat\nx = 0.1\n\nfor i, lam in enumerate(lammat):\n    f = lambda x: x**2 + lam**2 - 1 \n    df = lambda x: 2*x \n\n    x, err = Newton(f, df, x, 10, 1e-8, 0)\n    if err > 1e-4:\n        print(\"Careful no convergence at lambda = \", lam)\n    xmat[i] = x\n# Plots\nplt.plot(lammat, xmat, '-o');\n\n# Plotting a circle\ntheta = np.linspace(0, 2*np.pi, 50)\nplt.plot(np.sin(theta), np.cos(theta), 'r--');\nplt.xlabel('lambda');\nplt.ylabel('x');\nplt.xlim([-1.5,1.5])\nplt.ylim([-1.5,1.5])\nplt.gca().set_aspect('equal')\nplt.show()\n\nCareful no convergence at lambda =  -0.8894736842105263\nCareful no convergence at lambda =  -0.6684210526315789\nCareful no convergence at lambda =  1.1\n\n\n\n\n\nYou’ll notice that there are several problems.\n\nFirst, there seems to be an issue for several points in \\(\\lambda\\) where the previous guess does not seem adequate to obtain the next solution.\nSecond, our numerical scheme cannot resolve past fold points, here at \\((1, 0)\\).\n\nOf course, we can re-do a secondary numerical calculation to resolve the lower branch of the locus. However, it would be preferable to be able to do this in a single run. Moreover, in more complicated problems, we may not know what the final locus ressembles, and it may furthermore lie in a high-dimensional space."
  },
  {
    "objectID": "part-05-techniques/arclength.html#pseudo-arclength-continuation",
    "href": "part-05-techniques/arclength.html#pseudo-arclength-continuation",
    "title": "23  Arclength continuation",
    "section": "23.2 Pseudo-arclength continuation",
    "text": "23.2 Pseudo-arclength continuation\nThere is nothing geometrically wrong about continuation past a fold point; our previous numerical difficulties are instead related to the fact that \\(\\lambda\\) is a poor choice of parameter used to describe the solution curve, \\((\\mathbf{x}, \\lambda)\\).\nInstead, it makes much more sense to consider an alternative parameter, such as the arclength along the curve. Let \\(t\\) denote the parameter along the curve (we will specify momentarily what it is). Then we are considering the computation of the arc \\((\\mathbf{x}, \\lambda) = (\\mathbf{x}(t), \\lambda(t))\\), which corresponds to points in \\(\\mathbb{R}^{n+1}\\) specified by a scalar value of \\(t\\).\nIn addition, we can calculate a tangent vector along this arc, given by the \\((N+1)\\)-component vector, \\[\n(\\dot{\\mathbf{x}}, \\, \\dot{\\lambda}) = \\left( \\frac{\\mathrm{d}\\mathbf{x}}{\\mathrm{d}t}, \\, \\frac{\\mathrm{d}\\lambda}{\\mathrm{d}t}\\right).\n\\]\nIn order to allow for continuation past a fold, we apply an idea called pseudo-arclength continuation. Assume that at some initial point, \\(t = t_0\\), we possess a solution \\(P = (\\mathbf{x}_0, \\lambda_0)\\) and its tangent \\(\\mathbf{\\tau}_0 = (\\dot{\\mathbf{x}}_0, \\dot{\\lambda})\\). We are seeking a new value, say \\((\\mathbf{x}_1, \\lambda_1)\\), at \\(t = t_1\\).\nIn order to find this new value, we construct a plane perpendicular to the vector \\(\\mathbf{\\tau}_0\\), which passes through the point \\(Q = (\\mathbf{x}_1, \\lambda_1)\\). This is shown in the diagram below.\n\n\n\nFigure 23.1: Diagram from (Spence and Graham 1999). Note that in the diagram, they use \\(\\Delta t\\) for the distance between the point and the plane; we use \\(\\Delta s\\).\n\n\nThe illustrated plane lies a distance \\(\\Delta s\\) from the point P. From planar geometry, the distance of a point, \\(P\\), from a plane with point \\(Q\\) and normal direction \\(\\mathbf{\\tau}_0\\) is given by \\[\n\\frac{\\mathbf{\\tau}_0}{||\\mathbf{\\tau}_0||} \\cdot \\mathbf{v} = \\Delta s\n\\] where \\(\\mathbf{v}\\) is the vector from \\(Q\\) to \\(P\\). Putting in the values then gives \\[\n-\\frac{(\\dot{\\mathbf{x}}_0, \\dot{\\lambda_0})}{||(\\dot{\\mathbf{x}}_0, \\dot{\\lambda_0})||}\n\\cdot (\\mathbf{x}_0 - \\mathbf{x}, \\lambda_0 - \\lambda) = \\Delta s.\n\\]\nIn other words, we are seeking to solve the coupled set of equations \\[\n\\begin{cases}\n\\mathbf{F}(\\mathbf{x}, \\lambda) = 0 \\\\\n\\frac{(\\dot{\\mathbf{x}}_0, \\dot{\\lambda_0})}{||(\\dot{\\mathbf{x}}_0, \\dot{\\lambda_0})||}\n\\cdot (\\mathbf{x} - \\mathbf{x}_0, \\lambda - \\lambda_0) - \\Delta s = 0\n\\end{cases}\n\\tag{23.2}\\]\nNotice that we seem to have the right number of equations to unknowns. There are \\((N+1)\\) unknowns in \\((\\mathbf{x}, \\lambda)\\). The equation for \\(\\mathbf{F} = 0\\) gives \\(N\\) equations, while the last (scalar) equation closes the system. The step \\(\\Delta s\\) is specified by the implementation."
  },
  {
    "objectID": "part-05-techniques/arclength.html#secant-continuation",
    "href": "part-05-techniques/arclength.html#secant-continuation",
    "title": "23  Arclength continuation",
    "section": "23.3 Secant continuation",
    "text": "23.3 Secant continuation\nWe require a method for approximating the initial tangent direction, \\((\\dot{\\mathbf{x}}_0, \\lambda_0)\\), and then we need to update this direction as the continuation proceeds. To do this, we approximate the derivative with a secant. Suppose we have two nearby solution points, \\[\n\\mathbf{v}_0 = \\begin{pmatrix}\n\\mathbf{x}_0 \\\\\n\\lambda_0\n\\end{pmatrix}\n\\quad \\text{and} \\quad\n\\mathbf{v}_1 = \\begin{pmatrix}\n\\mathbf{x}_1 \\\\\n\\lambda_1\n\\end{pmatrix}.\n\\] We can approximate the derivative using the secant line \\[\n\\mathbf{s} = \\frac{\\mathbf{v}_1 - \\mathbf{v}_0}{||\\mathbf{v_1} - \\mathbf{v_0}||}.\n\\]\nThis line has unit magnitude and is approximately aligned with \\(\\tau_0\\).\n\n\n\n\n\n\nPseudocode for pseudo-arclength continuation using the secant\n\n\n\n1. Input guess (x, lambda), f, df, initial step size, ds\n\n    a. Call Newton's method via Newton(f, df, x, lambda) \n    b. Obtain a preliminary solution (x0, lambda0)\n\n2. Increment lambda1 = lambda0 + delta \n\n    a. Call Newton's method via Newton(f, df, x0, lambda1)\n    b. Obtain a new solution (x1, lambda1)\n\n3. While lambda < desired_max\n    \n    a. Form the secant line, S, using v0 and v1\n    b. The new solution is approximately at v = v1 + S*ds\n    c. Solve the extended Newton system \n    d. Assign v0 = v1, v1 = new solution, v. Go back to a."
  },
  {
    "objectID": "part-05-techniques/arclength.html#exercises",
    "href": "part-05-techniques/arclength.html#exercises",
    "title": "23  Arclength continuation",
    "section": "23.4 Exercises",
    "text": "23.4 Exercises\n\nDo pseudo-arclength continuation using a table(?)\n\n\n\n\n\nKrauskopf, Bernd, Hinke M Osinga, and Jorge Galán-Vioque. 2007. Numerical Continuation Methods for Dynamical Systems. Vol. 2. Springer.\n\n\nSpence, Alastair, and Ivan G Graham. 1999. “Numerical Methods for Bifurcation Problems.” In The Graduate Student’s Guide to Numerical Analysis’ 98, 177–216. Springer."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "24  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "part-xx-exercises/part-exercises.html",
    "href": "part-xx-exercises/part-exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Exercises and problem sets to be released as the term progresses."
  },
  {
    "objectID": "part-xx-exercises/ps01.html#a-source-in-the-heat-equation",
    "href": "part-xx-exercises/ps01.html#a-source-in-the-heat-equation",
    "title": "26  Problem set 1",
    "section": "26.1 A source in the heat equation",
    "text": "26.1 A source in the heat equation\nConsider the same heat experiment discused in Chapter 1 but now consider a bar that has an internal source or sink generating or removing heat, such as the case of a boiler with an internal heating element. By adapting a similar derivation to the one presented, explain why the modified conservation of heat equation is \\[\n\\frac{\\mathrm{\\partial}}{\\mathrm{\\partial}t} \\int_a^b \\rho c T \\, \\mathrm{d}x = q(x = b, t) - q(x = a, t) + \\int_a^b R(x, t) \\, \\mathrm{d}x.\n\\]\nIn addition:\n\nBy studying the dimensions of the other terms in the above equation, find what the dimensions of \\(R\\) are. What does \\(R > 0\\) mean and \\(R < 0\\)?\nHence derive the partial differential equation that governs the temperature \\(T\\).\nBy introducing the appropriate scalings on each of the variables, \\(x\\), \\(t\\), and \\(T\\), non-dimensionalise the PDE and discuss the non-dimensional parameters (there will be two)."
  },
  {
    "objectID": "part-xx-exercises/ps01.html#choice-of-scalings",
    "href": "part-xx-exercises/ps01.html#choice-of-scalings",
    "title": "26  Problem set 1",
    "section": "26.2 Choice of scalings",
    "text": "26.2 Choice of scalings\nConsider the dimensional problem for the motion of a projectile launched from close to the surface of the Earth. The dimensional height of the projectile, \\(y(t)\\), is given by \\[\\begin{align}\n\\frac{\\mathrm{d}^2 y}{\\mathrm{d}t^2} &= - \\frac{GM}{(R+y)^2}, \\\\\ny(0) &= 2 \\, \\mathrm{m}, \\\\\ny'(0) &= -V_0 \\, \\mathrm{m/s}.\n\\end{align}\\] Assume that the Earth is spherical and of uniform density, with its mass given by \\(M = (4/3) \\pi R^3 \\rho\\). Non-dimensionalise the height using \\(y = L \\tilde{y}\\) and time using \\(t = T\\tilde{t}\\). Consider the following cases:\n\n\\(R\\) fixed, \\(V_0 \\to \\infty\\), \\(\\rho\\) fixed;\n\\(R\\) fixed, \\(V_0\\) fixed, \\(\\rho \\to \\infty\\);\n\\(R\\) fixed, \\(V_0\\) fixed, \\(\\rho \\to 0\\);\n\\(R \\to 0\\), \\(V_0\\) fixed, \\(M\\) fixed.\n\nFor each case:\n\nExplain the physical interpretation of the limits.\nChoose the scalings \\(L\\) and \\(T\\) to normalise as many terms as possible.\nChoose the scalins so that the time it takes for the projectile to fall should be finite for the given limit, and for the speed, acceleration, and initial height to be well behaved (finite).\nWrite out the scaled problem and identify all remaining nondimensional parameters.\nIdentify the limiting small parameter for each case. Write out the problem (leading-order problem) when the parameter is set to zero."
  },
  {
    "objectID": "part-xx-exercises/ps01.html#the-unique-timescale-in-the-heat-equation",
    "href": "part-xx-exercises/ps01.html#the-unique-timescale-in-the-heat-equation",
    "title": "26  Problem set 1",
    "section": "26.3 The unique timescale in the heat equation",
    "text": "26.3 The unique timescale in the heat equation\nDuring our investigation of the heat equation, we found that it was possible to scale time so as to scale out the only non-dimensional parameter that appears in the PDE (the Peclet number). This produced (Equation 2.3). As explained in lectures, the disappearance of all non-dimensional parameters is due to the fact that only a single sensible timescale exists.\nBy adjusting the boundary conditions, we may create a new problem involving heat flow where a unique ‘special’ timescale in (Equation 2.2) can no longer be chosen.\nConsider a system where one side of the rod is heated in some periodic fashion, e.g. set the initial and boundary conditions to be \\[\\begin{align}\nT(x, 0) &= T_0 \\\\\nT(0, t) &= T_a \\cos (\\omega t), \\\\\nT(L, t) &= T_b.\n\\end{align}\\]\n\nWhat must the units of \\(\\omega\\) be?\nNon-dimensionalise as usual and, without selecting the timescale, \\([t]\\), identify the key non-dimensional parameters that remain. Write a brief sentence to describe their physical interpretation.\nThere are two sensible choices for setting the timescale, \\([t]\\). Identify the two choices and present the reduced set of equations in each case."
  },
  {
    "objectID": "part-xx-exercises/ps01.html#timescale-in-the-surface-energy",
    "href": "part-xx-exercises/ps01.html#timescale-in-the-surface-energy",
    "title": "26  Problem set 1",
    "section": "26.4 Timescale in the surface energy",
    "text": "26.4 Timescale in the surface energy\nTake the basic zero-dimensional energy model studied in (Equation 3.7) for the temperature of the troposphere: \\[\nc \\frac{\\mathrm{d}T}{\\mathrm{d}t} = \\frac{1}{4} Q(1 - a) - \\sigma \\gamma T^4.\n\\]\n\nNon-dimensionalise the model by choosing \\(T = [T]T'\\), \\(t = [t]t'\\), and \\(Q = [Q]Q'\\). Show that it is possible to select the scalings on the temperature and time so as to completely remove all constants from the problem when \\(Q\\) is assumed to be constant.\nThus, show that the analysis of the above equation is equivalent to studying \\[\n\\frac{\\mathrm{d}T}{\\mathrm{d}t} = 1 - T^4,\n\\] where we have dropped the primes and assumed that the albedo is such that \\(1 - a \\neq 0\\).\nFrom your choice of \\([t]\\), estimate the typical dimensional value using \\(d \\approx 10 \\mathrm{km}\\), \\(\\rho \\approx 1 \\mathrm{kg} \\,\\mathrm{m}^{-3}\\), \\(c_p \\approx 10^3 \\mathrm{J} \\,\\mathrm{kg}^{-1} \\,\\mathrm{K}^{-1}\\).\n\nUse a pocket calculator to verify your calculations and conclude that this time-scale is on the order of a month. What is the relevance of this approximation as it concerns the steady-state solution?"
  },
  {
    "objectID": "part-xx-exercises/thought02.html",
    "href": "part-xx-exercises/thought02.html",
    "title": "26  Thinking about your own energy",
    "section": "",
    "text": "There is no problem set for the material related to MacKay’s book, i.e. Chapter 6 to Chapter 7. Instead, a portion of your coursework in Week 7 will ask you to explore some issues to your own energy usage, and to other interesting aspects from MacKay’s book.\n\n\nTherefore, instead of homework, I encourage you to read the following to get you into thinking about energy usage.\nDownload or access the book at www.withouthotair.com.\n\nRead/scan through Chap. 1 (Numbers, not adjectives).\nExamine MacKay’s arguments for those items that you find interesting. You can examine both the issue of consumption and energy production (or alternatively, use of renewables).\n\nRead/scan through MacKay’s technical sections, in Chap. 3 (technical chapters).\n\nSelect one or two items that you are interested in learning more about (e.g. energy usage in car transport), and read the technical aspects closely.\nInvestigate how much energy you are using yourself and what back-of-the-envelope calculations you would like to do.\nStart with your gas and electrical usage, but you may be interested in other energy usages that you have wondered about.\n\nMake a list of those interesting questions that you have wondered about. For example:\n\nIs it better for me to leave a hot coffee machine on the whole day, or turn it on every time I use it?\nHow important is it for me to eat less meat, in the grand scheme of things? How does this compare with the impact of going on vacation in the summers?\nMy family is thinking about selling our old car and instead buying an electric car. Is it better for the environment to do so, or is the environmental cost of electric car manufacturing, lithium battery usage, and disposing of our old car outweigh the benefits?\n\nMacKay can be accused of oversimplifying many of the modelling aspects. Moreover, the book is now ten years out-of-date.\n\nWhich of MacKay’s calculations might you be interested in digging into at a deeper level?"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Arrhenius, Svante. 1896. “XXXI. On the Influence of Carbonic Acid\nin the Air Upon the Temperature of the Ground.” The London,\nEdinburgh, and Dublin Philosophical Magazine and Journal of Science\n41 (251): 237–76.\n\n\nBesson, Ugo. 2012. “The History of the Cooling Law: When the\nSearch for Simplicity Can Be an Obstacle.” Science &\nEducation 21 (8): 1085–1110.\n\n\nBudyko, Mikhail I. 1969. “The Effect of Solar Radiation Variations\non the Climate of the Earth.” Tellus 21 (5): 611–19.\n\n\nCharney, Jule G, Akio Arakawa, D James Baker, Bert Bolin, Robert E\nDickinson, Richard M Goody, Cecil E Leith, Henry M Stommel, and Carl I\nWunsch. 1979. Carbon Dioxide and Climate: A Scientific\nAssessment. National Academy of Sciences, Washington, DC.\n\n\nFourier, Joseph. 1827. “Mémoire Sur Les\nTempératures Du Globe Terrestre Et Des Espaces\nPlanétaires.” Mémoires de\nl’Académie Royale Des Sciences de l’Institut de France\n7: 570–604.\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36.\nSpringer.\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate.\nSIAM.\n\n\nKrauskopf, Bernd, Hinke M Osinga, and Jorge Galán-Vioque. 2007.\nNumerical Continuation Methods for Dynamical Systems. Vol. 2.\nSpringer.\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot\nAir. UIT Cambridge Ltd.\n\n\nPouillet, Claude Servais Mathias. 1838. “Memoire Sur Le Chaleur\nSolaire.” Paris.\n\n\nSpence, Alastair, and Ivan G Graham. 1999. “Numerical Methods for\nBifurcation Problems.” In The Graduate Student’s Guide to\nNumerical Analysis’ 98, 177–216. Springer.\n\n\nStommel, Henry. 1961. “Thermohaline Convection with Two Stable\nRegimes of Flow.” Tellus 13 (2): 224–30.\n\n\nVan der Veen, CJ. 2000. “Fourier and the ‘Greenhouse\nEffect’.” Polar Geography 24 (2): 132–52."
  },
  {
    "objectID": "part-05-techniques/asymptotics03.html",
    "href": "part-05-techniques/asymptotics03.html",
    "title": "12  Matched asymptotics",
    "section": "",
    "text": "2022-23 note\n\n\n\nThis material has not yet been finalised and is still under construction. Once it is covered in lectures, this banner will be replaced."
  },
  {
    "objectID": "part-xx-exercises/problemclass02.html",
    "href": "part-xx-exercises/problemclass02.html",
    "title": "13  Problem class 2",
    "section": "",
    "text": "2022-23 note\n\n\n\nThis material has not yet been finalised and is still under construction. Once it is covered in lectures, this banner will be replaced."
  },
  {
    "objectID": "part-xx-exercises/ps02.html",
    "href": "part-xx-exercises/ps02.html",
    "title": "28  Problem set 2",
    "section": "",
    "text": "The intention of this problem set is to practice concepts from Chapter 8 (asymptotic approximations of algebraic equations) to Chapter 10 (Euler’s method and numerical solutions of differential equations). These techniques form some of the most powerful techniques at your disposal in applied maths.\n\nMake a table of the errors of the quadratic example.\nStudy a cubic example."
  },
  {
    "objectID": "part-xx-exercises/ps02.html#analysis-of-singular-cubic-equation",
    "href": "part-xx-exercises/ps02.html#analysis-of-singular-cubic-equation",
    "title": "28  Problem set 2",
    "section": "28.3 Analysis of singular cubic equation",
    "text": "28.3 Analysis of singular cubic equation\nConsider the cubic equation \\[\n\\epsilon x^3 + x - 1 = 0,\n\\] with \\(\\epsilon \\ll 1\\).\n\nDevelop the first three terms of an asymptotic expansion about the root by setting \\[\nx = x_0 + \\epsilon x_1 + \\epsilon x_2 + \\ldots\n\\]\nFill out the following table.\n\n\n\n\\(\\epsilon\\)\n\\(x_{\\text{exact}}\\)\n\\(x_{\\text{exact}} - x_0\\)\n\n\n\n\n1.0\n–\n–\n\n\n0.9\n–\n–\n\n\n0.8\n–\n–\n\n\n…\n–\n–\n\n\n0.1\n–\n–\n\n\n\nUse your code in Section 28.2 to input numerical approximations to the above entries.\nCreate a graph by hand of the data (it does not have to be extremely accurate), as plotted in the \\((\\epsilon, x_{\\text{exact}} - x_0)\\)-plane. Fit a line to this graph and estimate the gradient. Is this consistent with what you derived above?\nBy rescaling \\(x\\) appropriately in terms of \\(\\epsilon\\), derive the first three terms of the asymptotic approximations of the remaining roots."
  },
  {
    "objectID": "part-xx-exercises/ps02.html#getting-started-with-jupyter",
    "href": "part-xx-exercises/ps02.html#getting-started-with-jupyter",
    "title": "28  Problem set 2",
    "section": "28.1 Getting started with Jupyter",
    "text": "28.1 Getting started with Jupyter\nGo online to the Jupyter hub at https://maths.jupyterhub.bath.ac.uk.\n\nNavigate to the welcome screen for MA30287 and follow the instructions in order to create your own local directory at /MA30287_workspace/\nNavigate to the workspace folder. Click New -> Notebook. If asked, select the kernel Python 3 (ipykernel).\nIn the first line of input, select, in toolbar Code -> Markdown. This allows you to annotate your notebook with Markdown-style text input.\nIn the first line of input, type # Problem set 2. Then either type Shift + Enter or press the play button which will execute the line(s) of input. Your markdown text should render as a nicely formatted entry.\nRename the file to something appropriate, like ps02_scripts. You can do this by right-clicking the filename in the file manager and selecting Rename.\nProceed to the next question."
  },
  {
    "objectID": "part-xx-exercises/ps02.html#testing-the-solutions-of-a-cubic",
    "href": "part-xx-exercises/ps02.html#testing-the-solutions-of-a-cubic",
    "title": "28  Problem set 2",
    "section": "28.2 Testing the solutions of a cubic",
    "text": "28.2 Testing the solutions of a cubic\nIn this question, you will develop the numerical solutions for the roots of the cubic equation: \\[\n\\epsilon x^3 + x - 1 = 0.\n\\]\nType the following code into your Jupyter notebook. This code uses a command, which you will learn in a later week, called fsolve, in order to solve nonlinear equations. When writing the below code, you may want to separate the import commands into their own input field in the notebook.\n\nimport numpy as np\nfrom scipy.optimize import fsolve\n\nep = 0.2        # epsilon value\nxguess = 1.1    # Initial guess of root\n\nf = lambda x: ep*x**3 + x - 1\nxsol = fsolve(f, xguess)\nprint(\"Solved root at x = \", xsol)\n\nSolved root at x =  [0.86883002]"
  },
  {
    "objectID": "part-xx-exercises/ps02.html#sec-ps2-cubic",
    "href": "part-xx-exercises/ps02.html#sec-ps2-cubic",
    "title": "28  Problem set 2",
    "section": "28.2 Testing the solutions of a cubic",
    "text": "28.2 Testing the solutions of a cubic\nIn this question, you will develop the numerical solutions for the roots of the cubic equation: \\[\n\\epsilon x^3 + x - 1 = 0.\n\\]\nType the following code into your Jupyter notebook. This code uses a command, which you will learn in a later week, called fsolve, in order to solve nonlinear equations. When writing the below code, you may want to separate the import commands into their own input field in the notebook.\n\nimport numpy as np\nfrom scipy.optimize import fsolve\n\nep = 0.2        # epsilon value\nxguess = 1.1    # Initial guess of root\n\nf = lambda x: ep*x**3 + x - 1\nxsol = fsolve(f, xguess)\nprint(\"Solved root at x = \", xsol)\n\nSolved root at x =  [0.86883002]"
  },
  {
    "objectID": "part-xx-exercises/ps02.html#epsilon-x_textexact-x_textexact---x_0",
    "href": "part-xx-exercises/ps02.html#epsilon-x_textexact-x_textexact---x_0",
    "title": "28  Problem set 2",
    "section": "28.4 | \\(\\epsilon\\) | \\(x_{\\text{exact}}\\) | \\(x_{\\text{exact}} - x_0\\) |",
    "text": "28.4 | \\(\\epsilon\\) | \\(x_{\\text{exact}}\\) | \\(x_{\\text{exact}} - x_0\\) |\n\nMake a table of the errors of the quadratic example.\nStudy a cubic example."
  },
  {
    "objectID": "part-xx-exercises/ps02.html#section",
    "href": "part-xx-exercises/ps02.html#section",
    "title": "28  Problem set 2",
    "section": "28.4 ",
    "text": "28.4"
  },
  {
    "objectID": "part-xx-exercises/ps02.html#a-damped-projectile-problem",
    "href": "part-xx-exercises/ps02.html#a-damped-projectile-problem",
    "title": "28  Problem set 2",
    "section": "28.4 A damped projectile problem",
    "text": "28.4 A damped projectile problem\nIn Chapter 9 you performed the asymptotic analysis for a projectile. The small parameter was \\(\\epsilon\\) and represented \\(v_0^2/(gR_E)\\) (a parameter that includes the initial velocity, \\(v_0\\), gravity \\(g\\), and the radius of the Earth, \\(R_E\\).\nIf air resistance is included, then the non-dimensional toy model is instead \\[\n\\begin{gather}\n\\frac{\\mathrm{d}^2 y}{\\mathrm{d}t^2} = - \\frac{1}{(1 + \\epsilon y)^2} - \\frac{\\alpha}{(1 + \\epsilon y)} \\frac{\\mathrm{d}y}{\\mathrm{d}t}, \\\\\ny(0) = 0, \\\\\ny'(0) = 1.\n\\end{gather}\n\\tag{28.1}\\] where \\(\\alpha \\geq 0\\) is the parameter that controls air resistance.\n\nBegin by assuming that \\(\\alpha\\) is a fixed number and consider the limit where \\(\\epsilon \\ll 1\\). Find a two-term asymptotic expansion of the solution for small \\(\\epsilon\\).\nIs the effect of the air resistance to increase or decrease the flight time? Justify based on your analytical solution."
  },
  {
    "objectID": "part-xx-exercises/ps02.html#ode-solvers-and-eulers-method",
    "href": "part-xx-exercises/ps02.html#ode-solvers-and-eulers-method",
    "title": "28  Problem set 2",
    "section": "28.5 ODE solvers and Euler’s method",
    "text": "28.5 ODE solvers and Euler’s method\nReturn to the setup of the above question.\n\nModify the script developed in lecture 8 or alternatively copy-and-paste the script shown in Section 9.2 in order to solve (Equation 28.1) at a prescribed value of \\(\\epsilon\\) and \\(\\alpha\\).\nUsing a pocket calculator (or your phone calculator) apply Euler’s method with \\(\\Delta t = 0.2\\), \\(\\epsilon = 0.2\\), and \\(\\alpha = 1\\) to determine the position of the projectile at \\(t = 0.6\\).\nCompare your hand calculation with the result from the Python output, as well as with your asymptotic approximations."
  },
  {
    "objectID": "part-05-techniques/asymptotics02.html#sec-asym2-num",
    "href": "part-05-techniques/asymptotics02.html#sec-asym2-num",
    "title": "9  Asymptotic approximations of ODEs",
    "section": "9.2 Numerical solutions of IVPs",
    "text": "9.2 Numerical solutions of IVPs\nWe first demonstrate how to solve ODEs (initial-value-problems, IVPs) using black-box functions in Python. For starters, most numerical formulations for ODEs will require that the problem be posed in terms of a first-order system of equations. To convert (Equation 9.1) into such a form, create a set of unknowns for the derivatives. Set \\[\n\\mathbf{Y}(t) =\n\\begin{pmatrix}\ny_1(t) \\\\\ny_2(t)\n\\end{pmatrix}\n= \\begin{pmatrix}\ny(t) \\\\\ny'(t)\n\\end{pmatrix}\n\\]\nThen we have the following first-order system: \\[\n\\begin{align}\n\\mathbf{Y}'(t) &= \\mathbf{F}(t, \\mathbf{Y}(t)) = \\begin{pmatrix}\ny_1' \\\\\n- \\frac{1}{(1 + \\epsilon y_1)^2}\n\\end{pmatrix} \\\\\n\\mathbf{Y}(0) &= \\begin{pmatrix}\n0 \\\\\n1\n\\end{pmatrix}\n\\end{align}\n\\tag{9.2}\\]\nYou can find a little guide on using solve_ivp in Python here. Here is the Python code to solve the differential equation.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import solve_ivp\n\nep = 0.2 # epsilon value\ntmax = 2 # max time\nt = np.linspace(0, tmax, 100) # mesh used for plotting\n\n# Define function for the ODE\ndef f(t, Y):\n    ep = 0.2\n    y, yp = Y\n    ypp = -1/(1 + ep*y)**2\n    return [yp, ypp]\n\n# define the initial condition\nY0 = [0, 1]\n\nsol = solve_ivp(f, [0, tmax], Y0, dense_output=True)\n\n# Prior to plotting, re-interpolate solution on a fine grid\nyy = sol.sol(t)\n# Asymptotic solutions\ny0 = -1/2*t**2 + t\ny1 = -1/12*t**4 + 1/3*t**3\n\n# Plot it all\nplt.plot(t, yy[0,])\nplt.plot(t, y0, '--')\nplt.plot(t, y0 + ep*y1, '--')\nplt.xlabel('t')\nplt.ylabel('y(t)')\n\nText(0, 0.5, 'y(t)')\n\n\n\n\n\nThe two-term approximation does beautifully well, even at this moderate value of \\(\\epsilon = 0.2\\)."
  }
]