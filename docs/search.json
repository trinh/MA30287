[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "",
    "text": "Preface\nWelcome to to the 2022-23 delivery of MA30287 Maths of Planet Earth at the University of Bath.\nHere is a picture that represents the course."
  },
  {
    "objectID": "index.html#lectures-and-office-hours",
    "href": "index.html#lectures-and-office-hours",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "Lectures and office hours",
    "text": "Lectures and office hours\nLectures take place at the following times and locations:\n\nTuesdays 9:15 in 4E 3.10\nWednesdays 11:15 in 8W 3.22\nThursdays 15:15 in 8W 3.22\n\nOffice hours: You will be able to find me for an office hour in 4W 2.18 on Thursdays (following the lecture). Typically it is best to set this up, beforehand, by email appointment."
  },
  {
    "objectID": "index.html#coursework-and-examinations",
    "href": "index.html#coursework-and-examinations",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "Coursework and examinations",
    "text": "Coursework and examinations\nYour final mark will be 25% coursework and 75% final exam.\nDetails of the coursework will be released in Week 7 and it will be due in Week 101."
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "Resources",
    "text": "Resources\nIn general, you will have access to a few kinds of resources:\n\nThe Moodle portal will be the main organisation portal.\nLecture notes, coursework, and other resources will be found in an online format and will be linked on Moodle.\nCoding will be done via the website https://maths.jupyterhub.bath.ac.uk.\n\nNaturally, because this is an entirely new module at Bath, there will be a fair amount of activity as we settle the material over the semester. Whenever we complete a lecture note (i.e. a ‘chapter’), we will use a box like this to indicate when the material was covered and in which lecture:\n\n\n\n\n\n\n2022-23 note\n\n\n\nThe material in this note was covered in Lecture XX.\n\n\nHopefully by the time the module ends, every relevant chapter will have such a note. This allows you to judge what material has been ‘finalised’."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis course officially requires MA20221 (modeling and dynamical systems) or XX20231 (mathematical and statistical methods for the life sciences).\nIt is designed to be somewhat stand-alone in the sense that applied mathematical techniques learned in other courses will be introduced in some capacity. Such techniques will involve:\n\nSolutions of ordinary differential equations (MA10230 and MA20220).\nMultivariable calculus, partial differentiation, and multiple integrals (MA10230 and MA10236); some review/introduction of concepts from MA20223.\nDynamical systems, stability, phase planes (MA20221, MA30060).\nNumerical methods in Python (MA10276).\n\nWhenever possible, I have isolated such reviews/introductions and these can be found in the Mathematical methods section of these notes."
  },
  {
    "objectID": "index.html#resources-1",
    "href": "index.html#resources-1",
    "title": "MA30287: Mathematics of Planet Earth",
    "section": "Resources",
    "text": "Resources\nThis course is designed around the following sources:\n\nSustainable energy – without the hot air by (MacKay 2009)\nMathematics & Climate by (Kaper and Engler 2013)\nMathematical Geoscience by (Fowler 2011)\nA gentle introduction to numerical simulations with Python\n\n\n\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36. Springer.\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM.\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-01-intro/intro.html",
    "href": "part-01-intro/intro.html",
    "title": "Introduction",
    "section": "",
    "text": "2022-23 note\n\n\n\nCovered in lecture 1.\n\n\nMathematics of Planet Earth seems like an incredibly broad description for a course, but perhaps in order to give a rough idea of what such a course might include, we can consider the following diagram, which illustrates different categories and subject areas that are involved in the modelling of a full Earth system.\n\n\n\nFigure 1: The many components of a full Earth System Model (image from Nature; citation needed\n\n\nIt would be possible to spend a lifetime studying any one aspects of the above categories, and they span many different areas of study, including: (i) engineering (civil, fluids, mechanical, etc.); (ii) physics (geosciences, mechanics); (iii) Earth sciences; (iv) policy and health; and so forth and so on. As mathematicians, we also have a unique perspective, and applied mathematics plays important roles in many of the above categories.\nIn essence, this course will divide into three themes, each theme centred upon a different style of study. All of these themes are united by aspects of mathematical modelling and mathematical analysis and this is what distinguishes our style of study from adjacent areas of science and social science.\n\nIn the first part of the course, we will use back-of-the-envelope mathematics, and conservation-style arguments to study various aspects of energy consumption and energy renewal. This involves, for example, estimating your own energy usage, and developing a basic understanding of the mechanics of some renewable technologies. The source for this part of the course will be (MacKay 2009).\nIn the second part of the course, we will study so-called conceptual or box models of the climate. This involves some of the blue elements of Figure 1, and thus we use coarse-grained models of describing the climate. This will involve applying some of the dynamical systems (phase-plane analysis of ODEs) you have learned previously, along with new methods of computation and analysis. The source for this part of the course will be (Kaper and Engler 2013).\nFinally, the last part of the course will involve more in-depth analysis of the physical models that govern the blue elements of Figure 1. This moves us from the toy box models studied above to digging into the underlying physics—this also falls into the category of Mathematical Geoscience. For example, we will use partial differential equations to study the atmosphere and develop a deeper understanding of greenhouse gases. The source for this part of the course will be (Fowler 2011).\n\n\n\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36. Springer.\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM.\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-01-intro/intro-PDEs.html",
    "href": "part-01-intro/intro-PDEs.html",
    "title": "1  Conservation laws and consitutive laws",
    "section": "",
    "text": "2022-23 note\n\n\n\nCovered in lecture 1.\n\n\nIn the first chapter of (Fowler 2011), there is a concise introduction to the different categories of techniques and approaches that you might use when doing mathematical modelling in the real world. Some of these ideas will be introduced to you in this course.\nHere, we provide a brief intro to the highlights, involving the use of conservation laws (and PDEs) and also the concept of non-dimensionalisation (which you would have encountered previously), studied in Chapter 2.\n\n\n\n\n\n\nVectors and PDEs\n\n\n\nVectors and PDEs is not a prerequisite for this course, but naturally in studying anything related to the physical real world, we must discuss partial differential equations. The hope is that the necessary theory for PDEs will be presented to you as this course evolves, so that it can appreciated by both newcomers and experienced readers.\n\n\nConservation laws can be expressed as mathematical equations that represent the idea that some quantity is conserved. In processes governing the planet, these might correspond to conservation of heat, of water, of air, of momentum, etc.\nIn Chapter 3, we will develop the simplest possible model governing the temperature on the surface of the Earth. It is a conservation equation for energy and is zero-dimensional (does not involve time and does not involve spatial variation).\nIn order to demonstrate some of the basic principles of this course, let us demonstrate the derivation of the heat equation. We are interested in modelling the heat in a volume, \\(V\\), which, for the sake of concreteness is given by a long cylinder with its axis along \\(x \\in [0, L]\\). We assume that the side walls of the cylinder are insulated and the temperature only varies along the \\(x\\) direction.\nAt any point along this rod, the internal heat is given by \\(\\rho c T(x, t)\\), where \\(\\rho\\) is the density of the material (kg/m3), \\(c\\) is the specific heat capacity (J/(kg K)), and \\(T\\) is the temperature (K). Therefore, the heat energy along any segment in the rod is calculated from\n\n\n\n\n\n\nInternal heat energy\n\n\n\n\\[\n\\text{heat energy in $[a, b]$} = \\int_a^b \\rho c T \\, \\mathrm{d}x.\n\\]\n\n\nIf the heat changes, then the rate of change of heat energy is given the time derivative of the above quantity. By conservation of energy, any change of the internal energy must be equal to the inflow or outflow of heat at the ends, \\(x = a\\) or \\(x = b\\). We therefore write \\(q\\) for the flux (or flow) of heat.\nWe need a constitutive law that dictates how energy is exchanged at the boundaries. Based on intuition, it is sensible to assume that the flow of heat proceeds from hot to cold. For example, hot air rises towards cool air; or heat from a hot mug of tea flows and diffuses outwards into a cold room. Therefore, we write this as\n\n\n\n\n\n\nFourier’s law\n\n\n\nFourier’s law in 1D specifies that the heat flux is given by \\[\nq(x, t) = -k \\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}x}.\n\\]\n\n\nThis is known as Fourier’s law. The quantity \\(k\\) is the thermal conductivity, and its units are W/(m K). Because a Watt is a Joule/s, you can also see that the units of \\(k\\) are J/(m K s). The quantity \\(q\\) is the flux, and you can verify that it is given in units of J/(m2 s).\nTherefore by energy conservation, we have \\[\n\\frac{\\mathrm{d}}{\\mathrm{d}t}  \\int_a^b \\rho c T \\, \\mathrm{d}x = q(x = b, t) - q(x = a, t),\n\\] i.e. the change in internal heat is equal to the flow through the ends. Substitution Fourier’s law, we can then write \\[\n\\int_a^b \\rho c \\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}t} \\, \\mathrm{d}x = \\int_a^b k \\frac{\\mathrm{\\partial}^2 T}{\\mathrm{\\partial}x^2} \\, \\mathrm{d}x.\n\\] We then argue that because the above needs to be true for all segments [a, b] within the rod, then it must be true everywhere. Therefore we are left with the classic heat equation.\n\n\n\n\n\n\nHeat equation\n\n\n\n\\[\n\\rho c\\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}t} = k \\frac{\\mathrm{\\partial}^2 T}{\\mathrm{\\partial}x^2}.\n\\tag{1.1}\\]\n\n\nIn order to produce a sensible physical solution, the above equation is typically supplemented by initial conditions and boundary conditions. An example might be\n\n\n\n\n\n\nInitial and boundary conditions\n\n\n\n\\[\n\\begin{gather}\nT(x, 0) = T_0 \\\\\nT(0, 0) = T_a \\\\\nT(L, 0) = T_b\n\\end{gather}\n\\]\n\n\nwhich expresses, respectively, that the temperature starts from a constant temperature, \\(T_0\\), and where the ends of the rod are kept at temperature \\(T_a\\) and \\(T_b\\). In courses like MA20223, you may have learned how to solve the above equation.\n\n\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36. Springer."
  },
  {
    "objectID": "part-01-intro/intro-nondim.html#dimensional-quantities",
    "href": "part-01-intro/intro-nondim.html#dimensional-quantities",
    "title": "2  Dimensional scaling analysis",
    "section": "2.1 Dimensional quantities",
    "text": "2.1 Dimensional quantities\nEvery physical quantity, say Q, can be expressed as a product of a dimensional unit, denoted [Q], and a magnitude, say Q’. Thus we write \\[\nQ = Q'[Q]\n\\] For example, if \\(x\\) corresponds to the physical length in a problem, we might select \\([x] = \\mathrm{km}\\) or \\([x] = \\mathrm{yards}\\) or \\([x] = \\mathrm{m}\\). It is important to choose the dimensionalisation to suit the problem under consideration.\n\n2.1.1 SI units\nThe International System (SI) of Base Units sets out a distinct selection of choices for dimensions in certain physical quantities. The seven fundamental dimensional units are\n\n[Length] = metre\n[Time] = seconds\n[Mass] = kilogram\n[Temperature] = Kelvin\n[Electric current] = ampere\n[Light intensity] = candela\n[Material quantity] = mole\n\nDimensional units that can be expressed in terms of other fundamental units are known as derived units. For example:\n\n[Speed] = metre/second\n[Acceleration] = metre/second2\n[Force] = kilogram . metre/second2"
  },
  {
    "objectID": "part-01-intro/intro-nondim.html#dimensional-homogeneity-and-non-dimensionalisation",
    "href": "part-01-intro/intro-nondim.html#dimensional-homogeneity-and-non-dimensionalisation",
    "title": "2  Dimensional scaling analysis",
    "section": "2.2 Dimensional homogeneity and non-dimensionalisation",
    "text": "2.2 Dimensional homogeneity and non-dimensionalisation\nAll terms in any equation must have the same dimensions. This is the principle of dimensional homogenuity. For example, Newton’s second law expresses the fact that \\[\nF = m \\frac{\\mathrm{d}^2x}{\\mathrm{d}t^2}\n\\] We can check, then, that the units do indeed match up on either side. Here, the RHS has units of [m] [x]/[t]2 or in SI units, kg . metres / seconds2. This indeed matches our previous given SI unit decomposition for force.\nNotice in addition that the input to functions like \\(\\cos\\theta\\) and \\(e^z\\) must be non-dimensional (or dimensionless).\nThe process of nondimensionalisation is then as follows. Given an equation, we know that each term must have the same dimension. Therefore, we can scale all the dependent and independent variables by dimensional constants in order to yield a non-dimensional equation.\nWhy this is an important tool is demonstrated by the below."
  },
  {
    "objectID": "part-01-intro/intro-nondim.html#returning-to-the-heat-equation",
    "href": "part-01-intro/intro-nondim.html#returning-to-the-heat-equation",
    "title": "2  Dimensional scaling analysis",
    "section": "2.3 Returning to the heat equation",
    "text": "2.3 Returning to the heat equation\nExact units are not relevant for dynamics, and it is instead the ratio of units that we care about. To apply this principle, let us non-dimensionalise the equation Equation 1.1. We introduce typical scales for each of the variables. For example, we non-dimensionalise the temperature and distance by setting \\[\nT = T_0 T' \\quad \\text{and} \\quad x = L x',\n\\] where primes now denote non-dimensional quantities. Since it is not clear how to scale time, we set \\(t = [t] t;'\\) and choose the scale later. Substitution into the equation now yields \\[\\begin{gather}\n\\frac{\\rho c T_0}{[t]}\\frac{\\mathrm{\\partial}T'}{\\mathrm{\\partial}t'} = \\frac{kT_0}{L^2} \\frac{\\mathrm{\\partial}^2 T'}{\\mathrm{\\partial}x'^2}, \\\\\nT(x, 0) = 1 \\\\\nT(0, 0) = \\frac{T_a}{T_0}, \\\\\nT(L, 0) = \\frac{T_b}{T_0}.\n\\end{gather}\\]\nIt is useful to think of time in terms of velocity and distance. Let us then write \\[\n[t] = L/U,\n\\] where \\(U\\) is a typical velocity scale (which again, we shall specify later). Then note that the heat equation can be written as \\[\n\\frac{\\rho c}{(L/U)} \\frac{\\mathrm{\\partial}T'}{\\mathrm{\\partial}t'} = \\frac{k}{L^2}\\frac{\\mathrm{\\partial}^2 T'}{\\mathrm{\\partial}x'^2}.\n\\] We can move all the units to one side and then write \\[\n\\frac{\\mathrm{\\partial}T'}{\\mathrm{\\partial}t'} =\\text{Pe} \\frac{\\mathrm{\\partial}^2 T'}{\\mathrm{\\partial}x'^2}.\n\\tag{2.1}\\]\nWe can verify that the quantity \\[\n\\mathrm{Pe} =  \\frac{k/(\\rho c L^2)}{U/L} = \\frac{\\text{diffusive timescale}}{\\text{advective timescale}}.\n\\] known as the Peclet number is entirely non-dimensional. This number essentially charactises the balance between diffusive effects (which causes heat to spread out) versus advective effects (the transport of the heat). In the case of our problem, there is no obvious source of advection. Another way to see this is that the temporal or velocity scale is entirely free for us to select.\nWe can now choose the temporal scale so as to simplify the equation. Let us choose \\[\n[t] = \\frac{L}{U} = \\frac{\\rho c L^2}{k}.\n\\tag{2.2}\\]\nNow the system simplifies. We can now write \\[\n\\begin{gather}\n\\frac{\\mathrm{\\partial}T'}{\\mathrm{\\partial}t'} = \\frac{\\mathrm{\\partial}^2 T'}{\\mathrm{\\partial}x'^2} \\\\\nT'(x', 0) = 1 \\\\\nT'(0, 0) = A, \\\\\nT'(1, 0) = B.\n\\end{gather}\n\\tag{2.3}\\]\nWe have gone from a system where we needed to consider six parameters to one where we only need to specify two (essentially, the ratio of the initial heat to the boundary values). Imagine you are an engineer at a thermal company, and asked to study the different possible configurations of heat in the above setup. If you were to blindly perform numerical computations, you would have had to set specific values for each of the six parameters.\nInstead, some mathematical analysis has demonstrated that the six-dimensional space of parameters can be simplified to a two-dimensional one—this is an enormous simplification.\nYour analysis has further identified the key non-dimensional parameter that appears in Equation 2.1. This demonstrates that it is not the individual values of \\(k\\), \\(\\rho\\), \\(c\\), … that matter, but rather their specific combination in the form of the Peclet number."
  },
  {
    "objectID": "part-01-intro/intro-nondim.html#gi-taylor-and-the-atomic-bomb",
    "href": "part-01-intro/intro-nondim.html#gi-taylor-and-the-atomic-bomb",
    "title": "2  Dimensional scaling analysis",
    "section": "2.4 GI Taylor and the atomic bomb",
    "text": "2.4 GI Taylor and the atomic bomb\n\n\n\n\n\n\n2022-23 note\n\n\n\nDuring Lecture 3 we will cover some aspects of how non-dimensionalisation was famously used by British fluid dynamicist GI Taylor to estimate the energy of the atom bomb. Students can refer to the visualiser notes.\n\n\n\n\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36. Springer."
  },
  {
    "objectID": "part-01-intro/basic-energy-model.html#the-basic-energy-model",
    "href": "part-01-intro/basic-energy-model.html#the-basic-energy-model",
    "title": "3  Basic energy models",
    "section": "3.1 The basic energy model",
    "text": "3.1 The basic energy model\nThe basic model is derived as follows.\n\nBy considering the incoming radiation from the sun, obtain an estimate for the incoming energy, \\(E_{\\text{in}}\\).\nUse a constitutive law that indicates how much outgoing energy is produced by an object heated to some temperature.\nEquate the change in internal energy to be equal to the difference between the above two items.\n\nNote that the primary components of the global energy balance are radiative fluxes: we receive short-wave radiation (UV and visible light) from the Sun, and emit longwave radiation (infra-red) to space.\n\n\n\nFigure 3.1: Radiation in the atmosphere\n\n\nFirst we consider incoming energy.\n\n\n\n\n\n\nEnergy from the Sun\n\n\n\nFirst, note that the shortwave radiation (UV and radiation) recieved from the sun is \\(Q \\approx 1370 \\text{ W$\\cdot$m$^{-2}$}\\) (which we consider measured at a point near the planet).\nIf we consider only that radiation that is absorbed into the Earth, we have \\[\nE_{\\mathrm{in}} = \\pi R^2 Q (1 - a),\n\\tag{3.2}\\] where \\(R\\) is the Earth’s radius.\nIn the above formula, we have multiplied the flux, \\(Q\\), with the visible surface area, \\(\\pi R^2\\). There is an additional multiplication by \\((1 - a)\\) where \\(a\\) is the planetary albedo, which characterises amount of energy reflected due to the surface properties. Light surfaces like snow will have high albedo, \\(a \\approx 0.9\\), while darker surfaces like the ocean have smaller albedo, \\(a \\approx 0.3\\). The global average albedo is \\(a \\approx 0.3\\).\n\n\nNext we consider outgoing energy.\n\n\n\n\n\n\nEnergy from the Earth\n\n\n\nWe now wish to characterise the energy, \\(E_{out}\\), and in the case of Earth, this will correspond to longwave radiation (infra-red) emitted into space. All bodies characterised by a temperature, say \\(T_e\\), will emit radiation, \\(Q_e\\). As a model, we can consider \\(Q_e\\) to be given by the Stefan-Boltzmann law, which states that \\[\nQ_e = \\sigma T_e^4,\n\\tag{3.3}\\] where \\(\\sigma \\approx 5.67 \\times 10^{-8} W m^{-2} K^{-4}\\) is the Stefan-Boltzmann constant.\nNow although the Earth’s surface may emit radiation according to (Equation 3.3), some of this radiation will be absorbed by the atmosphere and reflected back. This is the greenhouse effect. As a consequence of the greenhouse gas, the surface temperature of the Earth, \\(T\\), will be larger than the effective emitting temperature, \\(T_e\\). For the moment, we model this as \\[\nT_e = \\gamma^{1/4} T_e,\n\\tag{3.4}\\] where \\(\\gamma < 1\\) is a greenhouse gas factor, which depends on the properties of the atmosphere.\n\n\nNow combining the above equations, we have \\[\nE_{\\mathrm{in}} - E_{\\mathrm{out}} = \\pi R^2 Q (1 - a) - 4\\pi R^2 \\sigma \\gamma T^4,\n\\tag{3.5}\\] which gives the incoming energy per unit time.\n\n\n\n\n\n\nInternal heat energy\n\n\n\nDue to this incoming energy, the Earth will cool or heat in response. We need to know how the internal temperature of an object responds to an input in energy. The general formula is \\[\n\\text{Internal heat energy} = \\text{volume} \\times (\\rho c_p) \\times T.\n\\] The key quantity is the experimentally determined, \\(c_p\\), which corresponds to the specific heat capacity. It is given in the SI units of \\(\\mathrm{J} \\cdot \\mathrm{kg}^{-1} \\cdot \\mathrm{K}^{-1}\\), i.e. energy per unit mass per unit temperature. Note that this applied to a shell around the planet of thickness \\(d\\) in the atmosphere, and so the mass is given by \\[\n\\text{mass} = (4 \\pi R^2) d \\rho\n\\tag{3.6}\\] where \\(\\rho\\) is the average density of the atmosphere. Let us imagine the increase in temperature, \\(\\Delta T\\),during an interval of time, \\(\\Delta t\\). You can now verify that \\[\n\\Bigl[ (4 \\pi R^2) d \\rho \\Bigr] c_p (\\Delta T)\n\\] returns the units of Joules—i.e. this is the internal energy produced during the time \\(\\Delta t\\). We then have \\[\n\\Bigl[ (4 \\pi R^2) d \\rho \\Bigr] c_p \\Delta T =  \\Delta t (E_{in} - E_{out}).\n\\]\n\n\nPutting in (Equation 3.5) and taking the limit of \\(\\Delta t \\to 0\\), we finally have a heat equation for the Earth’s temperature.\n\n\n\n\n\n\nZero-dimensional model for the surface temperature of the Earth\n\n\n\nThe Earth’s temperature, as measured on a layer of thickness \\(d\\) at the troposphere is given by the following ordinary differential equation (ODE) for \\(T = T(t)\\): \\[\nC \\frac{\\mathrm{d}T}{\\mathrm{d}t} = \\frac{1}{4} Q(1 - a) - \\sigma \\gamma T^4,\n\\tag{3.7}\\] where we have defined \\[\nC = \\rho c_p d\n\\] as the heat capacity of the atmosphere. Above, the solar flux, Q is often taken to be \\(Q = 1370\\) W/m2, \\(\\sigma = 5.67 \\times 10^{-8}\\) W/(m2K4), and \\(\\gamma \\leq 1\\) is the greenhouse gas factor.\n\n\nThe above equation Equation 3.7 is time-dependent, but we may consider that the surface temperature, either over long-time or in an averaged sense, is dictated by the steady-state (time-independent) solution. Setting \\(\\mathrm{d}T/\\mathrm{d}t\\) to zero, we see that there is a unique steady-state given by \\[\nT = \\left(\\frac{Q(1-a)}{4\\sigma\\gamma}\\right)^{1/4}.\n\\]\nIf we take \\(Q \\approx 1370 \\,\\mathrm{W m}^{-2}\\), \\(a \\approx 0.3\\), \\(\\sigma \\approx 5.67 \\times 10^{-8} \\mathrm{W} \\,\\mathrm{m}^{-2} \\mathrm{K}^{-4}\\), we then get \\[\nT \\approx 255 \\mathrm{K} = -18^\\circ \\mathrm{C}.\n\\] under the assumption that \\(\\gamma = 1\\). That’s pretty cold! The actual average temperature is around \\(288 \\mathrm{K} \\approx 15 ^\\circ \\mathrm{C}\\).\nThe above back-of-the-envelope calculation seems to suggest that the parameter \\(\\gamma < 1\\) plays an important role in keeping the Earth warm enough for us to live on, and indeed the value of \\(\\gamma\\) inferred by the above is roughly \\(\\gamma \\approx 0.61\\). Later on in the course, we will develop a more rigorous model to predict such a \\(\\gamma\\) by studying the properties of the atmosphere."
  },
  {
    "objectID": "part-01-intro/basic-energy-model.html#the-history-of-global-warming",
    "href": "part-01-intro/basic-energy-model.html#the-history-of-global-warming",
    "title": "3  Basic energy models",
    "section": "3.2 The history of global warming",
    "text": "3.2 The history of global warming\nThe history of global warming (and hence the estimation of \\(\\gamma\\)) is convoluted, but the origins can be considered as far back as the work of (Fourier 1827) and (Pouillet 1838), and is discussed in the work by (Van der Veen 2000).\n\n\n\nFigure 3.2: An illustration of Fourier’s glass box\n\n\n\n\n\n\nFourier, Joseph. 1827. “Mémoire Sur Les Températures Du Globe Terrestre Et Des Espaces Planétaires.” Mémoires de l’Académie Royale Des Sciences de l’Institut de France 7: 570–604.\n\n\nPouillet, Claude Servais Mathias. 1838. “Memoire Sur Le Chaleur Solaire.” Paris.\n\n\nVan der Veen, CJ. 2000. “Fourier and the ‘Greenhouse Effect’.” Polar Geography 24 (2): 132–52."
  },
  {
    "objectID": "part-01-intro/problemclass01.html#projectile-motion",
    "href": "part-01-intro/problemclass01.html#projectile-motion",
    "title": "4  Problem class 1",
    "section": "4.1 Projectile motion",
    "text": "4.1 Projectile motion\nA projectile of mass \\(M\\) (in kg) is launched vertically with initial velocity \\(V_0\\) (in m/s) from a position \\(Y_0\\) (in m) above the surface. Thus the mass’s position, \\(Y(t)\\) is governed by Newton’s second law (applied to the mass and the mass of the Earth) and the set of equations \\[\\begin{gather}\nM Y_{tt} = - \\frac{g R_E^2 M}{(R_E + Y)^2}, \\\\\nY(0) = Y_0,\n\\end{gather}\\] where \\(g = 9.81 m/s^2\\) and \\(R_E = 6.4 \\times 10^6 m\\) is the radius of the Earth.\n\nNon-dimensionalise the equation using arbitary length and time scales.\nIdentify the non-dimensional constants, \\(\\Pi_i\\).\nChoose a length scale of \\(L = Y_0\\) and time scale of \\(T = (L/g)^{1/2}\\). Discuss the resultant equation and the interpretation of choosing these scales.\nDoes your above choice allow you to easily study the limit of \\(R_E \\to \\infty\\)? If the limit can be taken, reduce the governing system to a simpler equation.\nDoes your choice in 3. allow you to easily study the limit of \\(Y_0 \\to 0\\)? If not, choose an alternative choice of length and time scales and in that case, reduce the set of equations."
  },
  {
    "objectID": "part-01-intro/problemclass01.html#terminal-velocity",
    "href": "part-01-intro/problemclass01.html#terminal-velocity",
    "title": "4  Problem class 1",
    "section": "4.2 Terminal velocity",
    "text": "4.2 Terminal velocity\nA ball of radius \\(R\\) (in m) and uniform density \\(\\rho\\) (in kg/m3) falls in a viscous fluid. The fluid has density \\(\\rho_f\\) (in kg/m3) and viscosity (a measure of friction or resistance) \\(\\mu\\) (in kg/(m s)). The equation that governs the velocity is \\[\\begin{gather}\n\\frac{4}{3} \\pi R^3 \\rho \\frac{\\mathrm{d}V}{\\mathrm{d}t} = \\frac{4}{3} \\pi R^3 (\\rho - \\rho_f) g - 6\\pi \\mu R V, \\\\\nV(0) = V_0.\n\\end{gather}\\]\n\nChoose appropriate velocity and time scales to non-dimensionalise the equation so as to leave only a single non-dimensional number on the drag term (the last term on the right hand-side).\nDefine the non-dimensional parameter expressing a ratio between drag force and gravity force by the Stokes number (St) and confirm that it is \\[\nSt = \\frac{9\\mu V_0}{2(\\rho - \\rho_f) g R^3}.\n\\]\nComment on the two limits of \\(St \\to 0\\) and \\(St \\to \\infty\\). Can the problem be reduced in these two limits? If so, reduce and solve."
  },
  {
    "objectID": "part-02-energy/part-energy.html",
    "href": "part-02-energy/part-energy.html",
    "title": "Energy usage and energy sources",
    "section": "",
    "text": "The first part of this course is centred upon a seminal book by Cambridge physicist David MacKay (MacKay 2009) that was written a number of years ago.\n\n\n\nFigure 1: Cover of MacKay’s book\n\n\nUnlike many other books and discussions on the topic of energy, this one is written with the emphasis placed on developing simple back-of-the-envelope estimates of usage. This is a great philosophy, and one that does well to cut straight to the heart of more long-winded discussions.\nMacKay’s book was published with an open license, and can be freely downloaded at https://www.withouthotair.com/.\n\n\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-02-energy/mackay-energy.html#the-industrial-revolution-and-its-effects",
    "href": "part-02-energy/mackay-energy.html#the-industrial-revolution-and-its-effects",
    "title": "5  The CO2 concentration",
    "section": "5.1 The Industrial Revolution and its effects",
    "text": "5.1 The Industrial Revolution and its effects\nIn his book, MacKay offers the following graph of carbon dioxide (CO2) concentration.\n\n\n\nFigure 5.1: Upper graph showing carbon dioxide concentrations (in parts per million). The middle graph shows the history of UK coal production, Saudi oil production, world oil production, and total of all greenhouse gas emissions (shown circled). The bottom graph shows the similar trends as associated with the industrial revolution. Note scales of last two graphs are logarithmic.\n\n\nIt is remarked that the sudden rise of CO2 concentration is attributed to the industrial revolution, with a key event being the invention of the steam engine in 1769. Correlations between the rise and other key industries can also be established, including correlations with population increase, the growth of British ships and pig-iron production, and oil and coal production.\nSo in a nutshell, Mackay quite strongly argues that the significant rises in measured CO2 are the result of human influence and notably the downstream effects of the Industrial Revolution.\n\n\n\n\n\n\nNote\n\n\n\nMackay notes that in the various visualisations and explanations, greenhouse gases include carbon dioxide, methane, nitrous oxide, but Mackay expresses emissions in “equivalent amounts of CO2” where equivalent means having the same warming effect over a hundred years."
  },
  {
    "objectID": "part-02-energy/mackay-energy.html#doubling-of-co2",
    "href": "part-02-energy/mackay-energy.html#doubling-of-co2",
    "title": "5  The CO2 concentration",
    "section": "5.2 Doubling of CO2",
    "text": "5.2 Doubling of CO2\nWhat happens if CO2 concentration is doubled? This is one of the key questions that McKay discusses. Models seem to indicate that a doubling of CO2 would have the same effect as increasing the intensity of the sun by 2% and global temperatures rising by 3\\(^\\circ\\)C. Mackay notes (p. 10) that\nThis is what historians call a Bad Thing. I won’t recite the whole litany of probable drastic effects, as I am sure you’ve heard it before. The litany begins “the Greenland icecap would gradually melt, and, over a period of a few 100 years, sea-level would rise by about 7 metres.” The brunt of the litany falls on future generations. Such temperatures have not been seen on earth for at least 100 000 years, and it’s conceivable that the ecosystem would be so significantly altered that the earth would stop supplying some of the goods and services that we currently take for granted.\nThere is an excellent scientific paper by (Charney et al. 1979) that is cited by Mackay in footnote 10 on p.20, and which you should be able to find in the extended references of your Moodle page. This is a very readable scientific paper that summarises the current state-of-the art in simulations from 1979—which is still largely valid today. The authors of the review essentially conclude two facts.\n\nDoubling atmospheric CO2 would change net heating of the troposphere, oceans, and land by an average power per unit area of roughly 4W/m^2. Since the average power absorbed by the atmosphere, land, and oceans is approximately 238 W/m^2, then this would be equivalent to increasing the sun’s intensity by about 1.7%.\nThe effect of global temperatures is more difficult, since this involves some complex simulations. However, the current simulations seem to predict an increase of between 2\\(^\\circ\\)C and 3.5\\(^\\circ\\)C.\n\n\n\n\n\n\n\nNote\n\n\n\nIt is possible to develop a back-of-the-envelope calculation to estimate the rise in temperature via doubling of CO2 and this was done as early as 1896 by Arrhenius(!) (Arrhenius 1896)"
  },
  {
    "objectID": "part-02-energy/mackay-energy.html#who-should-fix-it",
    "href": "part-02-energy/mackay-energy.html#who-should-fix-it",
    "title": "5  The CO2 concentration",
    "section": "5.3 Who should fix it?",
    "text": "5.3 Who should fix it?\nSo to whom does the responsibility lie to fix the issue? There are different visualisations possible in order to make this argument. For example, one can examine estimates of the rate of GG poulation per population (tons of CO2 emissions per year per person). This would tell you who are the current biggest offenders.\nHowever, an alternative viewpoint is that the responsible party should be the party who was the largest polluter in time (i.e. find each country’s total historical footprint and divide by the populace). This produces the following graph.\n\n\n\nFigure 5.2: A graph of the average pollution rate vs. the population\n\n\nNote that the units of the vertical axis are given as tons of CO2 per year per person.\nSo how much do we need to reduce in order to “guarantee” global temperatues do not rise more than 2\\(^\\circ\\)C? At the end of the chapter, Mackay summarises the situations as follows. The plans require global emissions to fall by 70% or 85% by 2050. In the UK, for instance, 11 tons of CO2/y.p would need to be changed to 1.1 tons of CO2/y.p.\n\n\n\n\n\n\nImportant\n\n\n\n“This [the necessary reduction of carbon footprint per person] is such a deep cut, I suggesst the best way to think about it is no more fossil fuels”.\n\n\n\n\n\n\nArrhenius, Svante. 1896. “XXXI. On the Influence of Carbonic Acid in the Air Upon the Temperature of the Ground.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 41 (251): 237–76.\n\n\nCharney, Jule G, Akio Arakawa, D James Baker, Bert Bolin, Robert E Dickinson, Richard M Goody, Cecil E Leith, Henry M Stommel, and Carl I Wunsch. 1979. Carbon Dioxide and Climate: A Scientific Assessment. National Academy of Sciences, Washington, DC.\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-02-energy/mackay-units.html#units",
    "href": "part-02-energy/mackay-units.html#units",
    "title": "6  Units and physics",
    "section": "6.1 Units",
    "text": "6.1 Units\n\nDefinition 6.1 (Unit of energy) The SI unit of energy is a Joule (J). In discussing usage, however, we will often use the kilowatt-hour (kWh).\n\n\nDefinition 6.2 (Unit of power) The SI unit of power is a Watt (W), equivalent to 1 J/s. Thus 1 kW of power is 1000 J/s. Power can also be measured in kWh per day.\n\nSo based on the above, let us unpack one unit of energy (kWh) in terms of Joules.\n\\[\n[E] = 1\\mathrm{kWh} = (10^3 \\mathrm{J/s}) \\times \\left(3.6 \\cdot 10^3 \\frac{\\mathrm{s}}{\\mathrm{hr}}\\right) \\cdot 1 \\mathrm{hr} = 3.6 \\cdot 10^6 \\mathrm{J}.\n\\]\n\n\n\n\n\n\nNote\n\n\n\nOne 40W lightbulb left on for a day uses about 1 kWh via the following argument.\n\\[\n40 \\mathrm{W} \\cdot 1 \\mathrm{day} = 40 \\cdot 10^{-3} \\mathrm{kW} \\cdot 24 \\mathrm{hours} = 0.96 \\mathrm{kWh}.\n\\]\n\n\nSo to repeat, for measurement of electricity, the unit we will often use is the kWh, and 1 kWh is approximately the energy required to light a (40W) lightbulb for an entire day. Given the importance of understanding your energy bills, thinking in terms of those quantities will help you remember. See below note.\n\n\n\n\n\n\nNote\n\n\n\nExamining the current Shell Energy tarifs as of mid October 2022, the unit rate of electricity is 21.6p/kWh and the unit rate of gas is 4.2p/kWh. This is about double the figures quoted in (MacKay 2009)!\n\n\n\nDefinition 6.3 (Kilo, mega, giga, tera) Kilo means a multiplier of \\(10^3\\). Similarly, Mega is a multiplier of \\(10^6\\), Giga a multiplier of \\(10^9\\), and Tera a multipier of \\(10^{12}\\)."
  },
  {
    "objectID": "part-02-energy/mackay-units.html#energy-equivalences",
    "href": "part-02-energy/mackay-units.html#energy-equivalences",
    "title": "6  Units and physics",
    "section": "6.2 Energy equivalences",
    "text": "6.2 Energy equivalences\nAs the fundamental law of thermodynamics goes, energy cannot be created nor destroyed. However, not all energies are equivalent because there are penalties and efficiencies when one converts from one energy type to another (in terms of usable energy). For example:\n\nA fossil fuel plant will convert from chemical energy to electrical energy at an efficiency of about 40%.\nAn aluminium plant will convert from elecrical energy to manufacture aluminium (and hence chemical energy) at an efficiency of about 30%.\n\nBecause of the above, in common usage, some tables of energy usage will include the conversion factors while others will not. For example, consider a power station that converts 2.5 kWh of oil into 1 kWh of electrical energy (an efficiency of 40%). We might then write \\[\nE_\\mathrm{electrical} = E_\\mathrm{oil} \\cdot 0.4\n\\] but the above is a confusing statement if you assume that there is a single intrinsic notion of energy, \\(E\\). Do we set \\(E = E_\\mathrm{oil}\\) or \\(E = E_\\mathrm{electrical}\\)?. If this further confuses you, ask the following question: what does \\(E_\\mathrm{oil}\\) mean if one does not consider a conversion process?\nIn order to avoid this confusion, MacKay uses (p. 27) the convention of treating energy values as equivalent, i.e. 1 kWh of chemical energy is the same as 1 kWh of electrical energy.\n\n\n\n\n\n\nNote\n\n\n\nAs MacKay notes (p. 27) the above assumption is not the same as assuming that all energy can be converted to one and the other without loss.\n\n\n\n\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#tips-for-estimates",
    "href": "part-02-energy/mackay-consumption.html#tips-for-estimates",
    "title": "7  Estimating consumption",
    "section": "7.1 Tips for estimates",
    "text": "7.1 Tips for estimates\n\nUse appropriate conversion of units.\n\nFor example, even though you may not know what specific heat means (see below question about the bath hot water usage), examining the units of Joules/(Litre x Celcius) should tell you that this quantity corresponds to energy per unit volume per unit degree Celcius. Specific heat is a quantity associated with certain materials that describe the energy requred to increase its volume by one degree.\n\nManipulate different forms of energy\n\nAn object of mass \\(m\\) moving at speed \\(v\\) possesses kinetic energy given by \\[\nE_\\mathrm{kinetic} = \\frac{1}{2} mv^2.\n\\] An object can also possess different kinds of potential energy. For example, an object of mass \\(m\\) that will fall when released possesses gravitational potential energy given by \\[\nE_\\rm{grav. potential} = mgh\n\\] where \\(h\\) is its distance relative to some given point and \\(g = 9.8 \\, \\mathrm{m/s^2}\\) is the standard gravitational constant on the surface.\nA hot object also possesses heat energy. The heat energy is given by \\[\nE_\\mathrm{heat} = c \\rho V T\n\\] where \\(c\\) is the specific heat capacity (J/(kg K)), \\(\\rho\\) is the density (kg/m^3), \\(V\\) is the volume (m^3), and \\(T\\) is the temperature (K). An object can also possess chemical potential energy (for example, we possess such energy when we eat food). And so forth and so on.\n\n\n\n\n\n\nChecking energies\n\n\n\nIt is a good idea to check that all the above units make sense and the right hand-sides return the expected unit of energy."
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#heating-and-cooling",
    "href": "part-02-energy/mackay-consumption.html#heating-and-cooling",
    "title": "7  Estimating consumption",
    "section": "7.2 Heating and cooling",
    "text": "7.2 Heating and cooling\nWe would like to develop estimates of energy usage in heating and cooling.\n\n\n\n\n\n\nEnergy in a hot bath\n\n\n\nTo compute the heat energy in taking a hot bath, we take the specific heat capacity of water, \\(\\tilde{c} = 4200 \\, \\mathrm{J}/(\\mathrm{L} \\, ^{\\circ}\\mathrm{C})\\). This multiplies the volume of a bath (50 cm x 15 cm x 150 cm), and the temperature of water minus the temperature of ambient water, estimated at \\(40^\\circ\\mathrm{C}\\). This gives \\[\nE_\\mathrm{hot bath} \\approx (4200 \\times 110 \\times 40) \\mathrm{J} \\approx 18 \\, \\mathrm{MJ} \\approx 5 \\, \\mathrm{kWh}.\n\\]\nAfter lecture note: MacKay works with a slightly different convention and writes the specific heat capacity in per L quantities. He also writes his volume in litres. I will show how this is worked out in our typical process.\n\ndensity of water is 10^3 kg/m^3\nvolume of the bath is 0.1125 m^3\nspecific heat is 4.2 x 10^3 J/(kg C) [note K and C convert in one-to-one fashion]\nthe weight of water is then 0.1125*10^3 kg or 112.5kg\nconverting from litres to water weight is 1L = 1kg; so this is where he pulls 110L from.\nUsing our formula, it works out to be the same: \\[\nE_\\mathrm{heat} = \\rho c V T = 112.5 \\cdot 4.2 \\times 10^3 \\cdot 40^\\circ \\mathrm{J} = 1.89 \\times 10^7 \\mathrm{J}.\n\\]\n\n\n\n\n\n\n\n\n\nEnergy in appliances\n\n\n\nFor example, consider a kettle with a voltage of \\(V = 230V\\) and a max amperage of \\(I = 13A\\). Voltage measures the potential difference of electricity, and amperage measures the current. If you multiply the two together, \\(VI = P\\), you get power, \\(P\\). So this kettle has power \\(P = 3\\mathrm{kW}\\).\nTo estimate usage, we must estimate how often the kettle is used and for how long. Considering 20 minutes per household of two people, this then requires \\[\nE_\\mathrm{kettle} \\approx (3 \\mathrm{kW}) \\times \\left(20 \\, \\mathrm{min} \\times \\frac{\\mathrm{hrs}}{60\\mathrm{min}}\\right) = 1 \\mathrm{kWh}.\n\\]\nYou may also be interested in MacKay’s estimates for microwave ovens (0.5 kWh/day), regular ovens (1.5 kWh/day), and clothes washers (1 kWh/day).\n\n\nFollowing (MacKay 2009), you can also follow similar estimates of using space heaters, refrigerators, and air conditioners.\n\n\n\n\n\n\nHot air and cooling\n\n\n\nMackay develops the following estimates of energy usage (per day per person). Considering space heaters run during the colder months, he develops\n\\[\nE_\\text{hot air} \\approx 24\\,\\text{kWh}.\n\\] while considering the refrigerator and air condition usage, he approximates \\[\nE_\\text{heat + cooling} \\approx 1.5 \\, \\mathrm{kWh}.\n\\]\n\n\nNote that the above estimates are for average domestic consumption, and hence this does not include the significant energy usages of the service and workplace industries. The total estimate from this chapter is as follows.\n\n\n\n\n\n\nTotal heating and cooling estimate\n\n\n\nMacKay estimates (p. 53) that the total energy one (domestic) person spends on heating and cooling, including home, workplace, and cooking, is 37 kWh per day per person (12 for hot water, 24 for hot air, and 1 for cooling). He notes that this seems to be close to the typical figures quoted (45 kWh/d per person) if you make use of some national tables (and some liberties—like using the University of Cambridge’s energy estimates)."
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#energy-usage-of-stuff",
    "href": "part-02-energy/mackay-consumption.html#energy-usage-of-stuff",
    "title": "7  Estimating consumption",
    "section": "7.3 Energy usage of stuff",
    "text": "7.3 Energy usage of stuff\nA significant amount of energy is expended on:\n\nproduction of raw materials\nproduction on stuff and transportation of such\nuse of stuff\ndisposal and recycling of stuff\n\n\n\n\n\n\n\nEnergy usage in a soda addict\n\n\n\nConsider someone who has a coca-cola addiction and drinks five cans of coke a day. What is their energy usage in this regard? On the assumption that the raw aluminium material phase dominates (production of metals is intensive), MacKay notes that one can needs about 0.6kWh of energy. Thus \\[\nE_\\text{coke} \\approx 5 \\times 0.6 \\, \\mathrm{kWh} = 3 \\, \\mathrm{kWh}\n\\] as the per day per person figure."
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#energy-usage-of-transportation",
    "href": "part-02-energy/mackay-consumption.html#energy-usage-of-transportation",
    "title": "7  Estimating consumption",
    "section": "7.4 Energy usage of transportation",
    "text": "7.4 Energy usage of transportation\n\n7.4.1 Cars\nMacKay uses some interesting back-of-the-envelope estimates here. First \\[\n\\text{energy per day} = \\frac{\\text{distance travelled per day}}{\\text{distance over unit of fuel}} \\times \\text{energy per unit of fuel}.\n\\]\nWe take about 50km travelled per day, and a typical family car is quoted as 12 km/L.\nIn order to estimate the energy per unit (L) of fuel, MacKay notes that automobile fuel is a hydrocarbon and so we can sensibly use butter as an estimate. A packet of butter informs that it contains a calorific value of about 3000 kJ per 100g. We have that 1 kJ is 1/3600 kWh, so this gives (5/6)*10 ~ 8 kWh per kg. To get energy density in terms of volume, we need to know the density of butter. Water has a density of about 1kg/L (nearly by definition). Since butter floats on water, we might take its density to be 0.9kg/L (this is very close). Together this gives an estimate of about 8*0.9 or 7 kWh/L.\nLooking it up in a random reference, though, gives that petrol has about 10kWh/L.\nThus altogether, this gives an estimate of \\[\n\\text{energy per day} = \\frac{50 \\mathrm{km}}{12 \\mathrm{km/L}} \\times 10 \\mathrm{kWh/L} \\approx 40 \\mathrm{kWh/day}\n\\] so the equivalent of leaving 40 lightbulbs on for an entire day."
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#in-depth",
    "href": "part-02-energy/mackay-consumption.html#in-depth",
    "title": "7  Estimating consumption",
    "section": "7.5 In-depth",
    "text": "7.5 In-depth\nMacKay provides a more in-depth calculation for car transport in the Appendix A.\nThe energy in a fossil-fuel car goes into four main categories.\n\nSpeeding-up and slowing down using the brakes;\nair resistance;\nrolling resistance;\nheat – about 75% of the energy is thrown away as heat\n\n\n7.5.1 Brakes\n\nAssume a car of mass \\(m_c\\) accelerates rapidly to a constant speed, \\(v\\), and maintains this speed for a distance \\(d\\), at which point the driver brakes rapidly to a stop.\nAssume that the kinetic energy is transferred into the brakes. We can estimate \\[\n\\text{Power in brakes} = \\frac{ \\text{kinetic energy}}{ \\text{time between braking events}} = \\frac{\\frac{1}{2}m_c v^2}{(d/v)} = \\frac{1}{2} \\frac{m_c v^3}{d}.\n\\]\n\n\n\n7.5.2 Air resistance\nDrag is the most important aerodynamic force in cars at highway speeds. In order to calculate the exact drag, we would essentially need to integrate forces around the car in a fluid dynamics model. However, drag is usually approximated by the force1, \\[\nF_d = \\frac{1}{2} \\rho C_D A_f v^2,\n\\] where \\(\\rho\\) is the density of air, \\(A_f\\) is the frontal cross-sectional area of the car, and \\(C_D\\) is the drag coefficient, a non-dimensional number that encodes all of the complicated fluid dynamics. Then we know that \\[\n\\text{Power in drag} = \\frac{ \\text{Force . distance}}{ \\text{time between braking}} =  \\frac{1}{2} \\rho C_D A_f v^3.\n\\]\n\n\n7.5.3 Ratio of brake power to drag power\nRecalling our discussion of non-dimensionalisation, we can form a non-dimensional number representing the ratio of the two above powers:\n\\[\n\\Pi = \\frac{\\text{Power in brakes}}{\\text{Power in drag}} = \\frac{m_c}{d(\\rho C_D A_f)}.\n\\] Verify that the units are sensible. Note that when \\(\\Pi > 1\\), then braking effects are more dominant, and if \\(\\Pi < 1\\), then drag effects are more dominant. In order to examine the threshold, set \\(\\Pi = 1\\) and solve for \\(d\\), \\[\nd_{\\text{crit}} = \\frac{m_c}{\\rho C_D A_f}.\n\\]\nWe use the following approximations: \\(m_c = 1000 kg\\), \\(\\rho = 1.3 kg/m^3\\), \\(C_D = 1/3\\), \\(A_f = 3 m^2\\). This gives a critical distance of \\[\nd_{ \\text{crit}} = 750m.\n\\] Therefore, when travelling more than about a 1km, much of your energy expenditure between these two items is largely going into drag, while for less than 1km, more energy is going into your brakes. In order to save energy, you can (i) drive more slowly; (ii) reduce the mass of your car; (iii) get better brakes (regenerative brakes); (iv) reduce your car’s drag coefficient or reduce its cross sectional area.\n\n\n7.5.4 Rolling resistance\nRolling resistance involves the energy consumed in the tyres and bearings of the car, the energy going into the noise of the wheels against the ground, the energy of grinding rubber off the tyres, the energy in the wheel vibrating the ground, etc. The standard model assumes that the rolling resistance force is \\[\nF = C_{rr} m_c g,\n\\] where car rubber tyres are given in MacKay’s book as having a coefficient \\(C_{rr} = 0.01\\). Again, we can compare the threshold where rolling resistance is equal to drag via \\[\nC_{rr} m_c g = \\frac{1}{2} \\rho C_D A_f v^2,\n\\] which gives a critical speed of \\[\nv = \\sqrt{2 \\frac{C_{rr} m_c g}{\\rho C_D A_f}} = 7m/s = 16 mi/hr.\n\\]\n\n\n7.5.5 Power\nNotice that we can then write the total power as \\[\nP = \\sigma \\left( \\mathcal{A} v + \\mathcal{C} v^3\\right),\n\\] where \\(\\sigma\\) is an efficiency parameter that indicates how efficiently chemical energy (petrol) is converted into mechanical energy via the engine and transmission. Much of this is initial energy is ‘lost’ to heat, and MacKay indicates that petrol engines are about 25% efficient. Thus we should set \\(\\sigma = 4\\). Above, note that \\(\\mathcal{A}\\) is then associated with the rolling resistance and \\(\\mathcal{C}\\) to the drag and braking.\nPreviously in Section 7.4.1, we estimated energy consumption of 80 kWh to drive 100km (note this did not take into account any dynamics, i.e. time); this was a straight approximation based on the energy of petrol.\nFrom the table below (most figures taken from MacKay but see the footnotes)\n\n\n\nQuantity\nApproximation\n\n\n\n\n\\(m_c\\)\n1000kg\n\n\n\\(v\\)\n110km/h = 31 m/s\n\n\n\\(d\\)\n10km\n\n\n\\(\\rho\\)\n1.3 kg/m^3\n\n\n\\(C_D A_f\\)2\n0.7 m^2\n\n\n\\(C_{rr}\\)\n0.01\n\n\n\nWe seem to get the following. \\[\\begin{align}\n\\text{Power}_{\\text{brakes}} &\\approx 1500 W \\approx 1.5 kW \\\\\n\\text{Power}_{\\text{air}} &\\approx   13,600 W = 13.6 kW  \\\\\n\\text{Power}_{\\text{rolling}} &\\approx 3000 W = 3 kW.\n\\end{align}\\]\nWe see that by far, the biggest contributor at such speeds is the drag. The above numbers should be multiplied by \\(\\sigma = 4\\). If we ignore all other effects and only consider drag, this gives about 54 kW of power. Hence driving for one hour this is 54 kWh, to be compared with our prior estimate of 80 kWh3.\n\n\n7.5.6 Conclusions and caveats\nSo there are a few interesting conclusions. One conclusion is nicely summarised by this graph, which you can often see in other references.\n\n\n\nFigure 7.1: Car fuel consumption (energy per distance) from p.259 of MacKay\n\n\nThe key, really, is that energy consumption is largely dominated by the cubic term in the power. MacKay, on p.258, compares the relative energetic consumption due to drag of a cyclist versus a car. If we assume their drag-area values are about the same (cyclists are less aerodynamic but occupy less area), a cyclist travelling at 20 km/h versus a car travelling at 100 km/h would have an energy ratio of \\[\n\\frac{\\text{Energy per distance of bike}}{\\text{Energy per distance of car}} \\approx \\left(\\frac{20 }{100}\\right)^2 = 0.04,\n\\] i.e. 4% of the energy consumption of a car.\nThere is one interesting caveat that would have been nice to see more discussion, but there is a commentary on p.260 of MacKay. It is conventional knowledge that cars have a ‘sweet spot’ for fuel consumption, which is often quoted as around the range of 40-60mph4.\n\n\n\nFigure 7.2: Car fuel efficiency versus the approximations developed above\n\n\nIt seems unclear how the above alternative shape is modeled via the back-of-the-envelope estimates. For instance, can be be modeled by considering an efficiency, \\(\\sigma = \\sigma(v)\\), the depends on speed?"
  },
  {
    "objectID": "part-02-energy/mackay-consumption.html#references",
    "href": "part-02-energy/mackay-consumption.html#references",
    "title": "7  Estimating consumption",
    "section": "7.6 References",
    "text": "7.6 References\nA good reference on the so-called road load equation\n\n\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot Air. UIT Cambridge Ltd."
  },
  {
    "objectID": "part-05-techniques/techniques.html",
    "href": "part-05-techniques/techniques.html",
    "title": "Practical applied mathematics",
    "section": "",
    "text": "As we go deeper into formulating the equations that model or govern aspects of Planet Earth, we will quickly come to the realisation that many such equations, even for the simplest minimal models, are not exactly solvable.\nFor example, in Chapter 26 we develop the following “simple” model for the temperature in the ocean: \\[\\begin{align}\n\\frac{\\mathrm{d}x}{\\mathrm{d}t} &= \\delta(1 - x) - |f(x, y)|x, \\\\\n\\frac{\\mathrm{d}y}{\\mathrm{d}t} &= 1 - y - |f(x, y)|y,\n\\end{align}\\] where we have introduced the function, \\[\nf(x, y; R, \\lambda) = \\frac{1}{\\lambda}(Rx - y),\n\\]\nThis is quite a difficult problem! This is essentially a set of two nonlinear differential equations for two unknowns and three parameters. What kind of practical applied mathematics can we apply to study such problems?\nThe intention of this part is to introduce (and in some cases, review) three key concepts:\n\nAsymptotic approximations.\nNumerical solutions of differential equations.\nNumerical solutions of nonlinear equations (Newton’s method)."
  },
  {
    "objectID": "part-05-techniques/asymptotics01.html#a-simple-quadratic",
    "href": "part-05-techniques/asymptotics01.html#a-simple-quadratic",
    "title": "8  Asymptotic approximations",
    "section": "8.1 A simple quadratic",
    "text": "8.1 A simple quadratic\n\n\n\n\n\n\nA singular quadratic\n\n\n\nConsider the solution of \\[\n\\epsilon x^2 + x - 1 = 0,\n\\tag{8.1}\\] where \\(\\epsilon\\) is a fixed and very small positive number, say \\(0.000001\\). Forget that we know how to solve a quadratic equation: is it possible to develop a systematic approximation method?\n\n\nIf \\(\\epsilon = 0\\), then \\(x = 1\\). Moreover, if we substitute \\(x = 1\\) into the equation, then we see that the error is small and proportional to \\(\\epsilon\\). It is natural to seek an approximation in powers of \\(\\epsilon\\). We call this an . We write \\[\nx = x_0 + \\epsilon x_1 + \\epsilon^2 x_2 + \\ldots\n\\] Substitution into the equation yields \\[\n\\epsilon \\Bigl(x_0 + \\epsilon x_1 + \\epsilon^2 x_2 + \\ldots\\Bigr)^2 + \\Bigl( x_0 + \\epsilon x_1 + \\epsilon^2 x_2 + \\ldots \\Bigr) - 1 = 0.\n\\] Expand and collect terms in powers of \\(\\epsilon\\): \\[\n\\Bigl( x_0 - 1 \\Bigr) + \\epsilon\\Bigl(x_1 + x_0^2\\Bigr) + \\epsilon^2\\Bigl(x_2 + 2 x_0 x_1\\Bigr) + \\ldots = 0.\n\\] Now we equate coefficients at each order in \\(\\epsilon\\). This gives \\[\\begin{align}\nx_0 - 1 &= 0 \\Longrightarrow x_0 = 1 \\\\\nx_1 + x_0^2 &= 0 \\Longrightarrow x_1 = -1 \\\\\nx_2 + 2 x_0 x_1 &= 0 \\Longrightarrow x_2 = 2\n\\end{align}\\] We therefore have obtained the three-term approximation, \\[\nx = 1 - \\epsilon + 2\\epsilon^2 + \\ldots\n\\] Clearly we could continue this process ad infinitum obtaining increasingly accurate approximations to one of the roots.\n\n8.1.1 The singular root\nBut where has the other quadratic root gone?\nThe problem is that in considering \\(\\epsilon\\) to be small, we began by ignoring the leading term, \\(\\epsilon x^2\\). We effectively assumed that the equation was primarily balanced by setting the \\(x\\) term with the \\(-1\\) term, and the sum of the two terms approximately equalling zero.\nBut if \\(|x|\\) is large, then clearly our assumption that \\(\\epsilon x^2\\) being small may not be necessarily true for it depends on how large \\(|x|\\) is compared to \\(\\epsilon\\). Note that if \\(|x|\\) is large, then necessarily the last term, \\(-1\\), is negligible in comparison. Therefore, in order for \\(\\epsilon x^2\\) to balance \\(x\\), we see that \\(|x|\\) must be of size \\(1/\\epsilon\\).\nTherefore this suggests that we should re-scale our solution as follows \\[\nx = \\frac{X}{\\epsilon}.\n\\]\nSubstitution into the original quadratic now yields \\[\nX^2 + X - \\epsilon = 0.\n\\] Now notice that \\(\\epsilon = 0\\) expresses the correct balance in order to detect that missing root. Again we write \\[\nX = X_0 + \\epsilon X_1 + \\epsilon^2 X_2 + \\ldots\n\\] and attempt to solve order by order. Substitution into the equation yields \\[\n\\Bigl(X_0 + \\epsilon X_1 + \\epsilon^2 X_2 + \\ldots\\Bigr)^2 + \\Bigl(X_0 + \\epsilon X_1 + \\epsilon^2 X_2 + \\ldots\\Bigr) - \\epsilon = 0.\n\\] Expand and collect orders of \\(\\epsilon\\): \\[\\begin{align}\nX_0^2 + X_0 &= 0 \\Longrightarrow X_0 = -1 \\\\\n2X_0 X_1 + X_1 -1 &= 0 \\Longrightarrow X_0 = -1,\n\\end{align}\\] and thus to two orders, we have \\[\nX = -1 - \\epsilon + \\ldots \\Longrightarrow x = - \\frac{1}{\\epsilon} - 1 + \\ldots\n\\]\nOf course, we have used a very simple example (a solvable quadratic) to illustrate the idea of asymptotic approximations, but you should hopefully see that this method is extensible to much more complicated equations.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nep = np.linspace(1,0.1, 20)\nroot1 = (-1 + np.sqrt(1-4*ep*(-1)))/(2*ep)\nroot2 = (-1 - np.sqrt(1-4*ep*(-1)))/(2*ep)\nasym1 = 1 - ep\nasym2 = -1/ep - 1\nplt.plot(ep, root1, 'o')\nplt.plot(ep, root2, 'o')\nplt.plot(ep, asym1, '-')\nplt.plot(ep, asym2, '-')\nplt.legend(['$x_1$', '$x_2$', '2-term asymp.', '2-term asym'])\nplt.xlabel('$\\epsilon$')\nplt.ylabel('x');"
  },
  {
    "objectID": "part-05-techniques/asymptotics01.html#order-notation-and-the-tilde-sign-for-asymptotic",
    "href": "part-05-techniques/asymptotics01.html#order-notation-and-the-tilde-sign-for-asymptotic",
    "title": "8  Asymptotic approximations",
    "section": "8.2 Order notation and the tilde sign for asymptotic",
    "text": "8.2 Order notation and the tilde sign for asymptotic\nWe define precisely what we mean when we say that two functions, say \\(f\\) and \\(g\\), exhibit the same behaviour in some limit, say \\(\\epsilon \\to 0\\) or \\(x \\to x_0\\) or \\(x \\to \\infty\\) and so forth. For instance, we claim that the graphs of \\(\\sin(x)\\) and \\(x\\) look very similar as \\(x \\to 0\\). Thus we might write \\[\n    \\sin(x) \\sim x \\quad \\text{as $x \\to 0$}.\n\\tag{8.2}\\] This notion of allows us to specify functional behaviours at a deeper level than just limits. As you can see, it is not as useful to specify that \\[\n\\lim_{x \\to 0} \\sin{x} = \\lim_{x\\to 0} x.\n\\] In contrast, (Equation 8.2) is much more prescriptive about the way that the functions are approaching the limit.\n\n\n\n\n\n\nDefinition of \\(\\sim\\), \\(\\gg\\), and \\(\\ll\\)\n\n\n\nFirst, the notation \\[\nf(x) \\ll g(x), \\qquad x \\to x_0,\n\\] is read as “\\(f(x)\\) is much smaller than \\(g(x)\\) as \\(x \\to x_0\\)” and means \\[\n\\lim_{x\\to x_0} \\frac{f(x)}{g(x)} = 0.  \n\\] We may analogously use \\(g(x) \\gg f(x)\\) for “much greater than”.\nSecond, the notation \\[\nf(x) \\sim g(x), \\qquad x \\to x_0,\n\\] is read as “\\(f(x)\\) is asymptotic to \\(g(x)\\) as \\(x \\to x_0\\)”, and means that the error between \\(f\\) and \\(g\\) tends to zero as \\(x \\to x_0\\), or \\[\n\\lim_{x\\to x_0} \\frac{f(x)}{g(x)} = 1.  \n\\] We will often say “\\(f\\) is like \\(g\\)” or “\\(f\\) behaves like \\(g\\)”,\n\n\nHere are some examples.\n\n\n\n\n\n\nExamples\n\n\n\n\n\\(\\sin x \\sim x \\sim \\tan x\\) as \\(x \\to 0\\)\n\\(x^2 + x + 1 \\sim \\dfrac{x^3 + \\sin x}{1 + x}\\) as \\(x \\to \\infty\\)\n\\(\\sin x \\ll \\cos x\\) as \\(x \\to 0\\)\n\n\n\nIn the examination of limiting processes, often the main issue of consideration is the relative sizes of quantities defined according to their powers. For example, if \\(x\\) is a very small number, with \\(x = 10^{-5}\\), then \\(x^5\\) is much smaller than \\(x\\) (in terms of our notation, \\(x^5 \\ll x\\) as \\(x \\to 0\\)). On the other hand, we might not care so much about the difference between \\[\nx^5 \\quad \\text{vs.} \\quad 5 x^5\n\\] The point is that the of \\(x^5\\) and \\(5 x^5\\) is the same as \\(x \\to 0\\). The “Big-Oh” notation formalises this distinction.\n\n\n\n\n\n\nDefinition of Big-Oh\n\n\n\nWe write \\(f = O(g)\\) as \\(x \\to x_0\\) to mean that there exists constants \\(K > 0\\) and \\(x^* > 0\\) such that \\[\n|f| < K |g| \\quad \\text{for all $|x - x_0| < x^*$}.\n\\]\n\n\nIn practice, the use of the order symbol is very natural and you will not need to work with the technical definition. For example, when you derive the terms of the Maclaurin/Taylor series, you are naturally clustering all the terms of the same order (power) together. For us, the \\(O\\) symbol provides a very convenient way of separating terms of different sizes.\n\n\n\n\n\n\nExamples\n\n\n\n\n\\(2\\sin x = O(\\tan x)\\) as \\(x \\to 0\\)\n\\(x^2 + x + 1 = O\\left(\\dfrac{5x^3 + \\sin x}{1 + x}\\right)\\) as \\(x \\to \\infty\\)\n\n\n\nLet us return to the case of the quadratic example (Equation 8.1). Using the O notation, we can write \\[\nx =\n\\begin{cases}\n1 - \\epsilon + 2 \\epsilon^2 + O(\\epsilon^3) \\\\\n-\\frac{1}{\\epsilon} - 1 + O(\\epsilon^2)\n\\end{cases}\n\\] for the two roots. Alternatively, we can truncate the expansions and simply using the \\(\\sim\\) symbol: \\[\nx \\sim\n\\begin{cases}\n1 - \\epsilon  \\\\\n-\\frac{1}{\\epsilon} - 1\n\\end{cases}\n\\]"
  },
  {
    "objectID": "part-05-techniques/asymptotics02.html#returning-to-the-projectile-problem",
    "href": "part-05-techniques/asymptotics02.html#returning-to-the-projectile-problem",
    "title": "9  Asymptotic approximations of ODEs",
    "section": "9.1 Returning to the projectile problem",
    "text": "9.1 Returning to the projectile problem\nIn Chapter 4 and ?sec-PS1 you studied the non-dimensionalisation of the projectile problem. Once re-scaled, it takes the following form: \\[\n\\begin{align}  \n\\frac{\\mathrm{d}^2 y}{\\mathrm{d}t^2} &= -\\frac{1}{(1 + \\epsilon y)^2}, \\qquad t > 0 \\\\\ny(0) &= 0, \\\\\ny'(0) &= 1.\n\\end{align}\n\\tag{9.1}\\] This is a difficult problem without, in fact, any explicit solutions. However, we can estimate the solution in the limit \\(\\epsilon \\to 0\\). We expand the solution as \\[\ny(t) = y_0(t) + \\epsilon y_1(t) + \\epsilon^2 y_2(t) + \\ldots\n\\] In order to expand the denominator, you can use Taylor’s theorem to expand the function \\[\nf(x) = (1 + x)^\\alpha = f(0) + f'(0)x + \\ldots = 1 + \\alpha x + \\ldots\n\\] around \\(x = 0\\).\nThe differential equation now yields \\[\ny_0'' + \\epsilon y_1'' + \\epsilon^2 y_2'' + \\ldots = -\\left[1 - 2\\epsilon \\left(y_0 + \\epsilon y_1 + \\ldots\\right) + \\ldots \\right]\n\\] so grouping terms together order-by-order yields \\[\n\\Bigl[ y_0'' + 1 \\Bigr] + \\epsilon \\Bigl[ y_1'' - 2y_0\\Bigr] + \\ldots = 0.\n\\]\nWe can similarly substitute the expansion into the initial conditions. Altogether, at leading order, we obtain the following system to solve: \\[\\begin{align}\ny_0'' + 1 &= 0, \\\\\ny_0(0) &= 0, \\\\\ny_0'(0) &= 1.\n\\end{align}\\] Integrating twice and applying the boundary conditions gives us \\[\ny_0(t) = -\\frac{1}{2}t^2 + t.\n\\] In fact, this is simply the parabolic motion you would expect from school Physics. The \\(\\epsilon = 0\\) solution corresponds to assuming that the mass at the centre of the planet is dominant and then acceleration is constant.\nHowever, we can now proceed to higher order and examine the nonlinear effects. Proceeding to \\(O(\\epsilon)\\), we have the following system to solve: \\[\\begin{align}\ny_1'' &= 2y_0, \\\\\ny_1(0) &= 0, \\\\\ny_1'(0) &= 0.\n\\end{align}\\] Notice the boundary conditions come from the fact there are no \\(\\epsilon\\) corrections in the original boundary conditions, so \\(y_n(0) = y_n'(0) = 0\\) for all \\(n > 0\\). Again this system is simple to integrate. Integrating the solution for \\(y_0\\) twice and substitution of the initial conditions yields \\[\ny_1(t) = -\\frac{1}{12}t^4 + \\frac{1}{3}t^3.\n\\] We have thus solved for the asymptotic approximation to two orders. We have \\[\ny(t) \\sim \\Bigl[ -\\frac{1}{2}t^2 + t\\Bigr] + \\epsilon \\Bigl[ -\\frac{1}{12}t^4 + \\frac{1}{3}t^3\\Bigr].\n\\] This was quite an accomplishment! We have taken a problem that was not easily solvable in explicit form and through fairly simple integrations, obtained an approximation to two orders in \\(\\epsilon\\). How good is it? Let us solve the problem numerically and compare with the asymptotic approximation."
  },
  {
    "objectID": "part-05-techniques/asymptotics02.html#sec-asym2-num",
    "href": "part-05-techniques/asymptotics02.html#sec-asym2-num",
    "title": "9  Asymptotic approximations of ODEs",
    "section": "9.2 Numerical solutions of IVPs",
    "text": "9.2 Numerical solutions of IVPs\nWe first demonstrate how to solve ODEs (initial-value-problems, IVPs) using black-box functions in Python. For starters, most numerical formulations for ODEs will require that the problem be posed in terms of a first-order system of equations. To convert (Equation 9.1) into such a form, create a set of unknowns for the derivatives. Set \\[\n\\mathbf{Y}(t) =\n\\begin{pmatrix}\ny_1(t) \\\\\ny_2(t)\n\\end{pmatrix}\n= \\begin{pmatrix}\ny(t) \\\\\ny'(t)\n\\end{pmatrix}\n\\]\nThen we have the following first-order system: \\[\n\\begin{align}\n\\mathbf{Y}'(t) &= \\mathbf{F}(t, \\mathbf{Y}(t)) = \\begin{pmatrix}\ny_1' \\\\\n- \\frac{1}{(1 + \\epsilon y_1)^2}\n\\end{pmatrix} \\\\\n\\mathbf{Y}(0) &= \\begin{pmatrix}\n0 \\\\\n1\n\\end{pmatrix}\n\\end{align}\n\\tag{9.2}\\]\nYou can find a little guide on using solve_ivp in Python here. Here is the Python code to solve the differential equation.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import solve_ivp\n\nep = 0.2 # epsilon value\ntmax = 2 # max time\nt = np.linspace(0, tmax, 100) # mesh used for plotting\n\n# Define function for the ODE\ndef f(t, Y):\n    ep = 0.2\n    y, yp = Y\n    ypp = -1/(1 + ep*y)**2\n    return [yp, ypp]\n\n# define the initial condition\nY0 = [0, 1]\n\nsol = solve_ivp(f, [0, tmax], Y0, dense_output=True)\n\n# Prior to plotting, re-interpolate solution on a fine grid\nyy = sol.sol(t)\n# Asymptotic solutions\ny0 = -1/2*t**2 + t\ny1 = -1/12*t**4 + 1/3*t**3\n\n# Plot it all\nplt.plot(t, yy[0,])\nplt.plot(t, y0, '--')\nplt.plot(t, y0 + ep*y1, '--')\nplt.xlabel('t')\nplt.ylabel('y(t)')\n\nText(0, 0.5, 'y(t)')\n\n\n\n\n\nThe two-term approximation does beautifully well, even at this moderate value of \\(\\epsilon = 0.2\\)."
  },
  {
    "objectID": "part-05-techniques/euler.html",
    "href": "part-05-techniques/euler.html",
    "title": "10  Euler’s method",
    "section": "",
    "text": "2022-23 note\n\n\n\nCovered in lectures 8-9.\n\n\nIn the previous section, we used built-in ODE solvers to develop numerical solutions. It is important to gain an understanding how a simple ODE solver works. The simplest scheme is called Euler’s method, and this we now explain.\nBegin from the system (Equation 9.2). We assume that the solution is represented by a discrete set of points, \\(\\mathbf{Y}_n = \\mathbf{Y}(t_n)\\) at the times \\(t_0 = 0\\), \\(t_1 = \\Delta t\\), \\(t_2 = 2\\Delta t\\), and so on. The time derivative is written as a discrete derivative while we approximate the right hand side by its value at the nth time step: \\[\n\\frac{\\mathbf{Y}_{n+1} - \\mathbf{Y}_{n}}{\\Delta t} = \\mathbf{F}(t_n, \\mathbf{Y}_n)\n\\]\nRearranging yields a very simple algorithm for solving the ODE: \\[\n\\mathbf{Y}_{n} = \\mathbf{Y}_{n-1} + \\mathbf{F}(t_{n-1}, \\mathbf{Y}_{n-1}) \\Delta t\n\\] for \\(n = 1, 2, 3, \\ldots\\)\nThis would be implemented via the following pseudocode:\n\n\n\n\n\n\nEuler’s method\n\n\n\n1. Input: function f(t, Y)  \n            time step, dt\n            initial condition, Y0\n\n2. Set initial condition Y = Y0\n\n2. Take one Euler step and overwrite previous value\n\n                 Y = Y + f(t, Y)\n\n3. Increment t by dt and goto 2\n\n\nEuler’s method is conceptually simple but quite inaccurate. But in this case, we see that it works fairly well in comparison to the built-in solvers.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import solve_ivp\n\nep = 0.2            # epsilon value\ntmax = 2            # max time\nN = 20              # number of steps\nt = np.linspace(0, tmax, N) # mesh used for plotting\ndt = t[1] - t[0]\n\n# Define function for the ODE\ndef f(t, Y, ep):\n    y, yp = Y\n    ypp = -1/(1 + ep*y)**2\n    return np.array([yp, ypp])\n\n# define the initial condition\nY = [0.0, 1.0]\nti = 0\n\n# define the solution vector\nfor i in range(1, N):\n    ti = ti + dt  # Increment time\n    Y = Y + f(ti, Y, ep)*dt # Euler step\n    plt.plot(ti, Y[0], 'k.')\n\n# Asymptotic solutions\ny0 = -1/2*t**2 + t\ny1 = -1/12*t**4 + 1/3*t**3\nplt.plot(t, y0, '--')\nplt.plot(t, y0 + ep*y1, '--')\nplt.xlabel('t');\nplt.ylabel('y');"
  },
  {
    "objectID": "part-xx-exercises/problemclass02.html",
    "href": "part-xx-exercises/problemclass02.html",
    "title": "11  Problem class 2",
    "section": "",
    "text": "2022-23 note\n\n\n\nCovered Lecture 9.\n\n\nIn this problem class, we reviewed the week’s methods. We then studied the problem of solving \\[\nx^2 - 2 x + \\epsilon \\sin x = 0,\n\\] for \\(\\epsilon > 0\\) and \\(\\epsilon \\ll 1\\). We developed the roots of this equation using asymptotic expansions.\nWe then asked how to perform asymptotic analysis in the other limit of \\(\\epsilon \\to \\infty\\). In this limit, we can set \\[\n\\delta = \\frac{1}{\\epsilon} \\to 0.\n\\]\nThe discussion can be found in the lecture visualiser notes."
  },
  {
    "objectID": "part-05-techniques/asymptotics03.html#boundary-layer-theory",
    "href": "part-05-techniques/asymptotics03.html#boundary-layer-theory",
    "title": "12  Matched asymptotics",
    "section": "12.1 Boundary layer theory",
    "text": "12.1 Boundary layer theory\nWe seek a method that will allow us to develop a uniformly valid approximation, i.e. an approximation that is good everywhere in the relevant domain, \\(t \\geq 0\\). Begin by performing the usual asymptotic approximation: \\[\nT(t) = T_0(t) + \\epsilon T_1(t) + \\epsilon^2 T_2(t) + \\ldots\n\\] Substitution into the ODE (Equation 12.1) yields at leading order, \\[\n0 = R(t) - T_0(t) \\Longrightarrow T_0(t) = R(t) = 1 + A \\cos(t).\n\\] As we have noted, this approximation fails to satisfy the initial condition, \\(T(0) = T^*\\) in general. It is possible to go to higher order but this is not so important at the moment. So for now, we have obtained: \\[\nT_{\\text{outer}} \\sim \\Bigl[ 1 + A\\cos t\\Bigr].\n\\] We have chosen to refer to this as the outer solution for reasons that will be abundantly clear. But rather than satisfying \\(T(0) = T^*\\), this approximation has the limiting behaviour of \\[\n\\lim_{t \\to 0} T_{\\text{outer}} \\sim \\Bigl[ 1 + A\\Bigr]\n\\] Above, we have only included the leading term in the limit expression.\n\n12.1.1 The inner scaling\nOur intuition follows a very similar logic to the examination of the singular root in Section 8.1.1. Above, our naive assumption was that \\(\\epsilon T'(t)\\) could be ignored since \\(\\epsilon\\) is a small number. However, this may not be the case if the gradient is very large.\nOur intuition further suggests that the boundary layer occurs near \\(t = 0\\) and that it scales in size with \\(\\epsilon\\). Therefore, let us set \\[\nt = \\epsilon^{\\alpha} s,\n\\] as a change of coordinates. We expect \\(\\alpha > 0\\) (otherwise \\(t\\) is not small), and within this region, we expect the new coordinate, \\(s\\), to be \\(O(1)\\) (of moderate size). We then transform the unknown function: \\[\nT(t) = T(\\epsilon s) = U(s),\n\\] and seek a new differential equation for \\(U\\). By the chain rule, \\[\n\\frac{\\mathrm{d}T}{\\mathrm{d}t} = \\epsilon^{-\\alpha} \\frac{\\mathrm{d}U}{\\mathrm{d}s}.\n\\] Before substituting into the equation, we are prudent to examine the behaviour of \\(R(t)\\) near \\(t = 0\\). We know by Taylor’s theorem that \\[\nR(t) = 1 + A \\left(1 - \\frac{t^2}{2} + \\ldots \\right).\n\\] Therefore, under the substitution, we may approximate \\(R\\) by its leading terms: \\[\nR( \\epsilon^{\\alpha} s) \\sim 1 + A.\n\\] For now, we will not need more terms than this. Substituting into the ODE now gives \\[\n\\epsilon^{1-\\alpha} \\frac{\\mathrm{d}U}{\\mathrm{d}s} \\sim \\Bigl[1 + A\\Bigr] - U.\n\\] Now in order to involve the first term, it is sensible to select \\[\n1 - \\alpha = 0 \\Longrightarrow \\alpha = 1.\n\\]\n\n\n12.1.2 The inner equation\nTherefore, the correct coordinate re-scaling was the ‘obvious’ one: \\[\nt = \\epsilon s.\n\\]\nSubstituting this again in (Equation 12.1): \\[\n\\begin{align}\n\\frac{\\mathrm{d}U}{\\mathrm{d}s} &= 1 + A\\cos(\\epsilon s) - U, \\\\\nU(0) &= T^*.\n\\end{align}\n\\]\nThe procedure is now exactly the same. We expand \\[\nU(s) = U_0(s) + \\epsilon U_1(s) + \\epsilon^2 U_2(s) + \\ldots\n\\] At leading order, we get \\[\n\\begin{align}\nU_0' &= 1 + A - U_0 \\\\\nU_0(0) &= T^*.\n\\end{align}\n\\] The above ODE can be solved by integrating factors. Multiplying both sides be \\(e^s\\), we have \\[\n(U_0 e^s)' = (1 + A)e^s.\n\\] Integrate and use the initial condition: \\[\nU_0(s) = (1 + A) + (T^* - (1 +A))e^{-s}.\n\\] This is exactly what we expect. Notice that \\[\n\\lim_{s \\to \\infty} U_0(s) = \\lim_{t \\to 0} T_{\\text{outer}}\n\\tag{12.2}\\] therefore the outer limit of our inner solution matches the inner limit of our outer solution. In terms of outer coordinates, our inner solution is approximated as follows: \\[\nT_{\\text{inner}} \\sim (1 + A) + (T^* - (1 +A))e^{-t/\\epsilon}.\n\\]\nLet’s finally plot this with our previous curves:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import solve_ivp\n\nTs = 0\nep = 0.2\nA = 0.1\nf = lambda t, T: 1/ep*(1 + A*np.cos(t) - T)\n\ntmax = 20\nsol = solve_ivp(f, [0, tmax], [Ts], dense_output=True)\n\nt = np.linspace(0, tmax, 1000)\ny = sol.sol(t)\nplt.plot(t, y[0])\nplt.plot(t, 1 + A*np.cos(t), '--')\nplt.plot(t, (1 + A) + (Ts - (1 + A))*np.exp(-t/ep), '--')\n\n\n\n\nIt works beautifully!\n\n\n12.1.3 Summary\nLet us summarise the procedure of matched asymptotics.\n\nExpand the solution of the differential equation naively in the typical asymptotic expansion (e.g. in powers of \\(\\epsilon\\)).\nNotice that the approximation does not satisfy certain boundary conditions.\nRe-scale the coordinates in the ‘inner’ regions.\nDevelop an inner solution that satisfies the boundary condition. Ensure it matches the outer solution.\n\nYou will get more practice of this procedure in the problem sets."
  },
  {
    "objectID": "part-05-techniques/newtons.html#demo-of-newtons-method-for-scalar-equations",
    "href": "part-05-techniques/newtons.html#demo-of-newtons-method-for-scalar-equations",
    "title": "13  Newton’s method",
    "section": "13.1 Demo of Newton’s method for scalar equations",
    "text": "13.1 Demo of Newton’s method for scalar equations\nHere is a simple demonstration of Newton’s method in order to solve for one of the roots of the following: \\[\nf(x) = x^3 + x - 1.\n\\]\nWe will start with the initial guess of \\(x_0 = 0\\). We can do this by hand in lectures using a pocket calculator. The solution is \\(x^* \\approx 0.6823278..\\)\n\n\n\ni\nxi\nf(xi)\nf’(xi)\n-f(xi)/f’(xi)\nerror\n\n\n\n\n0\n\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n2\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\nx0 = 0\nN = 10\n\ndef Newton(f, df, x, maxiter=10):\n    i = 0\n    while (i < maxiter):\n        err = f(x)\n        x = x - err / df(x)\n        print(\"f(x) = \", np.abs(err), \", x = \", x)\n        i = i + 1\n    return x, err\n\nf = lambda x: x**3 + x - 1\ndf = lambda x: 3*x**2 + 1\n\nx, err = Newton(f, df, x0, N)\nprint(\"Final approximation = \", x)\n\nf(x) =  1 , x =  1.0\nf(x) =  1.0 , x =  0.75\nf(x) =  0.171875 , x =  0.686046511627907\nf(x) =  0.008941036638283384 , x =  0.6823395825973142\nf(x) =  2.823062168566537e-05 , x =  0.6823278039465127\nf(x) =  2.839946056099052e-10 , x =  0.6823278038280194\nf(x) =  2.220446049250313e-16 , x =  0.6823278038280193\nf(x) =  1.1102230246251565e-16 , x =  0.6823278038280193\nf(x) =  1.1102230246251565e-16 , x =  0.6823278038280193\nf(x) =  1.1102230246251565e-16 , x =  0.6823278038280193\nFinal approximation =  0.6823278038280193\n\n\n\nIt is a good idea to also learn how to do this using built-in packages. The ‘fsolve’ function provides a Newton-like nonlinear solver. In fact, it can estimate the Jacobian (derivative), so only the function values need to be provided.\n\nimport numpy as np\nfrom scipy.optimize import fsolve\n\nf = lambda x: x**3 + x - 1\n\nx0 = 1\nx, info, ier, msg = fsolve(f, x0, full_output=True)\n\nprint(msg)\nprint(x)\n\nThe solution converged.\n[0.6823278]"
  },
  {
    "objectID": "part-05-techniques/newtons.html#newtons-method-for-systems-of-nonlinear-equations",
    "href": "part-05-techniques/newtons.html#newtons-method-for-systems-of-nonlinear-equations",
    "title": "13  Newton’s method",
    "section": "13.2 Newton’s method for systems of nonlinear equations",
    "text": "13.2 Newton’s method for systems of nonlinear equations\nNewton’s method generalises naturally to the case of a system of equations. Suppose we wish to solve for the \\(n\\) unknowns \\(\\mathbf{x} = (x_1, \\ldots, x_n)\\) via \\[\n\\mathbf{F(\\mathbf{x}}) =\n\\begin{pmatrix}\nF_1(\\mathbf{x}) \\\\\nF_2(\\mathbf{x}) \\\\\n\\ldots \\\\\nF_n(\\mathbf{x})\n\\end{pmatrix} = 0.\n\\]\nWe have, via Taylor’s formula, \\[\n\\mathbf{F}(\\mathbf{x}_{i+1}) \\sim  \\mathbf{F(\\mathbf{x}_i}) + J(\\mathbf{x}_i)(\\mathbf{x}_{i+1} - \\mathbf{x}_i) + \\mathcal{O}(||\\mathbf{x}_{i+1} - \\mathbf{x}_i||^2),\n\\] where \\(J\\) is the Jacobian matrix \\[\nJ(\\mathbf{x}) = \\nabla \\mathbf{F}(\\mathbf{x}) =\n\\begin{pmatrix}\n\\frac{\\mathrm{\\partial}F_1}{\\mathrm{\\partial}x_1} &\n\\cdots &\n\\frac{\\mathrm{\\partial}F_1}{\\mathrm{\\partial}x_n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\frac{\\mathrm{\\partial}F_n}{\\mathrm{\\partial}x_1} &\n\\cdots &\n\\frac{\\mathrm{\\partial}F_n}{\\mathrm{\\partial}x_n}\n\\end{pmatrix}.\n\\] Therefore, Newton’s method forms the iterates of \\[\n\\mathbf{x}_{i+1} = \\mathbf{x}_i {\\color{blue}-} J^{-1}(\\mathbf{x}_i) \\mathbf{F}(\\mathbf{x}_i),\n\\] which takes a very similar form to the scalar case.\nHowever, solution of the inverse of \\(J\\) is typically inefficient, and it is better to instead solve for \\(\\delta_{i+1} = \\mathbf{x}_{i+1} - \\mathbf{x}_i\\) via \\[\nJ(\\mathbf{x}_i) \\delta_{i+1} = - \\mathbf{F}(\\mathbf{x}_i),\n\\] and then calculate \\(\\mathbf{x}_{i+1} = \\mathbf{x}_i + \\delta_{i+1}\\). There are many ways of solving the above matrix problem efficiently using built-in routines that perform, e.g. Gaussian elimination."
  },
  {
    "objectID": "part-05-techniques/newtons.html#secant-method",
    "href": "part-05-techniques/newtons.html#secant-method",
    "title": "13  Newton’s method",
    "section": "13.3 Secant method",
    "text": "13.3 Secant method\nIn many situations, evaluation of the Jacobian (or derivative) is the most time-consuming or difficult part of a nonlinear solver. Built-in solvers like ‘fsolve’, in fact, have the ability to approximate the derivative numerically.\nThe Secant Method is similar to Newton’s Method but replaces the derivative by a finite difference. Geometrically, the tangent line is replaced with a line through the two last known guesses. The algorithm goes as follows.\n\n\n\n\n\n\nSecant method\n\n\n\n\nDevelop two initial guesses to the solution, x0 and x1\nCompute \\[\nx_{n+1} = x_n - \\frac{f(x_n)}{\\frac{f(x_n) - f(x_{n-1})}{x_n - x_{n-1}}} =  x_n - \\frac{f(x_n)(x_n - x_{n-1})}{f(x_n) - f(x_{n-1})}.\n\\]"
  },
  {
    "objectID": "part-xx-exercises/problemclass03.html",
    "href": "part-xx-exercises/problemclass03.html",
    "title": "14  Problem class 3",
    "section": "",
    "text": "2022-23 note\n\n\n\nCovered in lecture 12.\n\n\nThe problem class will cover matched asymptotics and Newton’s method. We will focus on getting you started on problem set 3, ?sec-ps3. In particular, we will focus on learning how to solve boundary-value problems using a combination of solve_ivp and fsolve learned in the previous two chapters."
  },
  {
    "objectID": "part-03-box/box-energy-model.html#steady-state-analysis",
    "href": "part-03-box/box-energy-model.html#steady-state-analysis",
    "title": "15  The basic EBM (steady-state)",
    "section": "15.1 Steady-state analysis",
    "text": "15.1 Steady-state analysis\nPreviously, we have assumed that the planetary albedo, \\(a\\), is constant and independent of temperature. In actuality, water can turn to snow and ice and vice versa; since snow and ice have much higher albedo than open water, then we should consider \\(a = a(T)\\).\nLet us assume that there are two relevant ranges to consider: T < 150K (cold) and T > 280K (hot). Let us assume that the albedo is, in these two regions: \\[\na(T) \\approx\n\\begin{cases}\n0.7 & \\mathrm{if }\\ T < 150\\mathrm{K}, \\\\\n0.3 & \\mathrm{if }\\ T > 280\\mathrm{K}.\n\\end{cases}\n\\] The above guarantees that more energy is reflected if temperatures are low. To model this process, we can use a ramp function to specify the albedo over all temperatures: \\[\na(T) = A - B \\mathrm{tanh}\\left(k(T - 265)\\right).\n\\tag{15.2}\\] where \\(A = 0.5\\), \\(B = {\\color{blue}0.2}\\), \\(k = 0.1\\), and \\(T_0 = 265 \\mathrm{K}\\). Recall that the tanh function is given by \\[\n\\mathrm{tanh}(x) = \\frac{\\mathrm{sinh}(x)}{\\mathrm{cosh}(x)} = \\frac{e^x - e^{-x}}{e^x + e^{-x}}.\n\\]\nLet us further assume that the system is in steady state, so that the temperature is determined by solving the equation \\[\nf(T) = Q[1 - a(T)] - \\sigma \\gamma T^4 = 0.\n\\tag{15.3}\\]\n\nIn the following code, we plot the two terms that make up \\(f\\), and their intersections indicate roots of \\(f = 0\\). We then use the Python ‘fsolve’ function to approximate the roots given initial guesses.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.optimize as sciopt\n\nQ = 342\nsigma = 5.67e-8 \ngamma = 0.62\n\nTT = np.linspace(220,310,50)\n\ndef fun(T):\n    a = 0.5 - 0.2*np.tanh((T - 265)/10)\n    x = (1-a)*Q\n    return x\nLHS = fun(TT)\n\nplt.plot(TT, LHS)\nplt.plot(TT, gamma*sigma*TT**4, 'k--')\n\ndef eq(T):\n    x = fun(T) - gamma*sigma*T**4\n    return x\nT1 = sciopt.fsolve(eq, 230)\nT2 = sciopt.fsolve(eq, 265)\nT3 = sciopt.fsolve(eq, 290)\nprint(\"T1 = {:.2f}\".format(T1[0]))\nprint(\"T2 = {:.2f}\".format(T2[0]))\nprint(\"T3 = {:.2f}\".format(T3[0]))\n\nT1 = 232.55\nT2 = 265.56\nT3 = 286.74\n\n\n\n\n\nTherefore multiple equilibria are observed."
  },
  {
    "objectID": "part-03-box/box-energy-model.html#dynamics-and-phase-line-solutions",
    "href": "part-03-box/box-energy-model.html#dynamics-and-phase-line-solutions",
    "title": "15  The basic EBM (steady-state)",
    "section": "15.2 Dynamics and phase line solutions",
    "text": "15.2 Dynamics and phase line solutions\nThe full time-dependent model is given by \\[\nC \\frac{\\mathrm{d}T}{\\mathrm{d}t} = f(T),\n\\] so we may use the positivity or negativity of \\(f\\) in order to sketch the time-dependent behaviour of the system.\nTo see this, we can perform an asymptotic analysis near the fixed points. Let the initial condition be considered near the fixed point: \\[\nT(t = 0) = T^* + \\delta,\n\\] where \\(\\delta \\ll 1\\). Then we expand the solution into an asymptotic expansion, \\[\nT(t) = T^* + \\delta T_1(t) + \\delta T^2(t) + \\ldots\n\\] Substitution into the above ODE gives, at \\(O(\\delta)\\), \\[\nC \\frac{\\mathrm{d}T_1}{\\mathrm{d}t} = f'(T_0) T_1,\n\\] and hence, with \\(T_1(0) = 1\\), we have \\[\nT_1(t) = e^{f'(T_0) t/C}.\n\\] Therefore, depending on the positivity or negativity of the gradient function, the perturbation will either decay or grow as \\(t\\to\\infty\\).\nIt can then be verified that the centre equilbria is unstable while the other two are stable. The higher temperature corresponds to the one that the Earth is currently in, but according to this model, there seems to be the possibility of a colder climate (50 degrees colder) where the Earth is entirely covered with snow and ice.\nInterestingly, there is some evidence that the Earth’s climate may have been in this so-called state up to four times between 750 million and 580 million years ago (Neoproterozoic age). Observations of geological deposits suggest that the Earth has undergone periods of complete global glaciation where there have been very minimal biological activity. During this period, there is a massive build-up of CO2 in the atmopshere, leading to huge greenhouse effect. As \\(\\gamma\\) decreases in our model, the equilibrium can then shift, suddenly transitioning the Planet into the warm state."
  },
  {
    "objectID": "part-03-box/box-energy-model.html#numerical-continuation-of-the-steady-states",
    "href": "part-03-box/box-energy-model.html#numerical-continuation-of-the-steady-states",
    "title": "15  The basic EBM (steady-state)",
    "section": "15.3 Numerical continuation of the steady states",
    "text": "15.3 Numerical continuation of the steady states\nWe have done a preliminary steady-state analysis of \\[\nQ (1 - a(T)) - \\sigma \\gamma T^4,\n\\] but we would like to better understand how these steady-states may change depending on the parameters. For example, we would like to understand how the solutions vary of the solar constant related to \\(Q\\) varies; or we would like to understand how solutions vary as \\(\\gamma\\) varies.\nMore specifically, we would like to design some numerical routines that would allow us to (smartly!) solve for the roots of the above equation as the parameters are varied. Although the above problem (roots of a single equation) is simple enough to do this in a manual way, the methods of numerical continuation we learn in this chapter is applicable to much more general set of problems.\nSuppose that we are interested in studying how the steady-states (up to three) change as \\(Q\\) changes. Then we are interested in producing a diagram of \\(Q\\) vs. \\(T\\). The basic idea is to start with an initial solution at some value of \\(Q\\), increment \\(Q\\), then solve for the next value using the previous value as a guess. This involves the following pseudocode:\n\n\n\n\n\n\nNumerical continuation\n\n\n\n1. Input guess T0, f, df, parameter Q1\n\n    a. Call Newton's method via Newton(f, df, T0, Q1) \n    b. Obtain a preliminary solution (T1, Q1)\n\n2. Increment Q1 = Q1 + dQ \n\n    a. Call Newton's method via Newton(f, df, T1, Q1)\n    b. Obtain a new solution (T1, Q1)\n\n3. Repeat 2 until we reach a desired Q value\n\n\nThe following code provides continuation for one of the roots.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import fsolve\nfrom scipy.optimize import root\n\nsigma = 5.67e-8\ngamma = 0.62\na = lambda T: 0.5 - 0.2*np.tanh((T - 265)/10)\n\nQ0 = 342\nQmat = np.linspace(250, 450, 30)\nTmat = 0*Qmat\n\n# Initial guess\nx = 220\nfor i, Q in enumerate(Qmat):\n    f = lambda T: Q*(1-a(T)) - sigma*gamma*T**4\n    sol = root(f, x)\n    # If solution not found, output error\n    if sol.success != 1:\n        print(\"Q/Q0 = \", Q/Q0, \": \", sol.message)\n    Tmat[i] = sol.x\n\nplt.plot(Qmat/Q0, Tmat, 'o');\n\nplt.xlabel('Q/Q0');\nplt.ylabel('T');\n\nQ/Q0 =  1.2754587618471467 :  The iteration is not making good progress, as measured by the \n  improvement from the last ten iterations.\nQ/Q0 =  1.2956241177656787 :  The iteration is not making good progress, as measured by the \n  improvement from the last ten iterations.\nQ/Q0 =  1.3157894736842106 :  The iteration is not making good progress, as measured by the \n  improvement from the last five Jacobian evaluations.\n\n\n\n\n\nAbove, we have scaled \\(Q\\) with the reference value of \\(Q_0 = 342\\).\nIn your lecture, problem class, or exercises, you will design continuation on the other branches of solutions, and then study the result and its implications. During the lecture, we studied MA30287/notebooks/lecture13_EBM.ipynb which can be found at this link."
  },
  {
    "objectID": "part-03-box/box-energy-model.html#bifurcation-diagram",
    "href": "part-03-box/box-energy-model.html#bifurcation-diagram",
    "title": "15  The basic EBM (steady-state)",
    "section": "15.4 Bifurcation diagram",
    "text": "15.4 Bifurcation diagram\nIn reference to the above note, the following diagram was drawn and discussed in Lecture 15.\n\n\n\nFigure 15.1: Bifurcation diagram of \\(Q/Q_0\\) vs \\(T^*\\)\n\n\nWe noted the following:\n\nThe system has three steady states, given by the green, red, and blue curves.\nThe middle state is unstable (shown dashed).\nThe system exhibits hysteresis. Note that if we decrease \\(Q/Q_0\\) past the tipping point, marked \\(Q_{T1}\\) in the image, then we would evolve to the lower stable steady state (which is the ice state). However, while we are in the ice stated, if we were to attempt to increase the solar radiation to return to the green branch, we would need to arrive at \\(Q_{T2}\\) to do so; this irreversibility is known as hysteresis."
  },
  {
    "objectID": "part-03-box/box-energy-model.html#sec-budyko",
    "href": "part-03-box/box-energy-model.html#sec-budyko",
    "title": "15  The basic EBM (steady-state)",
    "section": "15.5 Re-scaling and Budyko’s model",
    "text": "15.5 Re-scaling and Budyko’s model\nTo model the outgoing radiation, we use the quartic Stefan-Boltzmann law. However, over the range of temperatures we are interested-in, it seems that a simpler approximation is sufficient. In your homework, you will investigate the re-scaling and shifting of temperature, such that \\[\nT = T_0 + [T]\\tilde{T},\n\\] where \\(T_0 = 265 \\mathrm{K}\\). Then under the assumption that temperatures are not-so-far from \\(T_0\\), we expand \\[\n(T_0 + [T]\\tilde{T})^4 \\sim T_0^4 + 4 T_0^3 [T] \\tilde{T} =\nC_1 + C_2 \\tilde{T}.\n\\] This simplifies the model considerably."
  },
  {
    "objectID": "part-03-box/box-energy-model2.html#incoming-energy",
    "href": "part-03-box/box-energy-model2.html#incoming-energy",
    "title": "16  EBM with latitude I",
    "section": "16.1 Incoming energy",
    "text": "16.1 Incoming energy\nWe make the following remarks about \\(E_{\\text{in}}\\).\n\nNotice that now, compared to the previous model, we have weighted the incoming solar constant \\(Q\\) with a term \\(s(y)\\) and also our albedo no longer directly depends on temperature but instead depends on the latitude.\nPoints on Earth that are closer to the equator receive more direct sunlight and experience more hours of daylight on average. We thus define a function \\(s(x)\\) to account for this and consider the incoming radiation as weighted by \\(Qs(y)\\).\nNote that the total solar input is calculated by a surface integral: \\[\n\\int_{\\theta = 0}^{\\theta = 2\\pi} \\int_{\\varphi = -\\pi/2}^{\\pi/2} Q s(y = \\sin\\varphi) (a^2 \\cos\\varphi) \\, \\mathrm{d}\\varphi \\mathrm{d}\\theta = 4\\pi a^2 Q \\int_0^1 s(y) \\, \\mathrm{d}y = 4\\pi a^2 Q,\n\\] if the function \\(s(y)\\) has been normalised appropriately so that its integral is equal to one, and furthermore the radiation is assumed symmetric about the equator.\nThe above is equal to the solar flux intercepted by an area of the circular disk of the earth seen by the sun, which is \\(\\pi a^2 S\\) for \\(S = 1370 \\mathrm{W}/\\mathrm{m}^2\\). Therefore \\(Q = S/4 \\approx 342 \\mathrm{W}/ \\mathrm{m}^2\\).\n\nFinally the function \\(s(y)\\) is fitted to data. We can assume it to be given by \\[\ns(y) = 1 - S_2 P_2(y), \\qquad S_2 = 0.482, \\quad P_2(y) = (3y^2 - 1)/2.\n\\tag{16.3}\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ny = np.linspace(0, 1, 20)\nplt.plot(y, 1 - 0.482*(3*y**2 - 1)/2)\nplt.xlabel('y'); plt.ylabel('s(y)');\n\n\n\n\nWe assume that an ice sheet forms if the temperature is sufficiently low, and \\(T < T_c = 10^\\circ \\mathrm{C}\\). The ice forms at an ice line, where \\(y = y_s\\). We then have the following form form the albedo: \\[\na(y) = \\begin{cases}\na_i = 0.62 & y > y_s, \\\\\na_w = 0.32 & y < y_s, \\\\\n\\frac{1}{2}(a_i + a_w) & y = y_s.\n\\end{cases}\n\\] Therefore we are using a discontinuous model for the albedo. Note that the ice boundary \\(y_s\\) is an unknown to be determined by the model.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nys = 0.7\ny = np.array([0, ys-0.0001, ys, ys+0.0001, 1])\nai = 0.62; aw = 0.32; \na = np.piecewise(y, [y < ys, y == ys, y > ys], [aw, 0.5*(aw+ai), ai])\nplt.plot(y, a, '-o') \nplt.xlabel('y'); plt.ylabel('a(y)');\n\n\n\n\nThe above forms what is referred to as a free-boundary problem, as the boundary \\(y = y_s\\) is solved as part of the model. Because \\(y_s\\) is essentially determined by where the temperature reaches the critical value, i.e. \\(T(y_s, t) = T_c\\), then the above albedo not only depends on latitude, but also on the current temperature distribution as well."
  },
  {
    "objectID": "part-03-box/box-energy-model2.html#outgoing-energy",
    "href": "part-03-box/box-energy-model2.html#outgoing-energy",
    "title": "16  EBM with latitude I",
    "section": "16.2 Outgoing energy",
    "text": "16.2 Outgoing energy\nThe outgoing energy is approximated via the linear Budyko approximation discussed in Section 15.5. \\[\nE_{\\text{out}} = A + BT,\n\\] where \\(A = 202 \\mathrm{W}/ \\mathrm{m}^2\\) and \\(B = 1.9 \\mathrm{W}/(\\mathrm{m}^2 {}^\\circ \\mathrm{C})\\). These figures are taken from a 1993 paper by Graves, Lee, and North."
  },
  {
    "objectID": "part-03-box/box-energy-model2.html#transport-energy",
    "href": "part-03-box/box-energy-model2.html#transport-energy",
    "title": "16  EBM with latitude I",
    "section": "16.3 Transport energy",
    "text": "16.3 Transport energy\nThe next term we should consider is the transport. In the case of this simple model, transport is taken to be modelled via a “Newton law of cooling” type expression. We assume that \\[\n\\text{rate of change of heat energy} = k(\\bar{T} - T),\n\\] where it can be verified (exercise) that the global mean temperature is the same as the hemispherically averaged temperature, i.e.  \\[\n\\bar{T} = \\frac{1}{\\text{surface area}} \\iint T \\, \\mathrm{S} = \\int_0^1 T(y) \\, \\mathrm{d}y.\n\\] Above, we shall use a value of \\(k = 1.6B\\), again estimated based on data and studies.\nThis completes our review of all the components (Equation 16.2) that make up the EBM model (Equation 16.1)."
  },
  {
    "objectID": "part-03-box/box-energy-model2.html#steady-state-temperature",
    "href": "part-03-box/box-energy-model2.html#steady-state-temperature",
    "title": "16  EBM with latitude I",
    "section": "16.4 Steady-state temperature",
    "text": "16.4 Steady-state temperature\nLet \\(T^*(y)\\) be the steady-state temperature and \\(\\bar{T}^*\\) be the corresponding global mean temperature. Then from setting the LHS of (Equation 16.1) to zero, we have the fact that \\(T^*\\) is given by solving the implicit equation: \\[\nT^*(y) = \\Phi(T^*) = \\frac{{\\color{blue}k}\\bar{T}^* + Qs(y)(1 {\\color{blue}-} \\alpha(y)) - A}{B + C}.\n\\] It is important to remember that the albedo, \\(\\alpha(y)\\), implicitly depends on \\(T^*\\) because at each location \\(y\\), we must decide if the temperature is less or greater than the threshold \\(T_c\\), which is the temperature of the ice line.\nThe above equation is somewhat tricky because of its implicit nature; it is made even trickier by virtue that multiple equilibria exist at the same parameter values. We will begin studying this problem, but before doing so, let us make a few remarks:\n\nIt is possible to solve for the steady-state global mean, \\(\\bar{T}^*\\) as a function of the ice line location, \\(y_s\\).\nIt is possible to solve for the ice line location, \\(y_s\\), although not entirely explicitly. Up to four solutions are possible.\nOnce the ice line is known it is possible to solve for the steady-state.\n\nHowever:\n\nA numerical solution can be developed without the need to go through the above procedures."
  },
  {
    "objectID": "part-03-box/latitude2.html#numerical-quadrature",
    "href": "part-03-box/latitude2.html#numerical-quadrature",
    "title": "17  EBM with latitude II",
    "section": "17.1 Numerical quadrature",
    "text": "17.1 Numerical quadrature\nAbove, one step that requires a comment is the integration for \\(\\bar{T}\\). There is a name for the long list of techniques of numerically calculating integrals: numerical quadrature. For our purposes, it is sufficient to go with a very simple approximation. In order to estimate the integral \\[\n\\bar{T} = \\int_0^1 T(y) \\, \\mathrm{d}y.\n\\] we estimate its value by a Riemann sum, i.e. a sum of rectangles approximating the area: \\[\n\\bar{T} \\approx \\sum_{i=0}^{N-2} T(y_i)(y_{i+1} - y_i).\n\\]"
  },
  {
    "objectID": "part-03-box/latitude2.html#latitude-vs.-temperature-dependent-albedo",
    "href": "part-03-box/latitude2.html#latitude-vs.-temperature-dependent-albedo",
    "title": "17  EBM with latitude II",
    "section": "17.2 Latitude vs. temperature-dependent albedo",
    "text": "17.2 Latitude vs. temperature-dependent albedo\nDuring the lecture, we will also discuss the two different albedos that have been introduced, namely, the latitude-dependent version, \\[\na(y) =\n\\begin{cases}\na_i & y > y_s, \\\\\na_w & y < y_s, \\\\\n\\frac{1}{2}(a_i + a_w) & y = y_s.\n\\end{cases}\n\\] which depends on the specification of a single ice sheet location, \\(y = y_s\\), where \\(T = T_C\\). This is to be compared with the alternative definition: \\[\na(T) =\n\\begin{cases}\na_i & T < T_C, \\\\\na_w & T > T_C, \\\\\n\\frac{1}{2}(a_w + a_w) & T = T_C.\n\\end{cases}\n\\] It seems that the first definition is inferior since the second allows for multiple transitions."
  },
  {
    "objectID": "part-03-box/latitude2.html#numerical-implementation-via-newtons-method",
    "href": "part-03-box/latitude2.html#numerical-implementation-via-newtons-method",
    "title": "17  EBM with latitude II",
    "section": "17.3 Numerical implementation via Newton’s method",
    "text": "17.3 Numerical implementation via Newton’s method\nThe remainder of the lecture is devoted to following the code written in MA30287/notebooks/lecture17-latitudeEBM_newton.ipynb which you can find here.\nThe result is a graph of \\(T(y)\\) vs \\(y\\) for a set of parameters.\n\n\n\nFigure 17.1: Temperature distribution"
  },
  {
    "objectID": "part-xx-exercises/problemclass04.html",
    "href": "part-xx-exercises/problemclass04.html",
    "title": "18  Problem class 4",
    "section": "",
    "text": "2022-23 note\n\n\n\nCovered in lecture 18.\n\n\nThis problem class will be devoted to getting started on problems from ?sec-ps4."
  },
  {
    "objectID": "part-03-box/latitude3.html#placement-of-the-ice-line",
    "href": "part-03-box/latitude3.html#placement-of-the-ice-line",
    "title": "19  EBM with latitude III",
    "section": "19.1 Placement of the ice line",
    "text": "19.1 Placement of the ice line\nUsing Newton’s method, we previously solved for a complete solution by starting off with a ‘lucky’ initial guess. For example, starting with a linear temperature distribution set to \\(T(0) = 20\\) and \\(T(1) = -20\\) we were able to converge to the profile shown below.\n\n\n\nFigure 19.1: Temperature distribution\n\n\nIt is seen in the image that the ice line lies roughly at \\(y_s = 0.85\\). Actually, this turns out to be wrong because the numerical method we applied previously in Chapter 17 was flawed in a very subtle way. We will eventually come to this realisation after the material from this chapter.\n\n\n\n\n\n\nInteractive matplotlib plots\n\n\n\nNote that it is now possible to gain interactivity with your matplotlib plots by inserting the magic command matplotlib ipympl at the top of your notebook files. The kernel will need to be restarted for this to take effect.\n\n\nWe want to know whether other solutions exist with ice lines at \\(y_s \\in [0, 1]\\)."
  },
  {
    "objectID": "part-03-box/latitude3.html#development-of-an-equation-for-the-ice-line",
    "href": "part-03-box/latitude3.html#development-of-an-equation-for-the-ice-line",
    "title": "19  EBM with latitude III",
    "section": "19.2 Development of an equation for the ice line",
    "text": "19.2 Development of an equation for the ice line\nIt turns out to be possible to develop an equation for the ice line.\nFirst, note from your problem set ?sec-ps4 you find that it is possible to solve for the steady-state mean temperature, which we write as \\(\\bar{T}^*\\). In your problem set, you will develop the following equation (given by (?eq-ps4-Tbar)): \\[\n\\bar{T}^* = \\frac{Q(1 - \\bar{a}) - A}{B}.\n\\tag{19.1}\\] The quantity \\(\\bar{a}\\) is given by integrating the albedo as follows: \\[\n\\bar{a} = \\int_0^1 s(y) a(y) \\, \\mathrm{d}y = a_i + (a_w {\\color{blue}-} a_i)y_s[1 - 0.241 (y_s^2 - 1)],\n\\tag{19.2}\\] which is given by (?eq-ps4-abar). You may check that the above formula has the right signs by considering either the complete ice case (ice line at the equator \\(y_s = 0\\)) or the complete water/land case (ice line at \\(y_s = 1\\)).\nNow we return to the implicit equation for the temperature, which is given by (Equation 17.3) and repeated here: \\[\nT^*(y) = \\Phi(T^*) = \\frac{k\\bar{T}^* + Qs(y)(1 {\\color{red}-} a(y)) - A}{B + k}.\n\\] Substitute the mean temperature in, and this now yields \\[\nT^*(y) = \\frac{Q}{B + k} \\left[ s(y) [1 - a(y)] + \\frac{k}{B}(1 - \\bar{a})\\right] - \\frac{A}{B}.\n\\tag{19.3}\\] This ice line is then found by setting \\(T = T_C\\) at \\(y = y_s\\) in the above formula. Notice, though, that since \\(s(y)\\) is a cubic function, then we would need to solve a cubic equation in general."
  },
  {
    "objectID": "part-03-box/latitude3.html#a-word-about-the-parameter-space",
    "href": "part-03-box/latitude3.html#a-word-about-the-parameter-space",
    "title": "19  EBM with latitude III",
    "section": "19.3 A word about the parameter space",
    "text": "19.3 A word about the parameter space\nSolutions to our latitude-dependent EBM can be symbolically written as follows: \\[\nT = T(t, y) = G(y; A, b, k, C, Q, a_i, a_w).\n\\] As you can see, even though it is a relatively simple equation in the sense it is only an ODE in time (and does not involve any spatial derivatives in \\(y\\)), is still complicated because the behaviour of the system can depend in a non-trivial way on all the parameters.\nYou can schematically think of the solution space as a being plotted in 8-dimensional space (or even higher, since the albedo \\(a\\) can be specified more generally). So for instance, bifurcation diagrams can then be plotted for some norm of the solution, say \\(\\bar{T}\\) versus the seven other parameters.\nThere are other representations of the bifurcation diagram(s). For example, you might plot \\(y_s\\) vs \\(Q\\) or \\(\\bar{T}\\) vs \\(A\\), and so forth."
  },
  {
    "objectID": "part-03-box/latitude3.html#a-bifurcation-diagram-for-q-vs-y_s",
    "href": "part-03-box/latitude3.html#a-bifurcation-diagram-for-q-vs-y_s",
    "title": "19  EBM with latitude III",
    "section": "19.4 A bifurcation diagram for \\(Q\\) vs \\(y_s\\)",
    "text": "19.4 A bifurcation diagram for \\(Q\\) vs \\(y_s\\)\nReturning to the ice line, we are interested in keeping all other parameters fixed, and then attempting to understand how the ice line evolves as the solar constant \\(Q\\) is changed. For example, we might believe that as \\(Q\\) increases (and hence temperatures rise), the ice line will move towards the North Pole. And as \\(Q\\) decreases, the ice line moves towards the equator.\nWe return to (Equation 19.3) and consider inverting the formulation. For each given ice line location, \\(y_s \\in (0, 1)\\), we solve for the \\(Q\\) value. This gives \\[\nQ = \\frac{\\left(T_C + \\frac{A}{B}\\right)(B + k)}{s(y_s)[1 - \\frac{1}{2}(a_i + a_w)] + \\frac{k}{B}(1 - \\bar{a})}.\n\\] Above, we have used the fact that \\(a(y_s) = \\frac{1}{2}(a_i + a_w)\\). This can now be plotted in Python, either in the notebook written during lectures, or via the code below.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nA = 202 # outgoing radiation\nB = 1.9 # outgoing radiation\nk = 1.6*B # transport parameter\ns = lambda y: 1 - 0.482*(3*y**2 - 1)/2 # solar weighting\naw = 0.32 # water albedo\nai = 0.62 # ice albedo\nTc = -10.0 # critical temperature for ice formation\nQ0 = 342.0 # solar constant (1370 W/m^2 divided by 4)\n\n# Note version in lectures was a 1/2 factor off on the second grouping of terms; \n# now corrected to match Q6 of PS4\nabar = lambda ys: ai + (aw - ai)*ys*(1 - 0.241*(ys**2 - 1))\nQfunc = lambda ys: (Tc + A/B)*(B+k)/(s(ys)*(1 - (ai+aw)/2) + k/B*(1 - abar(ys)))\n\n# Solve for the ice line\nys = np.linspace(0, 1, 100);\nQs = Qfunc(ys);\nplt.plot(Qs, ys, 'k')\nplt.plot([Q0, Q0], [0, 1], '--')\nplt.xlabel('Q');\nplt.ylabel('ys');\nplt.grid(1)\n\n\n\n\nOn the above graph, we have plotted the reference line, which is at \\(Q = 342\\) W-m-sq. So amazingly, there are two intersections with the black curve, which in fact indicates that two ice lines seem to be possible. One ice line as \\(y_s\\) near \\(0.95\\) and the other has \\(y_s\\) much lower down and near the equator.\nMoreover, the above graph is not complete! When we computed it, we specified that \\(a(y_s) = \\frac{1}{2}(a_i + a_w)\\) but this would not be true if there were no ice line, or equivalently if the ice line is located directly at \\(y = 1\\) or \\(y = 0\\). These yield the so-called ice-free states and ice-covered states, respectively."
  },
  {
    "objectID": "part-03-box/latitude3.html#ice-free-state",
    "href": "part-03-box/latitude3.html#ice-free-state",
    "title": "19  EBM with latitude III",
    "section": "19.5 Ice-free state",
    "text": "19.5 Ice-free state\nThe ice-free state is the state for which \\(a = a_w = \\bar{a}\\) for all \\(y \\in [0, 1)\\). In this case, the solution can be directly calculated from Equation 19.3. It would then be given by \\[\nT^*(y) = \\frac{Q(1 - a_w)}{B + k}\\left[s(y) + \\frac{k}{B}\\right] - \\frac{A}{B}.\n\\] This solution has a requirement, which is that when considering the solar constant \\(Q\\), the solar constant cannot be so weak so that an ice line appears for \\(y < 1\\). The minimum value of \\(Q\\) is therefore determined by pinning the ice line right at the North Pole. Thus \\[\nQ > \\frac{(B + k)(T_C + A/B)}{(1 - a_w)[s(1) + k/B]} \\approx 330 \\mathrm{W} \\, \\mathrm{m}^{-2}.\n\\] It is of interest to verify that the global mean temperature for a system in this state is a warm \\(16\\) degrees Celsius. According to this model, then, if the mean temperature is above this value, it is possible to have a state where there is no ice anywhere!"
  },
  {
    "objectID": "part-03-box/latitude3.html#ice-covered-state",
    "href": "part-03-box/latitude3.html#ice-covered-state",
    "title": "19  EBM with latitude III",
    "section": "19.6 Ice-covered state",
    "text": "19.6 Ice-covered state\nA similar argument applies setting \\(a = a_i = \\bar{a}\\) for all \\(y\\in (0, 1]\\). In this case, \\[\nT^*(y) = \\frac{Q(1 - a_i)}{B + k}\\left[s(y) + \\frac{k}{B}\\right] - \\frac{A}{B}.\n\\] This time, there is a maximal condition on \\(Q\\) such that any higher value would require an ice line somewhere within the domain, i.e. \\(y > 0\\). Thus \\[\nQ < \\frac{(B + k)(T_C + A/B)}{(1 - a_i)[s(0) + k/B]} \\approx 441 \\mathrm{W} \\, \\mathrm{m}^{-2}.\n\\] Again we may verify that this corresponds to a mean temperature of \\(-38\\) degrees Celsius.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nA = 202 # outgoing radiation\nB = 1.9 # outgoing radiation\nk = 1.6*B # transport parameter\ns = lambda y: 1 - 0.482*(3*y**2 - 1)/2 # solar weighting\naw = 0.32 # water albedo\nai = 0.62 # ice albedo\nTc = -10.0 # critical temperature for ice formation\nQ0 = 342.0 # solar constant (1370 W/m^2 divided by 4)\n\nQmin = ((B+k)*(Tc + A/B))/((1-aw)*(s(1)+k/B)) \nQmax = ((B+k)*(Tc + A/B))/((1-ai)*(s(0)+k/B))\nprint(\"Minimal Q for ice-free state = \", Qmin)\nprint(\"Max Q for ice-covered state = \", Qmax)\n\n# Note version in lectures was a 1/2 factor off on the second grouping of terms; \n# now corrected to match Q6 of PS4\nabar = lambda ys: ai + (aw - ai)*ys*(1 - 0.241*(ys**2 - 1))\nQfunc = lambda ys: (Tc + A/B)*(B+k)/(s(ys)*(1 - (ai+aw)/2) + k/B*(1 - abar(ys)))\n\n# Solve for the ice line\nys = np.linspace(0, 1, 100);\nQs = Qfunc(ys);\nplt.plot(Qs, ys, 'k')\nplt.plot([Q0, Q0], [0, 1], '--')\nplt.plot([250, Qmax], [0, 0], 'b')\nplt.plot([Qmin, 550], [1, 1], 'b')\nplt.xlabel('Q');\nplt.ylabel('ys');\nplt.grid(1)\n\nMinimal Q for ice-free state =  330.3616063989335\nMax Q for ice-covered state =  440.72694936919913"
  },
  {
    "objectID": "part-03-box/latitude3.html#partially-ice-covered-states",
    "href": "part-03-box/latitude3.html#partially-ice-covered-states",
    "title": "19  EBM with latitude III",
    "section": "19.7 Partially ice-covered states",
    "text": "19.7 Partially ice-covered states\nIn lectures, we demonstrated, via the code here the four possible solutions of the latitude EBM. Two of the solutions, developed above, correspond to completely covered ice-state and ice-free states. The other two solutions are partially-iced states.\n\n\n\nFigure 19.2: The four possible solutions; orange and blue show the completely-ice and ice-free states; red and green show the partial ice-covered state. These are shown for \\(A = 202\\), \\(B = 1.9\\), \\(k = 1.6 B\\), and \\(Q\\) = 342$\n\n\nIn the next chapter, we will examine the stability of these four states."
  },
  {
    "objectID": "part-03-box/latitude4.html#studying-the-mean-temperature",
    "href": "part-03-box/latitude4.html#studying-the-mean-temperature",
    "title": "20  EBM with latitude IV",
    "section": "20.1 Studying the mean temperature",
    "text": "20.1 Studying the mean temperature\nFollowing the previous chapter, we now have a better understanding of the relationship between the ice line, \\(y_s\\), and the solar forcing, \\(Q\\). We demonstrated that for the baseline case of \\(Q = 342\\), (at least) four solutions are possible.\n\n\n\nFigure 20.1: The iceline\n\n\nExamination of the root shows that the two non-trivial ice lines are approximately at \\(y_s = 0.256\\) and \\(y_s = 0.939\\) for \\(Q = 342\\). Using the script developed in lectures, we can study a similar graph of the mean temperature versus the solar forcing. Jupyter hub link.\nThis yields the following picture:\n\n\n\nFigure 20.2: Mean temperature\n\n\nDuring the lecture, we discussed the so-called Snowball Earth scenario where decreasing the solar constant may cause the stable state of the planet to jump down to the green branch shown above (completely frozen Earth). The solution exhibits hysteresis which describes the non-reversibility shown in the bifurcation diagram. This will be further expounded in the following discussion on stability."
  },
  {
    "objectID": "part-03-box/latitude4.html#stability",
    "href": "part-03-box/latitude4.html#stability",
    "title": "20  EBM with latitude IV",
    "section": "20.2 Stability",
    "text": "20.2 Stability\nSo far, we have only discussed the steady-state solutions of the latitude-dependent EBM, repeated below: \\[\nC \\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}t} = Qs(y)[1 - a(y)] - (A + BT) + k(\\bar{T} - T).\n\\] In this section, we investigate the stability analysis for the mean temperature, \\(\\bar{T}\\). This was given in ?eq-meanT-evo-ps and repeated below: \\[\nC \\frac{\\mathrm{d}\\bar{T}}{\\mathrm{d}t} = G(\\bar{T}) \\equiv Q(1 - \\bar{a}) - (A + B\\bar{T}),\n\\tag{20.1}\\] The following linearisation argument was presented by Cahalan and North (1979), with some additional details to avoid confusion. Let us linearise this about a steady-state solution, writing \\[\n\\bar{T} = \\bar{T}^* + u(t),\n\\] where \\(u \\ll 1\\). By Taylor series, \\[\nG(\\bar{T}) = G(\\bar{T}^*) + G'(\\bar{T}^*)u + O(u^2),\n\\] so substitution into the ODE yields the linear equation \\[\nC \\frac{\\mathrm{d}u}{\\mathrm{d}t} = G'(\\bar{T}^*) u.\n\\tag{20.2}\\] We need to calculate the derivative term on the RHS. First, using the equation for \\(G\\) in Equation 20.1, we have \\[\nG'(T^*) = -B - Q \\frac{\\mathrm{d}\\bar{a}}{\\mathrm{d}\\bar{T}}\\biggr\\rvert_{\\bar{T} = \\bar{T}^*}.\n\\tag{20.3}\\] The above calculation assumes that \\(Q\\) is a fixed number, as it should, since \\(Q\\) is regarded as a parameter (we choose a value of \\(Q\\), then this allows us to evolve the ODE).\n\n\n\n\n\n\nCalahan & North’s “trick”\n\n\n\nThe following presentation took about 3 lines of text in the presentation of Cahalan & North (1979), between eqns (1.2) and (1.3) in the image below. Students have inquired about the manipulations.\n\n\n\nFigure 20.3: From Cahalan & North, p.1179\n\n\n\n\nThe problem is what to do with the derivative of \\(\\bar{a}\\) that appears in (Equation 20.3). This is a strange quantity, since \\(\\bar{a}\\) does not explicitly depend on \\(\\bar{T}\\), and is given in (Equation 19.2). The issue is that there is a hidden dependence: \\(\\bar{a}\\) depends on the ice line, \\(y_s\\), which depends on not only \\(Q\\), but is multivalued as well! \nCahalan & North, whether knowingly or unknowingly, applied a trick, which is to consider that \\(Q\\) is not a parameter, but that it can be viewed as depending on \\(\\bar{T}^*\\), the steady state (this dependence is shown in Figure 20.2). Therefore, Cahalan & North returned to the equation (Equation 19.1) that gives the steady-state: \\[\nT^* = \\frac{Q(1 - \\bar{a}) - A}{B}.\n\\] We differentiate this equation with respect to \\(\\bar{T^*}\\), but now assume both \\(Q\\) and \\(\\bar{a}\\) depend on \\(\\bar{T^*}\\). This yields \\[\n1 = \\frac{1}{B} \\frac{\\mathrm{d}Q}{\\mathrm{d}\\bar{T^*}}(1 - \\bar{a}) - \\frac{Q}{B} \\frac{\\mathrm{d}\\bar{a}}{\\mathrm{d}\\bar{T}^*} \\Longrightarrow\nB = \\frac{\\mathrm{d}Q}{\\mathrm{d}\\bar{T^*}}(1 - \\bar{a}) - Q \\frac{\\mathrm{d}\\bar{a}}{\\mathrm{d}\\bar{T}^*}\n\\tag{20.4}\\]\nWe substitute the above value of \\(B\\) into (Equation 20.3), and then finally into the equation for the linearisation (Equation 20.2). Then we have \\[\nC \\frac{\\mathrm{d}u}{\\mathrm{d}t} = -\\left[(1 - \\bar{a}) \\frac{\\mathrm{d}Q}{\\mathrm{d}\\bar{T}^*}\\right]u(t) = -\\gamma u(t),\n\\] where the constant \\(\\gamma\\) has been defined by the above. Thus, the solution is given by \\[\nu(t) = u(0) e^{-\\gamma t/C}.\n\\]\nNote then that the crucial quantity is \\[\n\\gamma \\equiv (1 - \\bar{a}) \\frac{\\mathrm{d}Q}{\\mathrm{d}\\bar{T}^*}.\n\\] If \\(\\gamma\\) is positive, the equilibrium point is stable, while if \\(\\gamma\\) is negative, the equilibrium is unstable. Because \\((1 - \\bar{a}) > 0\\), then this yields the so-called slope-stability theorem coined by Cahalan and North (1979): \\[\n\\begin{align}\n\\frac{\\mathrm{d}Q}{\\mathrm{d}\\bar{T}^*} > 0 &\\Longrightarrow \\text{stable}, \\\\\n\\frac{\\mathrm{d}Q}{\\mathrm{d}\\bar{T}^*} < 0 &\\Longrightarrow \\text{unstable}.\n\\end{align}\n\\]\nWe may now plot the bifurcation diagram, shown in \\((Q, \\bar{T})\\)-space. First, return to Figure 20.2. In lecture 21, we drew the following picture:\n\n\n\nFigure 20.4: Bifurcation diagram for \\((Q, \\bar{T})\\)\n\n\nNote the following characteristics.\n\nThere are up to four steady states (green, orange, two blacks).\nThose branches with positive gradient are stable; there is only one branch with a negative gradient and it is thus unstable. In the image, these are shown solid for stable and dashed for unstable.\nThe diagram indicates tipping points and hysteresis. As explained in the lectures, one can encounter a situation where, beginning from the upper orange branches, the solar radiation is decreased past the tipping point. The solution must then evolve to the lowermost stable state (green). However, increasing \\(Q\\) does not return us to the original non-frozen state—unless \\(Q\\) is increased by a massive amount. This ‘hysteresis’ loop is shown with the maroon colours in the image above."
  },
  {
    "objectID": "part-03-box/iceages01.html#background",
    "href": "part-03-box/iceages01.html#background",
    "title": "21  Ice ages I: an introduction",
    "section": "21.1 Background",
    "text": "21.1 Background\nWe have mainly been concerned about time periods in the decades, but it is now time to discuss much longer time periods. In particular, we are interested in the Pleistocene era, which lasts from around 2.5 million years go to 11,700 years ago; this period marked the evolution of Homo sapiens. Begin by examining this figure:\n\n\n\nFigure 21.1: Figure from here\n\n\nThis figure indicates temperature changes tracked via various measures at different locations. The top two graphs show the temperatures derived from two different ice core measurements. The lower curve is the total ice cover. In this figure, you see evidence for the four complete glacial cycles with the Earth temperature dropping into the ice ages. A key observation concerns the regular periodic behaviour, with regular cycles appearing every 100k years.\nTurn now to this graph: \nThis graph goes back even further. The key observation is that between 1 million and 2.5 million years, the periods seem to be predominantly 41k years. Thus sudden transition is referred to as the Mid-Pleistocene Transition (MPT). The question of how or why the periods can suddenly change in such a manner is referred to as the 100,000-year problem."
  },
  {
    "objectID": "part-03-box/iceages01.html#milankovitch-cycles",
    "href": "part-03-box/iceages01.html#milankovitch-cycles",
    "title": "21  Ice ages I: an introduction",
    "section": "21.2 Milankovitch cycles",
    "text": "21.2 Milankovitch cycles\nThe most natural theory to explain the ice age periods is to consider that the Earth’s orbit is affected by the gravitational attractions of the Sun, Moon, and the other planets. The complex interaction results in a slow, cyclic change in three important parameters of the orbit (Taylor 2005):\n\nThe eccentricity of the ellipse that the Earth describes in its orbit around the Sun each year (100kyr);\nThe angle between the equatorial plane and the orbital plane, known as the Earth’s obliquity (41kyr);\nThe precession of the spin axis around the normal to the orbital plane (20kyr).\n\n\n\n\nFigure 21.2: Figure from here\n\n\nThe name given to these cycles is Milkankovich cycles.\nHowever, the key problem is that the Milankovich cycles do not seem to explain the MPT problem. The Milankovich cycles exhibit the necessary periods on both the 100kyr scale and 41kyr scale, but it cannot explain why there was a sudden transition. Moreover, the response of EBMs to the 100kyr forcing (due to the eccentricity) is not enough to explain why this forcing period takes precedence since it is the 41kyr cycle due to the obliquity that produces the largest effect on the solar radiation.\n\n\n\nFigure from here"
  },
  {
    "objectID": "part-03-box/iceages01.html#the-mathematicians-perspective-on-models",
    "href": "part-03-box/iceages01.html#the-mathematicians-perspective-on-models",
    "title": "21  Ice ages I: an introduction",
    "section": "21.3 The mathematician’s perspective on models",
    "text": "21.3 The mathematician’s perspective on models\nWe start with some discussion of the perspective of a mathematician. The last few weeks, we have been studying models of Planet Earth that take the form of first-order autonomous systems: \\[\nC \\frac{\\mathrm{d}T}{\\mathrm{d}t} = G(T),\n\\] or perhaps in the more recognisable ‘dynamical-systems’ form of \\[\n\\dot{x} = f(x),\n\\] for some function \\(x = x(t)\\). Because this is such a simple model, the analysis of the time-dependent evolution can be done on a phase line. Solutions can only exhibit two behaviours as \\(t \\to \\infty\\): they can tend towards a fixed point or they can diverge (to \\(\\pm \\infty\\)).\nThere are numerous ways to extend the basic EBM. For instance:\n\n(Latitude variation) Add latitude variation, with \\(G \\mapsto G(y, T)\\). Indeed this is what we had done in the last few chapters, and using a toy model (Newton’s law of cooling) that imposes a driver \\(k(\\bar{T} - T)\\) into the ODE.\n(PDEs) A more accurate model is to add a diffusion term, e.g. \\(k \\nabla^2 T\\). The Laplacian operator is then turned into a surface derivative in spherical coordinates along the planet. This turns the equation into a PDE, so is more involved to solve.\n(Non-autonomous forcing) We can consider the addition of temporal forcing, for instance, \\[\nG \\mapsto G(T) + \\epsilon f(t).\n\\] This would model, for instance, some oscillatory source input. For instance, this might model extra oscillatory effects due to the influence of the other planets.\n(Systems of DEs ) We might be interested in extending the model so that, in addition to modelling the evolution of the temperature, we also model the evolution of CO2 in the atmosphere. Or we might want a model where the albedo, itself, can evolve in time. An example of such a model is \\[\n\\begin{align}\nC \\frac{\\mathrm{d}T}{\\mathrm{d}t} &= Q[1 - a(t)] - \\sigma \\gamma T^4, \\\\\nD \\frac{\\mathrm{d}a}{\\mathrm{d}a} &= a_{\\text{eq}}(T) - a.\n\\end{align}\n\\] The above provides a model for ice sheet dynamics."
  },
  {
    "objectID": "part-03-box/iceages01.html#phase-plane-analysis-for-two-dimensional-systems",
    "href": "part-03-box/iceages01.html#phase-plane-analysis-for-two-dimensional-systems",
    "title": "21  Ice ages I: an introduction",
    "section": "21.4 Phase plane analysis for two-dimensional systems",
    "text": "21.4 Phase plane analysis for two-dimensional systems\nComing back now to the standard non-autonomous system of two ODEs, we have \\[\n\\begin{align}\n\\dot{x} &= f_1(x, y), \\\\\n\\dot{y} &= f_2(x, y).\n\\end{align}\n\\] What is the difference between these kinds of systems and the simpler 1D equations? The main difference is that the analysis is done in the phase plane given by \\((x, y)\\). Fixed points lie in the phase plane, but now there is the additional possibility of oscillations or circular orbits.\nAn example of this is the system \\[\n\\begin{align}\n\\dot{x} &= y - g(x), \\\\\n\\dot{y} &= h(x) - y.\n\\end{align}\n\\] For instance, choosing \\(h(x) = 4(2-x)\\) and \\(g(x) = \\sin x\\) yields the following phase plane diagram: \nWe see there exists a fixed point at where the two nullclines (dashed) intersect. Analysis near this fixed point would reveal that solutions encircle in a clockwise direction and tend towards the fixed point. This is shown by the solution plot on the right.\nTherefore, one way to extend our EBMs is to consider coupling to another component. Keep this in mind as this is where we will be going in the next lecture."
  },
  {
    "objectID": "part-03-box/iceages02.html#the-van-der-pol-oscillator",
    "href": "part-03-box/iceages02.html#the-van-der-pol-oscillator",
    "title": "22  Ice ages II: a model for fast-slow dynamics",
    "section": "22.1 The van der Pol oscillator",
    "text": "22.1 The van der Pol oscillator\nIn an article by Ditlevsen and Ashwin (2018) the authors argued that the following van der Pol oscillator presents a good toy model for understanding some of the dynamics that occur in ice ages: \\[\n\\frac{\\mathrm{d}^2 x}{\\mathrm{d}\\tau^2} = \\frac{1}{\\sqrt{\\epsilon}} (1 - x^2) \\frac{\\mathrm{d}x}{\\mathrm{d}\\tau} - \\alpha x + F(\\tau),\n\\] where \\(x = x(t)\\), \\(F(\\tau) = A \\cos(\\omega_F \\tau)\\) and \\(\\omega_F = (2\\pi/41) \\mathrm{kyr}^{-1}\\) represents a model for astronomical forcing. We will not discuss their ‘derivation’ of the above model (presented in their sec. 5), though it seems best to consider it solely as a toy model since otherwise their derivation of its validity based on EBM arguments is somewhat sketchy.\nIn any case, we are firstly interested in the case of zero forcing, \\(F \\equiv 0\\). It can be verified that through a transformation of time, \\(\\tau \\mapsto t\\), the above equation becomes\n\\[\n\\epsilon \\frac{\\mathrm{d}^2 x}{\\mathrm{d}t^2} + (x^2 - 1) \\frac{\\mathrm{d}x}{\\mathrm{d}t} + x = 0,\n\\] where we have chosen, without loss of generality, for \\(\\alpha = 1\\). Again we are considering \\(\\epsilon \\ll 1\\). This is a very well-known problem in nonlinear oscillations and it is the canonical example of fast-slow dynamics.\n\n22.1.1 The Lienard transformation\nWe first explain how to transform the above second-order equation so that it resembles the system of two linear differential equations shown above. Notice that the equation can be written in the form \\[\n\\frac{\\mathrm{d}}{\\mathrm{d}t} \\left(\\epsilon \\frac{\\mathrm{d}x}{\\mathrm{d}t} + \\frac{1}{3} x^3 - x \\right) + x = 0.\n\\tag{22.1}\\] We then define \\[\ny \\equiv \\epsilon \\frac{\\mathrm{d}x}{\\mathrm{d}t} + \\frac{1}{3} x^3 - x  \n\\] which can be re-arranged to yield \\[\n\\epsilon \\dot{x} = y - S(x), \\qquad S(x) \\equiv \\frac{1}{3}x^3 - x,\n\\] where we have used dots to indicate derivatives in time. The second equation is found by Equation 22.1 itself, since this yields \\[\n\\dot{y} = -x.\n\\] Therefore together, we have our system: \\[\n\\begin{align}\n\\epsilon \\dot{x} &= y - S(x), \\\\\n\\dot{y} &= -x.\n\\end{align}\n\\]\n\n\n22.1.2 An investigation in Python\nThe lecture will now investigate the scripts to see the qualitative behaviour of the ODE. We will design a phase plane plotter in Python and see why this is called a fast-slow system. The script can be found here: lecture23a-typicalphaseplot (where we show how to do phase plotting in Python) and then here: lecture23b-fastslow.\nDuring the lecture, we discussed the following image:\n\n\n\nPhase plot of the above system\n\n\nWe interpreted the dynamics that follow either the slow manifold, \\(y = S(x)\\), and also the fast transitions that occur between the branches of the cubic. Also shown on the right side of the above plots are the profiles, \\(x\\) and \\(y\\) versus \\(t\\). In the limit \\(\\epsilon \\to 0\\), the transitions begin to resemble shocks."
  },
  {
    "objectID": "part-03-box/iceages03.html#analysis-of-the-slow-manifold",
    "href": "part-03-box/iceages03.html#analysis-of-the-slow-manifold",
    "title": "23  Ice ages III: analysis of the van der Pol equation",
    "section": "23.1 Analysis of the slow manifold",
    "text": "23.1 Analysis of the slow manifold\nLet \\[\nx(t) = x_0(t) + \\epsilon x_1(t) + \\epsilon^2 x_2(t) + \\ldots, \\qquad y(t) = y_0(t) + \\epsilon y_1(t) + \\epsilon^2 y_2(t) + \\ldots\n\\] At leading order, we get the following system of equations: \\[\n\\begin{align}\n0 &= y_0 - S(x), \\\\\n\\dot{y_0} &= -x_0.\n\\end{align}\n\\tag{23.1}\\] First, examine the differential equation on the second line. Since the rate-of-change of \\(y\\) is equal to \\(-x\\), we can analyse the motion in the phase plane by the following cases: \\[\ny_0 \\text{ is }\n\\begin{cases}\n\\text{decreasing} & \\text{for $x_0 > 0$} \\\\\n\\text{increasing} & \\text{for $x_0 < 0$}\n\\end{cases}.\n\\] Therefore, we conclude that the \\(y\\) axis is nullcline in this leading-order approximation. The remaining equation restricts the solution to lie along the slow manifold, \\[\ny_0 = S(x) = \\frac{1}{3}x_0^3 - x_0.\n\\]\n\n\n\nIllustration of dynamics along the slow manifold\n\n\nAccording to our analysis, we should have both \\(y \\sim S(x)\\) as \\(\\epsilon \\to 0\\) and also \\(y\\) increasing on \\(x < 0\\) while decreasing on \\(x > 0\\). But this yields an apparent contradiction as \\(x\\to \\pm 1\\) and \\(y \\to \\mp 2/3\\).\nThe issue is that, at the critical point(s) where \\(x \\to \\pm 1\\), say \\(t = t^*\\), the solution encounters a shock or boundary layer where the gradient \\(\\dot{x}\\) is no longer small. Thus our prior assumption where we neglected \\(\\epsilon \\dot{x}\\) is invalid."
  },
  {
    "objectID": "part-03-box/iceages03.html#fast-analysis",
    "href": "part-03-box/iceages03.html#fast-analysis",
    "title": "23  Ice ages III: analysis of the van der Pol equation",
    "section": "23.2 Fast analysis",
    "text": "23.2 Fast analysis\nNear a shock, we re-scale \\[\nT = \\frac{t - t^*}{\\epsilon^\\alpha} \\Longrightarrow t = t^* + \\epsilon^\\alpha T,\n\\] and set \\(x(t) = X(T)\\) and \\(y(t) = Y(T)\\) under this new coordinate change. Essentially, this re-scales the coordinate axes, originally in \\(t\\), near the unknown location of the shock, \\(t = t^*\\). We can verify that the correct balance for re-scaling is chosen with \\(\\alpha = 1\\). From the chain rule, we convert derivatives as follows: \\[\n\\frac{\\mathrm{d}}{\\mathrm{d}t} = \\frac{\\mathrm{d}T}{\\mathrm{d}t} \\frac{\\mathrm{d}}{\\mathrm{d}T} = \\frac{1}{\\epsilon} \\frac{\\mathrm{d}}{\\mathrm{d}T}.\n\\] Then the system becomes \\[\n\\begin{align}\n\\frac{\\mathrm{d}X}{\\mathrm{d}T} &= Y - S(X) \\\\\n\\frac{\\mathrm{d}Y}{\\mathrm{d}T} &= -\\epsilon X.\n\\end{align}\n\\] We expand now in the typical fashion, setting \\[\n\\begin{align}\nX &= X_0(T) + \\epsilon X_1(T) + \\ldots \\\\\nY &= Y_0(T) + \\epsilon Y_1(T) + \\ldots\n\\end{align}\n\\] At leading order, this now yields \\[\n\\begin{align}\n\\frac{\\mathrm{d}X_0}{\\mathrm{d}T} &= Y_0 - S(X_0) \\\\\n\\frac{\\mathrm{d}Y_0}{\\mathrm{d}T} &= 0.\n\\end{align}\n\\]\nTherefore, from the second equation, we obtain \\[\nY_0 = \\text{constant}\n\\] which is to be expected from the phase-plane diagrams we have shown. Since we have established that the max/min of the slow manifold, \\(S(X)\\), is given by \\(\\pm 2/3\\), then we know that the above constant is this value if the solution had begun from the slow manifold (see comment later about the initial condition).\nNext, the equation for \\(X_0\\) has the form of a first-order nonlinear differential equation that can be studied by phase-line analysis. If the constant \\(Y_0\\) is indeed \\(\\pm 2/3\\), then the differential equation for the other component takes the form \\[\n\\frac{\\mathrm{d}X_0}{\\mathrm{d}T} = Y_0 - S(X_0) = \\pm \\frac{2}{3} - S(X_0).\n\\]\nThis leads to the following picture.\n\n\n\nFigure 23.1: Fast dynamics\n\n\nTo begin, we consider the evolution from the points marked ‘A’ and ‘B’. This occurs along the slow manifold. At the point ‘B’, time reaches the critical point, \\(t \\to t^*\\), and the solutions enter the fast dynamics, following along points ‘B’ to ‘C’. Notice that along this segment in the phase plane, \\[\n\\frac{2}{3} - S(X_0) > 0,\n\\] therefore \\(X_0\\) must increase during this time. However, upon approaching the point ‘C’, the above LHS tends to zero, and hence \\(X_0\\) slows its increase. This exists the fast dynamics layer and again the solution continues along the slow manifold from ‘C’ to ‘D’. Upon reaching ‘D’, it again enters a stage of fast dynamics (the \\(t^*\\) point here is a new one)."
  },
  {
    "objectID": "part-03-box/iceages03.html#initial-conditions",
    "href": "part-03-box/iceages03.html#initial-conditions",
    "title": "23  Ice ages III: analysis of the van der Pol equation",
    "section": "23.3 Initial conditions",
    "text": "23.3 Initial conditions\nYou will notice that above, we have not really discussed the effect of the initial conditions, say, \\[\n\\begin{align}\nx(0) &= A, \\\\\ny(0) &= B.\n\\end{align}\n\\] Perhaps more specifically, we have performed our asymptotic analysis with the assumption that the solution starts directly on the slow manifold, i.e. \\(y \\sim S(x)\\). Returning to the slow analysis leading to Equation 23.1 notice that the above conditions will not in general be compatible with the equations (since ‘A’ and ‘B’ might be chosen completely different from those values where \\(y = S(x)\\)). The conclusion is then that the slow analysis applied cannot be valid near the initial condition.\nThis turns out to be very similar to the example studied in Chapter 12, which also had a time-dependent problem where the initial condition was incompatible.\nTherefore near \\(t = 0\\), we must introduce an analogous boundary layer. This analysis will be identical to the above fast-scale dynamics except that \\(t^* = 0\\). The conclusion is that if we begin off the manifold \\(y = S(x)\\), the solution will rapidly tend left or right in the phase plane (at near-constant values of \\(y\\)). Once it intersects with the manifold, the trajectories then resume the slow and fast dynamics observed above.\nThis is now shown below for the initial condition of \\(x(0) = 2.5\\), \\(y(0) = -1.5\\) and \\(\\epsilon = 0.05\\).\n\nNotice the red circle in the left phase plot showing the initial condition. We see that the solutions then exhibit the fast dynamics, with \\(x\\) decreasing, until encountering the slow manifold. Thereafter it follows the standard slow-fast dynamics.\nOn the right image, notice the significant shock or boundary layer near \\(t = 0\\). If desired, we could confirm the size of this boundary-layer regions scales with \\(\\epsilon\\)."
  },
  {
    "objectID": "part-03-box/iceages04.html#slow-analysis",
    "href": "part-03-box/iceages04.html#slow-analysis",
    "title": "24  Fast-slow dynamics for higher-order systems",
    "section": "24.1 Slow analysis",
    "text": "24.1 Slow analysis\nWe thus expand the solutions in the typical way, setting \\[\n\\begin{align}\ns(t) &= s_0(t) + \\epsilon s_1(t) + \\ldots \\\\\nc(t) &= c_0(t) + \\epsilon c_1(t) + \\ldots \\\\\np(t) &= p_0(t) + \\epsilon p_1(t) + \\ldots\n\\end{align}\n\\] This yields at leading order, \\[\n\\begin{align}\n\\frac{\\mathrm{d}s_0}{\\mathrm{d}t} &= -s_0(1 - c_0) + \\lambda c_0, \\\\\n0 &= s_0(1 - c_0) - \\mu c_0,\\\\\n\\frac{\\mathrm{d}p_0}{\\mathrm{d}t} &= (\\mu - \\lambda)c_0,\n\\end{align}\n\\tag{24.2}\\]\nThe second equation yields the slow manifold, for which we expect \\[\ns(c_0) = \\frac{\\mu c_0}{1 - c_0}.\n\\tag{24.3}\\]\n\n\n\nFigure 24.3: Numerical solution as before but now plotted in the \\((c, s)\\) phase plane. The dashed line is the approximation derived above."
  },
  {
    "objectID": "part-03-box/iceages04.html#fast-dynamics-near-the-initial-condition",
    "href": "part-03-box/iceages04.html#fast-dynamics-near-the-initial-condition",
    "title": "24  Fast-slow dynamics for higher-order systems",
    "section": "24.2 Fast dynamics near the initial condition",
    "text": "24.2 Fast dynamics near the initial condition\nAs with our van der Pol example, the initial condition, where \\(c(0) = 0\\) and \\(s(0) = 1\\), does not lie on the slow manifold above. Therefore we expect that there is a boundary layer where the system rapidly begins from the initial condition and tends to the slow manifold. The distinguished scaling on time can be confirmed to be \\[\nt = \\epsilon^\\alpha T = \\epsilon T,\n\\] where \\(\\alpha = 1\\). We then set \\[\ns = S(T) \\qquad c = C(T),\n\\] for our new unknowns within this later. Under the scaling, the first two ODEs in (Equation 24.1) become \\[\n    \\begin{align}\n    \\frac{\\mathrm{d}S_0}{\\mathrm{d}T} &= 0,  & S_0(0) &= 1 \\\\\n    \\frac{\\mathrm{d}C_0}{\\mathrm{d}T} &= S_0(1 - C_0) - \\mu C_0. & C_0 &= 0.\n    \\end{align}\n    \\] Therefore, you see that the leading-order value of \\(S\\) is expected to be constant, and it remains at its initial value, \\[\n    S_0(T) \\equiv 1.\n    \\] Although we could solve for the concentration of \\(c\\) or \\(C\\), this turns out not to be necessary. It should first be remarked that as the outer solution, \\(s \\sim s_0\\), tends to the initial condition, \\(t \\to 0\\), we should have \\[\n    \\lim_{t \\to 0} s_0(t) = 1 = \\lim_{T\\to \\infty} S_0(T).\n    \\] Compare this with the condition (Equation 12.2) when we initially studied the method of matched asymptotics. Therefore, even though there is a boundary layer necessary for the concentration \\(c\\) near \\(t = 0\\), we do not need to resolve it."
  },
  {
    "objectID": "part-03-box/iceages04.html#an-equation-for-the-substrate-and-product",
    "href": "part-03-box/iceages04.html#an-equation-for-the-substrate-and-product",
    "title": "24  Fast-slow dynamics for higher-order systems",
    "section": "24.3 An equation for the substrate and product",
    "text": "24.3 An equation for the substrate and product\nTake now (Equation 24.3), which yields \\[\nc_0 = \\frac{s_0}{\\mu + s_0},\n\\] and substitute this into the first and third equations (Equation 24.2). This gives \\[\n\\begin{align}\n\\frac{\\mathrm{d}s_0}{\\mathrm{d}t} &= - \\frac{\\mu - \\lambda}{\\mu + s_0} s_0, \\\\\n\\frac{\\mathrm{d}p_0}{\\mathrm{d}t} &= \\frac{\\mu - \\lambda}{\\mu + s_0} s_0\n\\end{align}\n\\] Notice that actually, if we add these two equations, we come out with \\[\n\\frac{\\mathrm{d}}{\\mathrm{d}t}(s_0 + p_0) = 0,\n\\] which is a conservation of mass/concentration statement that indicates that the total substrate and product is conserved. Therefore, if we only solve the first equation for \\(s_0\\): \\[\n\\frac{\\mathrm{d}s_0}{\\mathrm{d}t} = - \\frac{\\mu - \\lambda}{\\mu + s_0} s_0, \\qquad s_0(0) = 1,\n\\tag{24.4}\\] we can obtain the product concentration by \\(p_0 = 1 - s_0\\).\nThe above equation (Equation 24.4) is in fact a famous result in biochemistry. It indicates that the substrate concentration follows a nonlinear rate and is called the Michaelis-Menten law. We have significantly simplified the necessary mathematical analysis down from the analysis of coupled system of three equations to a single equation for a single unknown (\\(s_0\\))!\n\n\n\nFigure 24.4: Numerical solution of the single differential equation"
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#terminology-and-context",
    "href": "part-03-box/basic-ocean-model.html#terminology-and-context",
    "title": "25  Basic models of the ocean",
    "section": "25.1 Terminology and context",
    "text": "25.1 Terminology and context\nThe ocean plays a significant role in regulating the Earth’s climate, as it acts as a massive heat sink and helps to distribute heat and moisture around the planet. In addition, carbon dioxide is water soluble, and through precipitation and wave motion, is transferred into the oceans. Thus the ocean acts as a sink, absorbing large amounts of this greenhouse gas from the atmosphere.\nThe thermohaline circulation (THC), also known as the global ocean conveyor belt, is a complex ocean circulation pattern that is driven by differences in water temperature and salinity. It is an important component of the Earth’s climate system, as it helps to distribute heat and other properties throughout the planet’s oceans.\nThe thermohaline circulation is driven by the sinking of cold, dense water in the polar regions, which then spreads out and flows towards the equator. As the water warms and becomes less dense, it rises to the surface and returns to the poles, creating a continuous loop of ocean currents. The role of salinity in driving the thermohaline circulation is due to the fact that the dissolved salts in seawater increase its density.\nThis circulation pattern has a significant impact on global climate, as it helps to regulate the exchange of heat and other properties between the oceans and the atmosphere. Changes in the thermohaline circulation, such as those caused by global warming, can have far-reaching effects on the planet’s climate and weather patterns.\n\n\n\nFigure 25.1: The thermohaline circulation. In the Atlantic, the circulation carries warm water (red) north near the surface and cold deep water (blue) south. Image from NASA/JPL."
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#temperature",
    "href": "part-03-box/basic-ocean-model.html#temperature",
    "title": "25  Basic models of the ocean",
    "section": "25.2 Temperature",
    "text": "25.2 Temperature\n\n\n\n\n\n\nExtra content\n\n\n\nThe material in this subsection is not examinable in 2022-23 and is given here for further context.\n\n\nIn regards to the temperature, the ocean can be divided into three layers.\n\nThe top layer is thin (on the order of metres) and is heated from the Sun. Mixing is a dominant effect due to wind and waves, and so the temperature in this region is mostly constant.\nThe thermocline region is the intermediate layer. Here, the temperature decreaes approximately linearly.\nThe deep abyssal zone comprises 98% of the total volume of the oceans. The temperature in this region is mostly constant, and a few degrees above freezing.\n\nWithin the intermediate region, the temperature can be modelled by an advection diffusion equation, \\[\n\\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}t} + w \\frac{\\mathrm{\\partial}T}{\\mathrm{\\partial}z} = \\kappa \\frac{\\mathrm{\\partial}^2 T}{\\mathrm{\\partial}z^2},\n\\tag{25.1}\\] where \\(w\\) is the upswelling velocity and \\(\\kappa\\) is the diffusion coefficient of the fluid.\nLet us assume that the temperature in this region is near steady state and that the upwards velocity is constant. Then we integrate the ODE to find \\[\nT(z) = T_0 + T_1 \\mathrm{e}^{-z/z^*},\n\\] where \\(T_0\\) and \\(T_1\\) are constants. From (Kaper and Engler 2013), the typical orders for the parameters are \\(\\kappa \\sim 10^{-2} \\,\\mathrm{m}^{2} \\,\\mathrm{s}^{-1}\\) and \\(z^* \\sim 10^2 \\, \\mathrm{m}\\), so \\(w \\sim 10^{-4} \\,\\mathrm{m} \\,\\mathrm{s}^{-1}\\), which is quite slow.\n\n\n\nFigure 25.2: Cross section of the Atlantic Ocean, showing the temperature and salinity profiles on the right. Image from (Kaper and Engler 2013)."
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#salinity-and-density",
    "href": "part-03-box/basic-ocean-model.html#salinity-and-density",
    "title": "25  Basic models of the ocean",
    "section": "25.3 Salinity and density",
    "text": "25.3 Salinity and density\nSalinity is a key component in the oceans since the salts have a large effect on the water density (which consequently drives motion). Salinity is measured in psu or practical salinity units, which is a non-dimensional ratio of conductivities. In the mixed layer, the sainity ranges from 31-39 psu, and is about 35 in the abyssal zone. You can inspect the profile in Figure 25.2.\nBelow in the study of the ocean, we will need a so-called equation of state, which connects the density, \\(\\rho\\), with the salinity, say \\(S\\), and temperature, say \\(T\\). Here is a typical graph of the relationship.\n\n\n\nFigure 25.3: Image from (Kaper and Engler 2013)"
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#two-box-model-of-the-ocean",
    "href": "part-03-box/basic-ocean-model.html#two-box-model-of-the-ocean",
    "title": "25  Basic models of the ocean",
    "section": "25.4 Two-box model of the ocean",
    "text": "25.4 Two-box model of the ocean\nModelling the THC is a challenging task! In principal, this might involve the solution of multiple coupled PDEs for the flows and temperatures, which would then need to be solved on a very complicated domain. In addition, such models require a number of empirical equations of state (connecting density to temperature and salinity).\nToy models can be developed much more easily at the ‘systems level’ via box models."
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#a-one-dimensional-model-constant-temperature",
    "href": "part-03-box/basic-ocean-model.html#a-one-dimensional-model-constant-temperature",
    "title": "25  Basic models of the ocean",
    "section": "25.5 A one-dimensional model (constant temperature)",
    "text": "25.5 A one-dimensional model (constant temperature)\nConstruction and assumptions of the box model.\n\nWe consider two boxes, labeled ‘1’ and ‘2’, respectively via subscripts. Box 1 corresponds to high latitudes (near poles) and Box 2 to low latitudes (near equator). Each box has a corresponding temperature, \\(T_i\\), and salinity, \\(S_i\\). In each box, the temperature and salinities are well mixed, so they take different values in either box, in general.\nDifferences between the two boxes will drive a flow through the capillary pipe that connects the boxes at the bottom. A compensating flow at the surface ensures that the volume of water in each box does not change. Together, these two exchanges (top and bottom) represent the overturning circulation of the THC.\nWe assume (see above) that the strength of the exchange flow between the boxes is linearly proportional to their differences of temperature and salinity. In particular, let \\(\\rho_1\\) and \\(\\rho_2\\) be the two densities in the corresponding boxes. The flow \\(q\\) in the capillary pipe is driven by the difference \\[\nq = k \\frac{\\rho_1 - \\rho_2}{\\rho_0},\n\\tag{25.2}\\] where \\(k\\) is the hydraulic constant and takes the typical value of \\(k = 1.5 \\cdot 10^{-6} \\, \\mathrm{s}^{-1}\\). The reference density \\(\\rho_0\\) is defined in conjunction with the equation of state.\nIn the normal state of the planet, \\(q > 0\\) when the flow through the capillary goes in the direction of the equator as a result of higher densities at high latitudes.\nWe need an equation of state that connects the densities, \\(\\rho\\), with the temperature and salinities. This concerns the figure Figure 25.3. We assume that \\[\n\\rho = \\rho_0(1 - \\alpha(T - T_0) + \\beta(S - S_0)),\n\\tag{25.3}\\] where \\(T_0\\) and \\(S_0\\) are average values of temperature and salinity; \\(\\rho_0\\) is the density if \\(T = T_0\\) and \\(S = S_0\\); \\(\\alpha\\) and \\(\\beta\\) are constants with typical values \\(\\alpha = 1.5 \\times 10^{-4} \\mathrm{deg}^{-1}\\) and \\(\\beta = 8 \\times 10^{-4} \\mathrm{psu}^{-1}\\). Combining (Equation 25.2) with (Equation 25.3) gives \\[\nq = k[ \\alpha(T_2 - T_1) - \\beta(S_2 - S_1)].\n\\tag{25.4}\\]\nExternal wind forces and Coriolis effects are ignored.\nWe assume that in each box, there is an exchange of heat and salinity to the surrounding environment. For instance, salinity will exchange due to evaporation, precipitation, and runoff. These will have constant of proportionalities of \\(c\\) and \\(d\\) in the equations below.\nPrecipitation, evaporation, and runoff from the continents and atmosphere will also cause the salinity in either box to change. We therefore assume that this is modeled by a flux \\(H\\).\nRemember that in general, \\(T_2 > T_1\\) (the temperatures at the equator are higher). Consequently, evaporation dominates Box 2; there is a net loss of salt-free moisture in the atmosphere and this causes a compensating virtual flux of salt, \\(H > 0\\), into Box 2. At the same time, there is higher precipitation and runoff into Box 1 (due to lower temperatures), causing a net gain of salt-free moisture and therefore a loss of virtual salt, say \\(-H < 0\\). We assume these two virtual salt fluxes sum to zero.\nNote that in the normal state of affairs, \\(S_2 > S_1\\), and the lower latitude water is saltier than that of high latitudes.\n\nAn image of the box model is shown below.\n\n\n\nFigure 25.4: Two-box model of the North Atlantic with evaporation and precipitation. Image from (Kaper and Engler 2013)\n\n\nThe equations are given as follows.\n\\[\n\\begin{align}\n\\frac{\\mathrm{d}T_1}{\\mathrm{d}t} &= c(T_1^* - T_1) + |q|(T_2 - T_1) \\\\\n\\frac{\\mathrm{d}T_2}{\\mathrm{d}t} &= c(T_2^* - T_2) + |q|(T_1 - T_2) \\\\\n\\frac{\\mathrm{d}S_1}{\\mathrm{d}t} &= -H + d(S_1^* - S_1) + |q|(S_2 - S_1) \\\\\n\\frac{\\mathrm{d}S_2}{\\mathrm{d}t} &= H + d(S_2^* - S_2) + |q|(S_1 - S_2)\n\\end{align}\n\\tag{25.5}\\]\nNote that in the exchange terms corresponding to the flow \\(q\\) in the capillary pipes, we use an absolute value since it does not matter (flows are exchanged in both lower and upper pipes).\nNote also that \\(q = q(T_1, T_2, S_1, S_2)\\) as given in (Equation 25.4)."
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#reducing-the-equations-via-symmetry",
    "href": "part-03-box/basic-ocean-model.html#reducing-the-equations-via-symmetry",
    "title": "25  Basic models of the ocean",
    "section": "25.6 Reducing the equations via symmetry",
    "text": "25.6 Reducing the equations via symmetry\n\nBy adding the equations (Equation 25.5), it can be verified that in the limit \\(t \\to \\infty\\), the average temperature in the system, \\(1/2(T_1 + T_2)\\) tends to the average temperature in the surrounding basins \\(1/2(T_1^* + T_2^*)\\). The same conclusion can be drawn for the corresponding salinities.\nIt is then sensible to write all temperature and salinity in terms of this baseline scenario. So let us write \\[\\begin{align}\nT_1 &= \\frac{1}{2}m + U_1, \\\\\nT_2 &= \\frac{1}{2}m + U_2,\n\\end{align}\\] where \\(m = T_1^* + T_2^*\\). Then the first equation becomes \\[\\begin{align}\n\\frac{\\mathrm{d}U_1}{\\mathrm{d}t} &= c\\left(T_1^* - U_1 - \\frac{1}{2}m\\right) + |q| (U_2 - U_1)\\\\\n&= c\\left(- T^*  - U_1\\right) + |q| (U_2 - U_1).\n\\end{align}\\] where \\(T^* = \\frac{1}{2}(T_2^* - T_1^*)\\).\nThe analgous manipulations are done to the quantities for the salinity. In the end, if we (confusingly) re-write \\(T\\) for \\(U\\), then we obtain \\[\n\\begin{align}\n\\frac{\\mathrm{d}T_1}{\\mathrm{d}t} &= c(-T^* - T_1) + |q|(T_2 - T_1) \\\\\n\\frac{\\mathrm{d}T_2}{\\mathrm{d}t} &= c(T^* - T_2) + |q|(T_1 - T_2) \\\\\n\\frac{\\mathrm{d}S_1}{\\mathrm{d}t} &= -H + d(-S^* - S_1) + |q|(S_2 - S_1) \\\\\n\\frac{\\mathrm{d}S_2}{\\mathrm{d}t} &= H + d(S^* - S_2) + |q|(S_1 - S_2)\n\\end{align}\n\\tag{25.6}\\]\nComparing the above to Equation 25.5, the main difference is that, in expressing the temperature and salinities with respect to the average values in the basin, we have eliminated two of the constants from the set \\((T_1^*, T_1^*, S_1^*, S_2^*)\\) now only into two constants \\((T^*, S^*)\\).\nIn the situation of zero salt flux. \\(H = 0\\), the above model reduces to Stommel’s box model studied in Chapter 26."
  },
  {
    "objectID": "part-03-box/basic-ocean-model.html#sec-ocean-toysalinity",
    "href": "part-03-box/basic-ocean-model.html#sec-ocean-toysalinity",
    "title": "25  Basic models of the ocean",
    "section": "25.7 Analysis of a reduced 1D model for the salinity",
    "text": "25.7 Analysis of a reduced 1D model for the salinity\nIt is possible to do some analysis on the system (Equation 25.6), though we may prefer to simply move on to study the more historically well-known reduction called Stommel’s box model in Chapter 26.\nWe make the following assumptions:\n\nWe assume that on the timescale of interest in the THC, the temperature of each box equilibrates quickly with the surrounding basin. Therefore the system can be regarded as being in steady state.\n\nThe difference in temperatures between the two boxes is small; together with the top assumption, this implies that \\(T_1(t) = -T^*\\) and \\(T_2(t) = T^*\\).\nSalinity exchanges by negligible amounts with its surrounding basin, i.e. \\(d = 0\\)\n\nThis leaves us with \\[\\begin{align}\n\\frac{\\mathrm{d}S_1}{\\mathrm{d}t} &= -H + |q|(S_2 - S_1) \\\\\n\\frac{\\mathrm{d}S_2}{\\mathrm{d}t} &= H + |q| (S_1 - S_2),\n\\end{align}\\] where \\(q = k(2\\alpha T^* - \\beta(S_2 - S_1))\\).\nNow, the formulation for the salinities can be placed into a single equation for \\(\\Delta S = S_2 - S_1\\), which satisfies \\[\n\\frac{\\mathrm{d}\\Delta S}{\\mathrm{d}t} = 2H - 2k|\\alpha \\Delta T - \\beta \\Delta S| \\Delta S.\n\\tag{25.7}\\]\nThis is now a much simpler and elegant formulation for study. Under a suitable non-dimensionalisation and scaling, we can even place the above equation in the final simplified form of \\[\n\\dot{x} = \\lambda - |1 - x| x,\n\\] where \\(\\lambda > 0\\) (for temperatures in the usual configuration, with \\(T_2 - T_1 > 0\\), and a suitably defined function \\(x = x(t)\\).\n\n\n\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM."
  },
  {
    "objectID": "part-03-box/stommel.html#non-dimensionalisation",
    "href": "part-03-box/stommel.html#non-dimensionalisation",
    "title": "26  Stommel’s box model",
    "section": "26.1 Non-dimensionalisation",
    "text": "26.1 Non-dimensionalisation\nWe can then nondimensionalise the system by setting \\[\nx = \\frac{\\Delta S}{\\Delta S^*}, \\quad y = \\frac{\\Delta T}{\\Delta T^*}, \\quad t' = ct,\n\\] where \\(t'\\) is nondimensional time. Dropping the primes henceforth, we have the following set of non-dimensional equations to study for the unknowns, \\(x = x(t)\\), and \\(y = y(t)\\): \\[\n\\begin{align}\n\\frac{\\mathrm{d}x}{\\mathrm{d}t} &= \\delta(1 - x) - |f(x, y)|x, \\\\\n\\frac{\\mathrm{d}y}{\\mathrm{d}t} &= 1 - y - |f(x, y)|y,\n\\end{align}\n\\tag{26.2}\\] where we have introduced the function, \\[\nf(x, y; R, \\lambda) = \\frac{1}{\\lambda}(Rx - y),\n\\tag{26.3}\\] where there are now three non-dimensional parameters given by \\[\n\\begin{align}\n\\delta &= d/c, \\\\\n\\lambda &= c/(2\\alpha k \\Delta T^*), \\\\\nR &= \\beta \\Delta S^*/(\\alpha \\Delta T^*).\n\\end{align}\n\\] Together Equation 26.2 and Equation 26.3 form a system of equations for \\((x(t), y(t))\\), with parameters \\(\\delta\\), \\(\\lambda\\), and \\(R\\).\nAlthough there are many parameters, it is important to note that the quantity \\(f\\) is crucial since it corresponds to the direction of flow in the bottom pipe of the Ocean model. By convention, the system was set up so that \\(f > 0\\) corresponds to flow through the bottom pipe goes in the direction of the equator (Box 1) as a result of higher densities at the high latitudes. We are subsequently interested in whether it is possible for \\(f\\) to switch sign, which would correspond to a bottom flow going from equator to poles, and the entire system switching direction."
  },
  {
    "objectID": "part-03-box/stommel.html#sec-ocean2-equil",
    "href": "part-03-box/stommel.html#sec-ocean2-equil",
    "title": "26  Stommel’s box model",
    "section": "26.2 Equilibrium states",
    "text": "26.2 Equilibrium states\nLet the equilibrium states be given by \\((x^*, y^*)\\) with \\(f(x^*, y^*) = f^*\\). Then setting the right hand sides of (Equation 26.2) to zero and solving, we find \\[\nx^* = \\frac{\\delta}{\\delta + |f^*|} \\quad \\text{and} \\quad\ny^* = \\frac{1}{1 + |f^*|}.\n\\tag{26.4}\\] We can solve for \\(f^*\\) in both equations and equate the result to one another. This gives \\[\n\\delta \\frac{1-x^*}{x^*} = \\frac{1 - y^*}{y^*} = |f^*|.\n\\] Therefore the equilibrium points lie along the above curve. Let us generate different values of \\(f^*\\) and plot the combination.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndelt = 1/6\nfmat = np.linspace(1e-3, 10, 101)\nxs = delt/(delt + np.abs(fmat))\nys = 1/(1 + np.abs(fmat))\nplt.plot(xs, ys, '.-')\nplt.xlim((0,1))\nplt.ylim((0,1))\nplt.xlabel(\"$x^*$\"); plt.ylabel(\"$y^*$\");\nplt.grid(1)\n\n\n\n\nThe above shows the steady-state values at \\(\\delta = 1/6\\). Each point refers to a different value of \\(|f^*|\\). Note that as \\(|f^*| \\to \\infty\\), then \\((x^*, y^*) \\to (0, 0)\\) while as \\(|f^*| \\to 0\\), then \\((x^*, y^*) \\to (1,1)\\).\nNow the above does not tell us what equilibrium states will exist at a specific value of \\(\\delta\\) since it requires information about \\(f^*\\). We take (Equation 26.3) and combine with (Equation 26.4). We conclude that the equilibrium points must satisfy \\[\n\\lambda f^* = \\phi(f^*),\n\\] where we have defined the function \\(\\phi\\) according to \\[\n\\phi(f^*) = \\frac{\\delta R}{\\delta + |f^*|} - \\frac{1}{1 + |f^*|}.\n\\tag{26.5}\\] Therefore, for each combination of the parameters \\((\\lambda, \\delta, R)\\), we must solve \\(\\delta f^* = \\phi(f^*)\\) to determine \\(f^*\\). Once the values of \\(f^*\\) are known, then the steady-states \\((x^*, y^*)\\) are also known. Here is a typical graph showing the potential intersections at the values of \\(\\lambda = 1/5\\), \\(\\delta = 1/6\\) and \\(R = 2\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.optimize as sciopt\n\nlam = 1/5;\ndelt = 1/6;\nR = 2;\n\nf = np.linspace(-2.5, 2.5, 101)\nphi = delt*R/(delt + np.abs(f)) - 1/(1 + np.abs(f))\n\nplt.plot(f, phi, 'k', label='$\\phi$')\nplt.plot(f, lam*f, 'b', label='$\\lambda f$' )\nplt.ylim((-1.5,2))\nplt.xlabel(\"$f$\")\nplt.ylabel(\"$\\phi$\")\nplt.legend()\nplt.grid(1)\n\n\n\n\nAlthough there are many parameters that can alter the shape of the overall graphs, note that if \\(\\lambda\\) is increased from its current value of \\(\\lambda = 1/6\\), then two of the left roots will disappear, leaving only a single root."
  },
  {
    "objectID": "part-03-box/stommel.html#stability",
    "href": "part-03-box/stommel.html#stability",
    "title": "26  Stommel’s box model",
    "section": "26.3 Stability",
    "text": "26.3 Stability\nWe let \\(x = x^* + \\xi\\) and \\(y = y^* + \\eta\\) and linearise the system about the fixed points. This gives \\[\n\\begin{pmatrix}\n\\dot{\\xi} \\\\\n\\dot{\\eta}\n\\end{pmatrix} = A\n\\begin{pmatrix}\n\\xi \\\\ \\eta\n\\end{pmatrix},\n\\] where the matrix \\(A\\) is given by \\[\nA =\n\\begin{pmatrix}\n-(\\delta + |f^*|) \\mp \\frac{Rx^*}{\\lambda} & \\pm \\frac{x^*}{\\lambda} \\\\\n\\mp \\frac{Ry^*}{\\lambda} & -(1 + |f^*|) \\pm \\frac{y^*}{\\lambda}\n\\end{pmatrix}\n\\] if \\(f^* \\gtrless 0\\).\nThere are two ways or proceeding. We can numerically substitute the fixed points into the above matrix for \\(A\\) and then calculate the eigenvalues (numerically or otherwise). Or we can directly proceed analytically.\nIf proceeding analytically, we can then calculate the trace and determinant, giving \\[\n\\begin{align}\nT &= -(1 + \\delta + 3 |f^*|), \\\\\nD &= (\\delta + 2|f^*|)(1 + |f^*|) \\pm (1 - \\delta) \\frac{y^*}{\\lambda}.\n\\end{align}\n\\] Using the above, we can analytically calculate the key discriminant expression of \\(T^2 - 4D\\) (or numerically) in order to verify stability. The details of the classification scheme is given in the appendix Chapter 29.\nFor our purposes, we will mainly proceed using numerics, and bypass the need to study the above results analytically.\nIn the accompanying lecture script, we will obtain the eigenvalues numerically, and generate the phase plane. At the test point \\(R = 2\\), \\(\\delta = 1/6\\), and \\(\\lambda = 1/5\\), we generate the following phase plane picture.\n\n\n\nFigure 26.1: Phase plane for \\(R = 2\\), \\(\\lambda = 1/5\\) and \\(\\delta = 1/6\\). The blue, red, and green fixed points correspond to \\(f_1\\), \\(f_2\\), and \\(f_3\\) in order. The blue point is a stable node, the red point is an unstable saddle, and the green point is a stable spiral."
  },
  {
    "objectID": "part-03-box/stommel.html#bifurcation-diagrams",
    "href": "part-03-box/stommel.html#bifurcation-diagrams",
    "title": "26  Stommel’s box model",
    "section": "26.4 Bifurcation diagrams",
    "text": "26.4 Bifurcation diagrams\nOnce the above stability analysis, it is possible to sketch the final bifurcation diagram.\nFirst, we can note that as \\(\\lambda\\) increases, the graph in Section 26.2 indicates that there may either be three intersections (as shown) or if \\(\\lambda\\) increases then two of the intersections may disappear. We can note that:\n\n\n\n\\(f_i^*\\)\n\\(\\lambda \\to 0^+\\)\n\\(\\lambda \\to \\infty\\)\n\n\n\n\n\\(f_1^*\\)\n\\(-\\infty\\)\nnone\n\n\n\\(f_2^*\\)\nfixed point < 0\nnone\n\n\n\\(f_3^*\\)\nfixed point > 0\n0\n\n\n\nWe can also ascertain that there should be a point, say \\(\\lambda = \\lambda^*\\) where the two roots coalesce, \\(f_1^* = f_2^*\\), and thereafter disappear. This allows us to now plot the bifurcation \\((\\lambda, f^*)\\)-plane:"
  },
  {
    "objectID": "part-03-box/stommel.html#stommels-conclusion",
    "href": "part-03-box/stommel.html#stommels-conclusion",
    "title": "26  Stommel’s box model",
    "section": "26.5 Stommel’s conclusion",
    "text": "26.5 Stommel’s conclusion\nWhat is the final takeaway message(s)?\n\nIt is possible to pose a conceptual model of the ocean and the thermohaline circulation, which governs the exchange of hot-and-cold waters and salty waters from equatorial-to-pole zones.\nThis conceptual model suggests that tipping points and hysteresis are possible in such systems. In particular, it is possible, according to these models, for the flow directions to entirely change!\n\n\n\n\n\n\n\nAs noted by (Kaper and Engler 2013):\n\n\n\n“Clearly, two-box models are only a caricature of the THC. At best, they account for the pole-to-equator circulation in single ocean basin (the North Atlantic). They certainly do not account for the fact that all the Earth’s oceans are connected, nor for the fact that the oceans are coupled to the atmosphere and other components of the climate system. Nevertheless, the finding that such simple models predict the possibility of two distinct stable modes of circulation, and that transitions from one more to another can be induced by changing the forcing parameters [–] has had a significant impact in oceanography and climate science.”\n\n\n\n\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM.\n\n\nStommel, Henry. 1961. “Thermohaline Convection with Two Stable Regimes of Flow.” Tellus 13 (2): 224–30."
  },
  {
    "objectID": "scripts.html",
    "href": "scripts.html",
    "title": "27  Listing of numerical scripts",
    "section": "",
    "text": "2022-23 note\n\n\n\nThis material has not yet been finalised and is still under construction.\nThis note will be completed as the course is taught for the first time.\n\n\n\n\n\nIntroduced\nScript\nTopic\n\n\n\n\nLecture 23\nlecture23a-typicalphaseplot\nCoding a phase plotter in Python\n\n\nLecture 23, 24\nlecture23b-fastslow\nNumerical solutions for an example problem exhibiting fast-slow dynamics\n\n\nLecture 25\nlecture25-ThreeTermChem\nFast-slow dyanmics for a system of three equations"
  },
  {
    "objectID": "part-05-techniques/odes.html#first-order-linear-differential-equations",
    "href": "part-05-techniques/odes.html#first-order-linear-differential-equations",
    "title": "28  Differential equations",
    "section": "28.1 First-order linear differential equations",
    "text": "28.1 First-order linear differential equations\nFirst-order linear differential equations are of the form \\[\ny' + q(x) y = r(x).\n\\] These are solved by integrating factors. Multiply both sides by \\[\ne^{\\int^x q(x') \\, \\mathrm{d}x'}\n\\] so that the equation can be placed in the form \\[\n\\frac{\\mathrm{d}}{\\mathrm{d}x} \\left(y e^{\\int^x q(x') \\, \\mathrm{d}x'}\\right) = r(x) e^{\\int^x q(x') \\, \\mathrm{d}x'}\n\\] Then integrate and solve for \\(y\\).\nReferences\n\nPaul’s online notes"
  },
  {
    "objectID": "part-05-techniques/odes.html#second-order-constant-coefficient-odes",
    "href": "part-05-techniques/odes.html#second-order-constant-coefficient-odes",
    "title": "28  Differential equations",
    "section": "28.2 Second-order constant coefficient ODEs",
    "text": "28.2 Second-order constant coefficient ODEs\nSecond-order linear constant-coefficient ODEs are of the form \\[\ny'' + ay' + by = f(x).\n\\] With both forced (\\(f \\neq 0\\)) and unforced (\\(f = 0\\)) varieties studied. For the unforced variant (homogeneous), you will remember that the equation is solved by attempting the ansatz \\(y = e^{rx}\\) and solving for \\(r\\).\nThere are many references on this topic since it is the standard second-order theory learned in most initial differential equations courses.\nReferences:\n\nPaul’s online notes"
  },
  {
    "objectID": "part-05-techniques/dynamical-systems.html#stability-analysis-for-2x2-systems",
    "href": "part-05-techniques/dynamical-systems.html#stability-analysis-for-2x2-systems",
    "title": "29  Dynamical systems",
    "section": "29.1 Stability analysis for 2x2 systems",
    "text": "29.1 Stability analysis for 2x2 systems\nIn the case of 2x2 systems, there is a useful classification and shortcut. The eigenvalues, \\(\\lambda_1\\) and \\(\\lambda_2\\) are given by \\[\n\\lambda_{1,2} = \\frac{1}{2} (T \\pm \\sqrt{T^2 - 4D}),\n\\] where \\(T = \\mathrm{tr}(A) = a + d\\) and \\(D = \\mathrm{det}(A) = ad - bc\\). Once \\(T\\) and \\(D\\) are known, then the fixed points can be classified based on the following diagram.\n\n\n\nFigure 29.1: Classification diagram from (Kaper and Engler 2013)\n\n\nAbove, the critical parabola is where \\(T^2 - 4D = 0\\).\n\n\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate. SIAM."
  },
  {
    "objectID": "part-05-techniques/vector-calculus.html#sec-appendix-surfaceintegral",
    "href": "part-05-techniques/vector-calculus.html#sec-appendix-surfaceintegral",
    "title": "30  Vector calculus",
    "section": "30.1 Surface integrals",
    "text": "30.1 Surface integrals\nSurface integrals are generalisations of the concept of a multiple integrals to integrals over surfaces. For example, consider a flat plate of area \\(A\\) heated to a certain temperature, and thus emits a certain amount of energy, \\(E\\), per unit area (per unit time). The total energy emitted per unit time would then be \\(E A\\).\nIf we want to consider the same problem, but now posed on a general surface, say the planet \\(S\\), and where \\(E\\) varies along the surface, then we must consider adding together \\(E(\\mathbf{x}) \\mathrm{d}{S}\\). We thus chop our surface into smaller pieces, each with area \\(\\mathrm{d}S\\), multiply each piece with its corresponding energy, and then sum the result.\nThe result is the surface integral \\[\n\\iint_S E(\\mathbf{x}) \\, \\mathrm{d}S.\n\\] A tutorial for computing surface integrals can be found here.\nYou will not need to know how to calculate surface integrals in general in the course."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Arrhenius, Svante. 1896. “XXXI. On the Influence of Carbonic Acid\nin the Air Upon the Temperature of the Ground.” The London,\nEdinburgh, and Dublin Philosophical Magazine and Journal of Science\n41 (251): 237–76.\n\n\nCharney, Jule G, Akio Arakawa, D James Baker, Bert Bolin, Robert E\nDickinson, Richard M Goody, Cecil E Leith, Henry M Stommel, and Carl I\nWunsch. 1979. Carbon Dioxide and Climate: A Scientific\nAssessment. National Academy of Sciences, Washington, DC.\n\n\nFourier, Joseph. 1827. “Mémoire Sur Les\nTempératures Du Globe Terrestre Et Des Espaces\nPlanétaires.” Mémoires de\nl’Académie Royale Des Sciences de l’Institut de France\n7: 570–604.\n\n\nFowler, Andrew. 2011. Mathematical Geoscience. Vol. 36.\nSpringer.\n\n\nKaper, Hans, and Hans Engler. 2013. Mathematics and Climate.\nSIAM.\n\n\nMacKay, D. J. C. 2009. Sustainable Energy – Without the Hot\nAir. UIT Cambridge Ltd.\n\n\nPouillet, Claude Servais Mathias. 1838. “Memoire Sur Le Chaleur\nSolaire.” Paris.\n\n\nStommel, Henry. 1961. “Thermohaline Convection with Two Stable\nRegimes of Flow.” Tellus 13 (2): 224–30.\n\n\nVan der Veen, CJ. 2000. “Fourier and the ‘Greenhouse\nEffect’.” Polar Geography 24 (2): 132–52."
  }
]